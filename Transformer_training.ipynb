{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI1---5jf0vZ"
      },
      "source": [
        "# **구글 드라이브에 임베딩/텐서플로우 가져오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwzJGeNKf946",
        "outputId": "701ac072-0abd-40fb-89c9-3e598751e2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNVNCP_TgaC4"
      },
      "source": [
        "Transformer 구현을 위한 사전 import 과정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqzdcrWaggY3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbDgkAusg1Ud"
      },
      "source": [
        "Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bVtdkn8g3_R",
        "outputId": "a0d28887-7189-4457-f068-0e41ffd4ca7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 50, 128)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5iU1fXHP2c7LLCUpXekCIiCIrFFEY0lRUx+JmpiYqwxiUZNrDEaNRpLEo1GE8WexG4s2EUFsQsqCEqVuvSlLG373t8f577vzLw7y87C7sLuns/zzLNz33LfO7O7d975nnvOV5xzGIZhGC2DtN09AMMwDKPxsEnfMAyjBWGTvmEYRgvCJn3DMIwWhE36hmEYLQib9A3DMFoQDTrpi8gSEZklIjNEZLrf1lFEJonIAv+zQ0OOwTAMY3chIg+KyFoRmV3DfhGRO0VkoYh8ISL7x+073c+TC0Tk9PoaU2Pc6R/pnBvpnBvt21cAbznnBgFv+bZhGEZz5GHguB3sPx4Y5B/nAv8CvTkG/gh8AxgD/LG+bpB3h7wzHnjEP38EOHE3jMEwDKPBcc5NBTbs4JDxwL+d8hHQXkS6A8cCk5xzG5xzG4FJ7PjDI2Uy6qOTHeCAN0TEAfc65yYAXZ1zq/z+1UDXZCeKyLnoJx+ZyAF9ho8I9xV9OReA3qOGa3vWHAAKe/QFIK91JgArV6wHIKdtWwB6bCgAYHNpBQBth+0NwNeLg+HAqH7tAdg0fzkA63v003PzcrQ96yvto0tvANIz0gHotnYZAOv8GHpvWw1ASVFp2Pfqrn20r/U6jq8zdFz9++pbkCECwHw/nmGtygBYQEcA2hfqefn7DtMxzJ4T9t2pp467qqJS35O1W/TYEfoal83QY1vvPQSAinnz9XV20zH12rQCgEXZeq3hbcrCvr/YoFnb+/fXfZ8tKgRg5N567ox5Oq4he/XQ8S5Zq6+zZyd93Ws2A9C2fW7Y57Zt2n9Gpr5/rkqvUeV/Zmbp9tLicgDatM0GYMumbQB07NQGgPWF2ne3ru3Dvlet0v+x3v76ywrWAdCvdxcAlixbA8Be/boBsNC/34MHdAdg/tcrAdh7YE8A5i4sCPseNrAXAF/5bcMH6d/BlwuWJ23v49uz5+vfx4gh+p7NmpfYjt+2r9/2RU1t/75/MTd5ez/fnunbybZF2+HvMsV28mP6+vbSXWonbBvqj5mTWhvAFa8vdM51ZidJa9fLUVGS0rGueP2XQPzBE/w8lyo9geVx7QK/rabtu4w0ZBkGEenpnFshIl3QT6oLgInOufZxx2x0zu3wa0u3tGw3YXbsl/rK8IMA+Os2nche66/K0YPX3QfAt/fTf96r//gwAHuPPRyA6/9zGQBvfr0RgG/O/BCAH/78+rDvLRPGA/D8MRcD8Mif7gfg2uOHarvfKAAm/eYOANp31onssjt/A8B91+oY/vbxzQAseG1R2PctF96pfT1yKQA/6HwkAI/ecwkAHXL0w+rYn1wHwOcjdGI5tupkAE54SJWwXxTMBOD1wYFiBqffpOMuXrdJ36M739XtSz8A4MI8lQpHffQOAGvGHgXAi1f8E4Bbn78agJP76bVmHxp7v/s+rR+SWx85BYBWpz4EwIb37wag85E6/slP/QmA48/R9+ZP1/0cgJvunATAuO+EciXTpumHTH6PdgCUlujkXrJNf3bppduXfKUfIIccpv/cb7/8GQA/+fGhADz84OsAXPHb8WHfN9z4KAC333gGAL+59F8APHjH+QD8/Ne3AfDcA5cDcMLPdNxvPv5HAI46+RoAPnz2RgAOOjGmQH724q0A7P89/Vua9fJfANjn+N8CMOd17XvosdpeMOl2AAYepX8fi9/+BwD9x10AwNLJ/wj77nukbiuYott6jdX2infuAqDnETr+VVO13f1wba/27W6+vfZdbXf55vlh3+ve87+rw36dtL3e/y47HZq8HfyuO/p2sm2bPtC/pfaH/GqX2vHbij7UbXkHp9YGKJ/x0KdxcnKdSWud7zKGnJDSsalcS0T6AS855/ZJsu8l4Gbn3Hu+/RZwOTAWyHHO3eC3Xw0UO+f+mvorSU6DyjvOuRX+51rgOVSbWuO/vuB/rm3IMRiGYdQJESQtPaVHPbAC6B3X7uW31bR9l2mwSV9EckWkbfAcOAaYDUwEgkj06cALDTUGwzCMuiOkZWSl9KgHJgI/86t4DgKKvPz9OnCMiHTwAdxj/LZdpiE1/a7Ac6I6dQbwmHPuNRGZBjwlImcBS4EfNeAYDMMw6oa/06+fruRxVKrJF5ECdEVOJoBz7h7gFeDbwEJgO3CG37dBRP4ETPNdXe+c21FAOGUabNJ3zi0C9kuyfT1wVF36apeZTp+rY8tUzz5+LwA+OlC1+snrNLg38Xs+NLB2HgCXFmnA8YtXXgLgiPtVw33xcP357WyNk7iqyrDv+V01XvD++u0AXHb0YADu/1g17lHtNKBYOErjBlNf/wKAWT5gO36Uxlp6Zo8E4IWnYsHWtcuLAOgyQgOK2cX5AHy6XHX4M0drkLCiZCsAmxZr7KHNfho3KPNBzo6t9A+yY1bsD3PbCn2tbftoUHhrRZWek9GKeDZu1wBqq3T9kldWrHp9tn9dlaXFAGTmxs5zVTo+yUrsq6xSxxP8g5T6awbt4jJ9X4M7ojK/X4/RoHVlpW5L80HsIKAb7A8Cu+lpiV9K09OC4ysT2vHbogTXqIno/h0dX9M1dnyFJMfX9YR6Iq2W6+6mYe0RCCDp9TPpO+dOrWW/A35dw74HgQfrZSBxNPTqHcMwjKaFCGn1dKe/J2KTvmEYRoT6knf2RGzSNwzDiKceNf09EZv0DcMw4hCEtIzM3T2MBqNJTPo5Q/fmnmfnhe3L1s0C4KEumqV7zvc1y/TNw38MgPPBwTEXaJLQtGeeBWBqF02GOr63Jv58eZUm4XQZHou1/P4lzbjt5oOUB7XWIOZ5H2jW4VkHa6C222hdQvvChMcAWOOzfE/1Wau5bcf57f8J+y5auVjPPXigHjNXMxo/W6oB298flphwt7lAs03zjmqdsL2DXymWEMhdrdnH+aM1SzkI5G4tq0o4d+1mDTgPSNdQXZkfd1au/pFXVWigN7Nd7JquSvuuigZyg6CrD3qV+GumZeoAg0BusL80LpCb7gPJQeA2LSOxXVOgNmhnhcdXD+QGxILDicdU+XZtwcxkRM/ZHYHYlhxkbRTsTt8wDKNlYZO+YRhGS0Gk3pZs7onYpG8YhhGHYHf6u52vFq9h6r2x5KzhFzwOwPuXHgFA2z9oQa172g1LOO+lX34DgG/5BKSL7v0YgI9v+iEAfz9LKzx/68FYHaRXn/sIgMt9VcdNj2vxqpWzNQ4w9AyNCwzplwdA+TZNuPIhAPqJ6vMVfQ8AoLgyVtCueL1Wb8wbqYlbHTZp3bmVPmkrY8MSIPYHt2G9Jkp1zk/U9NM3awXP1h1jGvuWVZrQld5Jk8ZKvDYeaPpewmeDr265r9fEy72mn52nr7dqjRY8S8+NVa0MNHGXmTiOIDkrWNO8vbwyYfzR5KygrcckJmdlZWRE2omafW0afnoScT09simabBU9J9quD72+Puqc1BZ72JnYhLEDJI30+imxsEfSJCZ9wzCMRkPsTt8wDKPFINjqHcMwjBaFTfq7mbT0DC5qc1LY3rRc175/cfUtAFx94xQA/nW4rntfM0/Xla+86CcAPPynhwHY79u/A2Db1X8HYHmxGqT84eiBYd///YuaMhx6mBY/m3n/e3pOluYEZB19LQCyQE1K0v3a9WDNfNXMtwBYOPz/9Pg4wbXM6/8Zw7SoW6e5WjRv0Wx1cqosUDerjFbqCrW6RPXrod01nrDN9xVo+rldYxr7tjVadC4jX92gir02vrm0MmEcy7bqOv02gaZfoqY/WW3VGaxqhWr+0rodUVym6v7BP0S1gmuViQXXogXYKuLX6Wf4NfPB2v7WiQXXqq3Tr2HNvasM1txXL7iWVk33r/aSEqitIBvUrvNHcwOq76/1EsguBhN29fwWj63TNwzDaEnYpG8YhtFiEJEwq7w5YpO+YRhGPCbvGIZhtCxs0t/N7NOvE4/95a6wfds/rwbg9Is0KWvbOnXA2v/9VwFI+/RFAK4+6vcA/PFb9wDQqoO6Sv3uRXWzOsonN/Wc83LYdxBEHX7eeABuOflOANL31WNnFLfVc158DoC8XnsDMHjh2wCsmjQFgPd8wbX8uKJoQXCvuOMAAA7or9tnTVZHtLJFmmCV5YOoG32y06CuOqaFQfC14GsA2nTNDfvesECTwmirblxBMbRC75QVBHK3+OSsVn5cgVNWVkftKyxG1jaWnBWO3ydn1RjI9UHZILGl2I8/3Y87SLyCWLAxcMZKizhlZQfJWJU1JGOlEKStPaiafH8YCE6htJklRjVPoosAmhMNZoxuGIbRFBERJC21R4r9HSci80RkoYhckWT/7SIywz/mi8imuH2Vcfsm1sfraxJ3+oZhGI1JUPp7VxGRdOBu4FtAATBNRCY6574KjnHOXRx3/AXAqLguip1zI+tlMB670zcMw4hHqM87/THAQufcIudcGfAEMH4Hx58KPF4Pr6JGmsSd/qZZc/jevf8K26d+qglU12Z3AmDwUT8A4Ii/fgDA+d89DIjp2K+cr4XVDrnuPgAmPfc+ALdcPBaAL266L+y7z4EX6pNjjgFgdcltAHTop0XZ7vtoKQCnvTgTgJ7H6O9v0BrV0pdNWQDAG0M0ger/2sSWfgWFx77eqAlS+/dR3fyejZqctXFOIQCtOowGYkYoe3VQLX2Vv/soX7UEgNxuMd29qES3VebqexLUeVsf0fRLffG57HaaaFVZppp+dnuNG1SV6/FprdsSpSozJ6FdFiZj6bhqKrgW3DVVJiRnBQXfvH4emKq45MlZgcZfVYOpSrwG66oSi8wFhBp+GCdI3F9PN3d1wu66YuwpOWVaZbPeBtMTWB7XLgC+kfS6In2B/sDbcZtzRGQ6UAHc7Jx7flcH1CQmfcMwjMZDUsrO9uT7STlggnNuwk5e+BTgGedc/MqCvs65FSIyAHhbRGY5577eyf4Bm/QNwzASkTrd6Rc650bvYP8KoHdcu5ffloxTgF/Hb3DOrfA/F4nIFFTv36VJ375dGoZhRKhHTX8aMEhE+otIFjqxV1uFIyJ7Ax2AD+O2dRCRbP88HzgU+Cp6bl1pEnf6pZWOR7JfD9tXn/sMABMX6reqAR1Ua+4z9gIArpx3KADvnn8IALf8TYuj/ecnGgTvfq8WWuv0sOr1/77pwLDvMy9XI5bHZ68FoFuOvkX9R6n5+rsfqkH6qHlaLO2wK9TMvG+artd/5U691tcLtehb3yGdwr5zclT3/7hAC68d1qcDECvEtmG+mqzkdk4smtbbG5wERd22LNMYQJuencO+N3j9vKp1B+JZ5zX9HK+7lxWrSUpWGzVCr/CafpY3QndVWrgtLbd6wbXouvxAw0+LrMsP2mUVgcbv1+DHGcoEOn9plcYYAk0+0P1rM0ZPxUSlmmlK5Jzo/mg72Tf86Nr96CHRc5pz8bM6SCBNCpFYQcBdxTlXISLnA68D6cCDzrkvReR6YLpzLvgAOAV4wgVBLWUocK+IVKE36DfHr/rZWZrEpG8YhtGY1OeHtXPuFeCVyLZrIu1rk5z3ATCi3gbisUnfMAwjDhFp1hm5NukbhmFEqMclm3scNukbhmFEsEl/N9N9n724/KcPhu2ju2hxsE5/PgeAdVvU/anPwWcDsOzDlwBo9U8ttLbf/QcAUHbXpQC06zUYgFs+0oDoyu3lYd+3jVHHrHF/U8esPw/qCEDXsVok7ffXPATAfO9Ader+Gsjtkn8UAF/fpM5Z6xYXANDz0AFh37nL1NnrvQXrAPjxiC4AVFVosHXDAg0Otx+ury+Ie3Zprb+mztkaQN3qA7k9Do9lZxeVawB0S0XiH+vqTfredPPJTUFyVo4PfgcF17LbazKWq9qsPzNbESXqhLW9PLEdJGMFtci37yA5Kwzu+m0ZQYE1H6jNykhPaNdUcC1MzkrinFU9cFvtJaVETQXbdoadkYrrY/qp7bU33yluJ5DmG6SGJjLpG4ZhNBaCkJbRfFez26RvGIYRjzTv0so26RuGYURozvkVTWLS/3JNGf88JqaNj/zvvwH4TWctrBYU1np19bcAOPFmTTw68R+a3PbC73X70ze+AcABN2l84MEnZwBwTqvMsO+qZ28FYOHHqkvvd+4RAAwbqolQF3rDlmIvuI8KcqHy1DQl0Na3rlkCQNdTDwj77lDZA4D5i9TwpFVRQcLrXL9STVQ6e9OUgOxtGgPI66g6/Gaf3NWnc8/wmG0+kavIFzAL3pO1WzT2MDAjKLim8Yuw4Fqhav7puRq7CPTrquzEMQCUBMlZ6ZHkLK/hB5p+aLLi9fq0JCYqWdn6p1flc1GyIpp+bclZWZHqaDsyUQmLtEWTtWpJxkp2s1fbXFAfokBtN5nN+CZ0j0ALru3uUTQcDf7SRCRdRD4XkZd8u7+IfOwNBZ70qcmGYRh7Bl7eSeXRFGmMz7MLgTlx7VuA251zA4GNwFmNMAbDMIwUEdLS01J6NEUadNQi0gv4DnC/bwswDnjGH/IIcGJDjsEwDKMuSDO/029oTf/vwGVA4MjRCdjknKvw7QLUZKAaInIucC6AZLVl8z8+CPd943YttHbnQXrqyq9VI5fr9UvDE1epKcqBJ1wOQMbbWlht9uVqmH73D/cFYPgDDwNw9KG9wr4/uUXX+G9OV9OUdj9UE/a05R8BkJ6l69eD4mdM1+MXDtPPrkBbLilSHT5r1Klh312XqPXlkq+0mFvVki90fDmqn6/wa+j36Zmnffg/qvSNGkfI9fkJW1ap9p/RrU/Yd1CcrajEa97+3GWbVbPPy/Q6e7Guy89pr6+jarU3TWmbWKjNZcXW6UeN0APj86hpSrAuPyi4Vhqs089IXJMPkNY6cVtNmn1s3X6iUXrU1DzZP2AynT+e2tZipxLLq918fcfn10fAsDkHHXcXzTk5q8Hu9EXku8Ba59ynO3O+c26Cc260c240SRKFDMMwGgIRvQlJ5dEUacg7/UOBE0Tk20AO0A64A2gvIhn+bn9HhgKGYRi7haY6oadCg93pO+eudM71cs71Q2tFv+2c+wkwGTjJH3Y68EJDjcEwDKOuCKnd5TfVD4bdsU7/cuAJEbkB+Bx4YDeMwTAMIykisRhSc6RRJn3n3BRgin++CBhTl/P36teN8Wf8OWyXe6epQVM02eqQFdMAuGTfMwC4ZvhNALTp1g+Anz6qSVhn+kBor2n/BSC7rSYkjbzyjLDv646/DoCM/TW4+sFWjUEPeOIxADr0UzvMfRZNBqDgBfVGmJStiWI9cjTRKwjsFbXfK+z74EFLAfjiLQ0Kl8zdAkBOnjpqFZZpIHeED+TO8X945cvmA9Cul45lyWR17yKvS9h3WZUGWddu02SsIJC7ZZsGalv5wHNFsQaBs/toX5XlQSC3PfG4zNbh8yBQW1qR3DkrPeKclR5JxpIwSSpmChQEXoNt2ZFAbU0F1sJ2tUSq6gXXanLGigZdw+NTKDu2qzd3zXcqqTt7avxZBDKa6F18KjSJjFzDMIzGQmjemr5N+oZhGPFI09XrU8G+bRqGYcShd/ppKT1S6k/kOBGZ50vPXJFk/89FZJ2IzPCPs+P2nS4iC/zj9Pp4fU3iTj+zYDG9jxobtgf44mcH/U4To44/bm8ARrXVImIPXfYsAL9+Ro3m7/iLavjP3KXv2QdXqBHK0JNuBGDdyIPDvjeUqV9xl+GHAnDLJNXTL3zqc732WacBMGS7JoYtfFX3T9xLV55e3F6LogUJV7PWbg/7PqifxhBuX78SgMIv1Awlt/MxAGz1iUp752vsYbVPqCpZ+jUA7fqohl9YugiAyrZdw74Dw5W1gYbvk5uKt/h2YJpSFpim6PjCgmYRTb8yIyd8Hmj4JWEBNY1blIbtxIJrUdOUQOMvL41p6UEKe1Vl8uSsQOOvqqHgWlrY9ufv4MYsFidI3B5tVyu4loLGHz2nuSZKNWdTkWTU152+iKQDdwPfQpNRp4nIROfcV5FDn3TOnR85tyPwR2A04IBP/bkbd2VMdqdvGIYRR5oIWRlpKT1SYAyw0Dm3yDlXBjwBjE9xKMcCk5xzG/xEPwk4bqdeVBw26RuGYURIF0npAeSLyPS4x7mRrnoCy+PaNZWe+T8R+UJEnhGR3nU8t040CXnHMAyjsQjKMKRIoXNu9C5e8kXgcedcqYj8Ai1EOW4X+6yRJjHpFxaVsvLyvWMb1ul697YPTQXg33N13fsdL10PwCWHa6G1vw/SNek3b1TtfMk3LwPglTlqmP7X0/YH4Ma3vw673t9r8hsP6w/A+5NmAfDxcjUM/6k3SB/UReMAk85/HIBl8woB6H2YFm9rXayGKe8sWh/2fbo3UQ/yDNbNXgVA3n66Tj8wZunVTjXywAi9aKHGC9r2UQ1/g9fOS7OCOnYxVvkCa7lesC7xpu+BEXq5X6efExqhaxE4aZ2X0E9Jgom5N2T3eQRhu1TbMU0/aOu1K7yhTKDxl1TEDOjTQ80+MFFJboRereBaDYYoyTTn6sbotZ8Tf41k1FXp3R1SeCrzVctS6OtOPa7eWQH0jmtXKz3jnFsf17wfuDXu3LGRc6fs6oBM3jEMw4gjSM5K5ZEC04BB3jwqCy1JMzHxetI9rnkCMf+R14FjRKSDiHQAjvHbdokmcadvGIbRWAhSb2UYnHMVInI+OlmnAw86574UkeuB6c65icBvROQEoALYAPzcn7tBRP6EfnAAXO+c27CrY7JJ3zAMI446avq14px7BXglsu2auOdXAlfWcO6DwIP1Nhhs0jcMw0jAyjDsAfTs25HbB38vbAeJOJf55Ku773oegJu37wfAT8b1A2DKib8CYNAx+qF6xoSPATjEafDwkO1aiO20V9aEfV/0w2EAHHDUYAAOvVs/ZFeWaJDyvL016Jrb7f8AWF78bwA2LNZci74njgKg/Qw9/+3Zq8O+rzgw0Z1qwwL9ptbpuDYJ2zumadG0zq01CapoiY6v86G6SGCzD7JuLKkecCzYoMlXw/3X09JiDZ6GyVlbfXJWRw3cuiqNIVVl5yb0U1wRK44m6YkF1tIyNXC71b8nQXt7JDmrKkzeSizABtUDs7W1o/+EmZFAb/z+qrDgWsIp1YK/UaLHN0YQNtncEt3UjOefPZN6vtPf02gSk75hGEZjEdTTb67YpG8YhhHBJn3DMIwWQpqZqOx+lqd1oHN2TGNeUaxa8mUbngFgwLVaSO03l/4LgCuffASAC7ocDsDf//cNAE742Z8AuGGQFj77/DI1ZlmzblDY96DHNYHL+eznQDNu5QMJHZe8r2PofQgQK3S2bZ0e327sTwHotlELna1esinsO22pxhDSs9TofXmRavcjfCG2oIhYxvol2pc3Tdm0RJO5Mrv3A2KF2TbFafqBacqKItXsD8lM1PSD5KyqTdpOy+vkX98C3Z6t1woNU+L09zS/bYvX7KMF1qoVXIto+JnZ+mdWVVFd06+q0PcpKz25hh8US8tMS9yfVkviFdSu4e+MZh81YolODbXdIDbXgmzNCtP0DcMwWg6C1HrD0JSxSd8wDCNCcy4lbZO+YRhGHMKO/RmaOk1i0t+wei2nFC4N2/KJrsu/5pirAfjjo6opX+h13zNfXwvAUR1VOz98rZqYB+vND7tFYwC3nHynbt83Vszt06whAPR85PcAdOi3DwD7LXkPgJVPaIG1V0/U43rkBHq1atPbemkRt0OGqdHJwx99HvZdMtsXO/NG6MHa//37qoHJwqBQ2eLZALTvp2vpl71XoOPM12JuxV4rX7WlNOw7iDmsL9KCa3l+XEFxt5zu2lflAm+E7jX9AJetuQIxw5Q4E/Nqxufa3uILrqWHBda8zu3HEjNRqW6MXpMRenSdfkBNRuixAmxUo5r+Xk2PTzypmonKHvqPb3GBBkaqx4yaE01i0jcMw2gshNjCgeaITfqGYRhxmLxjGIbRkhAxeccwDKOlINjqnd1O+66dGfSLp8P22GM1uHpU22wA7vz5fQBc9cqrANxwnRZJm/DQLwF45+xbANj3p2pIs/ZQTdZaXXIbAN32OzLs+8qJXwJwyUPqxjXovB8BMJI+AHz1lCZYPdFVA8uX5LcGICNHA6HTVmqw9shBGqy9e13M4nLNJ+qU1aarehsHDljf69oOgPWZGkQtXjgXgLx+6pS17o3FAFTmqddCkBC2YktJ2Hcrn9xUvEUDtUGBtYoSHzzupNeoKtf96W3bE09lhh4fBHK3lcUSv9IytPDblrKoU1ZigbVY4Fbb5aVBYNcnYu2g4Fp26KSVvOBaWhjo9deoIbAL8cHhxGOi7WqB2xT8pKLn1BZUbarKcENMek1pHjV5xzAMo4UgApnRO4RmhE36hmEYcZi8YxiG0cIweWc30082s3jN4rD91O1a9OyhmVpw7Zq9TgDgj5UfAHBtmRYdmzL4ZABemqfa/b/PHgPA+f+bBcDpXdQ4JPv4IWHfT/73bQCmFmwG4KLjdN/gAd8CYOIr9wCweLbq83sdOwCANuv76bW+VMOTy8b2B2LJUQCrP10BQKfDuwBQ5pOV+rVXjbxbjurpG+drHKDj0L4ArPPa+PaMRLOVgo3F4fN2XgPfvtVr+vmamFZerJp+6y5q4FJV4Q1j2iQmZxV7PV7C4moV4b5Aww9NU4LkrBJfvC1MztI+MnxsomSb7k8P9fpYclZ6WqTgWg2mKUE7um46eieWmeS/NHpMTXdvwTWi7Mz//e64QUxloUkznsPqHUHq9U5fRI4D7kA9cu93zt0c2f9b4GzUI3cdcKZzbqnfVwnM8ocuc86dsKvjaRKTvmEYRqNRj1U2RSQduBv4FlAATBORic65r+IO+xwY7ZzbLiK/BG4FTvb7ip1zI+tlMJ7mG60wDMPYCVTTT+2RAmOAhc65Rc65MuAJYHz8Ac65yc657b75EdCrHl9ONWzSNwzDiCMow5DKA8gXkelxj3Mj3fUElse1C/y2mjgLeDWuneP7/UhETqyP19ck5J2CxYV88tElYQQtyoYAACAASURBVPvEm6cA8M1/q+n4s9fquvcHf6CmKIf9+QEAfvlXPe6cHF1n3uOtOwD48EV92Q9dpecdNm5A2Pe/rr8diK2h/25fv369988AWFlyFwAbF80EoO9F4wDoMlX7eH+mav35Y7KrvY61C9UIvcdpiWvk25UUAtCts6753zBPX1eP47Tvjb6QWWFxYnGxpeu3h30Epikl21Qjb+3zByq9UXpme72mq1oJQFVO24QxbPN6fFCUbmv8Ov0ajNCDdfqBhh8UXMvypimBiUqrLN0f6PdQu4aflZ684Fqo8acnrutPVv88uq22gmqpyLi7epdU7ZopHGM0MlI9p2MHFDrnRtfLZUVOA0YDR8Rt7uucWyEiA4C3RWSWc+7rXblOg93pi0iOiHwiIjNF5EsRuc5v7y8iH4vIQhF5UkSyGmoMhmEYdSVYspnKIwVWAL3j2r38tsRrihwNXAWc4JwLy+c651b4n4uAKcConX5hnoaUd0qBcc65/YCRwHEichBwC3C7c24gsBH9OmMYhrGHoM5ZqTxSYBowyN/sZgGnABMTriYyCrgXnfDXxm3vICLZ/nk+cCgQHwDeKRps0nfKVt/M9A8HjAOe8dsfAepFpzIMw6gP6vNO3zlXAZwPvA7MAZ5yzn0pIteLSLD88i9AG+BpEZkhIsGHwlBguojMBCYDN0dW/ewUDarp++VKnwID0WVLXwOb/BsBOwhq+IDIuQBtSG/IYRqGYYRoGYb6C6w4514BXolsuybu+dE1nPcBMKLeBuJp0EnfOVcJjBSR9sBzwN61nBJ/7gRgAsCwvHZu6ZHjwn2ffaIJVG0PuxCAxc/9BYD5V+v7OvH0fXX/fRrQPflMlcFeuvAxADb3PAiA1uf8E4C0d/4d9p2T1xmA3q00+Fvxsh4zfcx5ALTxAcjijRpszThYtw8p1ADuJ5Pn6HmzlgGQ3bZj2PfCBZqsdKgvxlbo/7CkQD+8O/TXYOvGRZsAyOwzGICtPnFqrQ/SZvlI38INsUBuRx8sLd2mX65yu2igtnK1FmVL79DFH6nXcj6QGyRjFYfF0nzQtjSWnBU6ZflAbkaWBqlLg4JrgTOW7yOtdWI7GrSFWKA26pQVFEur5nIViW7uqOBaTdtqc8qq6fyakrf0mB33UR8uV+aU1fg057e8UVbvOOc2ichk4GCgvYhk+Lv9pEENwzCM3UkqFVebKg25eqezv8NHRFqhGWlzUG3qJH/Y6cALDTUGwzCMuiLonX4qj6ZIQ97pdwce8bp+GhrAeElEvgKeEJEb0PTjBxpwDIZhGHWmOedKNNik75z7giRrSv160zF16auizwBem7s+bJcPPwyAgy/QZKsfXfU8AO9epNvnn61lK/ocfDYAvW/SeMBf79YSFu0PVROWP7yxEICTbvtv2Hf/g68A4JvF7wIw4+7XAbi3/FgAjs9TPTsoOja/QnX4E0fql6Y3/6tfXArfXwdAm677hX2v8Tr5t/tq8bMPs/TtL5v/OQAdBmk8Yf40jQ9UdtDlvUFhtmVFqs8HcYXNm2ImKm28aUpQ4K1Vf71GRakmZ8U0faUqO6Lp++SsmGFKvIlKos4fmKKU+XaQnBWYpgTtIDkrNEgpr56cVZNpShBIC0xTMiPJW6HensQwJZbwldiujfr4R7cU9xhN9U6YJnwXnwop/Y2KyA9EZIGIFInIZhHZIiKbG3pwhmEYjY3U7zr9PY5U7/RvBb7nnJvTkIMxDMPYEzB5B9bYhG8YRkuhGc/5KU/600XkSeB5tLwCAM65ZxtkVIZhGLsJs0tU2gHbgWPitjmgUSb9rxev4s9v3xG2Lxl7JQCTv69OUq0e+wiA4r/dDcAjvTVg+8DcwwG46PWlAOzfXoOdG8drwPfpZ6YD0P6TlWHfv7p1OAAjh2iS3D/PfxyAaR8XAHD5uH4AtCnWn//zDlqn76+JxUHS1ooP1Omr036x0tlBktVQXwFzWSt9+wtnzAeg497a5+qSzwAoye2c8D4s8clY7TI0ULp9c/j5S653ASvzgdzAKctVaaJXWl5+Ql/bKzQ4HARpiyKuWJu9KxZAepa6cG312zKygqqaPqHLR0xLKhKdsirD5Kx0P5ZYQDU7o4bkrBqqZkb/CaMmF6kkZwXNMBgcTdaKnJ/s/z6aKLUnOmXtzJCa8yS3MzTntyOlSd85d0ZDD8QwDGNPoTmvwkp19U4vEXlORNb6x/9EpEHdXQzDMHYH4u0SU3k0RVL9QHsILQfawz9e9NsMwzCaHZaRC52dc/GT/MMiclFDDCgZmbltGfdB17D95DUaWrj/gNMAOOy6+wD4zjVvAHCG14cPnK7bT3pMX+b11xyvx41X3b7/HfcAsLIkVlzs8mF5AMjgXwGw5EwtxrZ2zjQABv9Gr9116kAAXvlYndB+v0/i5+fKWVoWu+f3O1R7PfnlmmjWvZNq5etma7yg61Eagyj0iVHrtuu4guJii9ZtA+AbWXqt7VviNP2uqukHTlnZXVTDr6rQcVS1yksYw/aIU1aRT7RKz9YxFW2PafqBU1ZYcK0Wp6ww8co7ZUXb8dtqcsqKJmNFnbIyqxVgq/4fWB9OWbtKbU5ZTfRmsVkjmLwDsF5EThORdP84DVhf61mGYRhNEBFJ6dEUSXXSPxP4EbAaWIUWTLPgrmEYzQ/Rb2CpPJoiqa7eWQqcUOuBhmEYTRyhul9Dc2KHk76IXOacu1VE/oGuy0/AOfebBhtZHMO75TDtqcfC9rsPXgvA8ptUA3/tZF1IlPuQhh3OuuIoAP573iMAFPU7BIDKM/8BQIc3dD1/6049ANgrN+bNvv2/NwPw/tiLAcjLTDRNST/ytwDsv3UJAG+/rGvqyz+dB8RMWObNV/362BHdwr5Xeh2bJTMAyB/SCYDCeaqUZfbXWEOwnn95kWr2rbyePW+tGqR812voJZuLwr7bdFfNvnyl6v7pnYb6PWqaUtVaYwtBgbWt5YmmKcE6/aC9KU7TD0xTikNNX8dT4WMPrdtkJbRb+XX8QYG1VpnV1+nXZpqSEdH4azJNiRZgS9hWi2lK9E6tWp9Ux0xTWgbN+XdQm7wTlF6YjtoeRh+GYRjNCs3IrT95R0SOE5F5IrJQRK5Isj9bRJ70+z8WkX5x+6702+eJyLH18fp2eKfvnHvRP93unHs6MtAf1scADMMw9jTq6z7f+4ncjZpIFQDTRGRixOD8LGCjc26giJwC3AKcLCLDgFOA4ehS+TdFZLC3od1pUg3kXpniNsMwjCaOkCapPVJgDLDQObfIOVcGPAGMjxwzHnjEP38GOEpUXxoPPOGcK3XOLQYWUkcvkmTUpukfD3wb6Ckid8btagdUJD/LMAyjCVO3xKt8EZke157gnJsQ1+4JLI9rFwDfiPQRHuOcqxCRIqCT3/5R5NyeKY+sBmpbvbMS1fNPIFHD3wJcvKsXT5U1sxdy3ZvPhe1fXKyB2NVPXQjAlLFquXvAT28FoOIX+p5+dq06ZPU88NsAnPYfdai65HYtojbivNsAOLrNJ2HfH/9VnbL+Vqrn/C5fk57+kaPF3d5bp/HsH49WV6tn73kUgJWTtPBaXu/jtP2ufiae3q9T2PfbPgC77XP9PXbeRwPQsz7Q5KyKTv2AmFPW1xu1wFrglLXFJ1616awF28q3xwK5rYfpdYLgaUZ+LIAMUJGl4w8Kqm3xLlfpWVqErqjUF0sLiquVxj7To8lYQUG1wCkrcNKq8slZrbMSA7fZEZcsiAV7a3LKCgK3qThlJWtDksBtLV/ao8enEsxrqkk8DVFgrbnEPsU5JEW3NaDQOTe6IcdT39Sm6c8EZorIo845u7M3DKNFIK6qvrpaAfSOa/fy25IdUyAiGUAemvyayrl1Zoc3KiLylH/6uYh8EfeYJSJf7OrFDcMw9jwcuKrUHrUzDRgkIv1FJAsNzE6MHDMRON0/Pwl42znn/PZT/Oqe/sAg4BN2kdrknQv9z+/u6oUMwzCaDK5aWtJOduMqROR84HUgHXjQOfeliFwPTHfOTQQeAP4jIguBDegHA/64p9Bkmwrg17u6cgdql3dW+aeFQLFzrkpEBgN7A6/u6sVTJVOEU167IWzflrcfAFe5cQBsn6va/JTfqLR2yC3vAXD7GE2+Othr/L+59F8AvLJEjUX+8eNRAAw//Fdh348epslX8z78EoD9ztRgecfFes1731NzlIdO3heAcm9asnTyIgB6nKRxlkCXH5qfE/a9ODcTgDXT5wLQ+6gDAVhRrOPdJLkJr3vBGk3G6uY19a2bSgBo00P1+cAwBaBNT00Kq6rw3/7yuiT0tdUnTgXJWRuKVcMPTVR8MlZQcG3T9lhxtEDTDzT8oF28xRdU8/p8ZYUqgIFpSrTgWtLkrLCAWqQdLbAWyc6KatLJTVSodt14dkaCrqtuXR8yd0OYphg7wLlU7+JT7M69ArwS2XZN3PMSIOkSeOfcjcCN9TYYUo9DTQVyRKQn8AbwU+Dh+hyIYRjGnoK4qpQeTZFUJ31xzm0HfgD80zn3QzRhwDAMo5nhoKoitUcTJNV6+iIiBwM/QbPHQPUpwzCM5oWjXuWdPY1UJ/2L0Azc53xwYQAwueGGlUjHfYdy863vhO03V2ie2JjxlwMw6SDV0T/5lq6tn102DIBDn78XgMPKNDTxiy0bAGjl9eFhy94CYOnAmN97sV9rvmHRTAB63PxrAAY+vwWATz/RNfVZI9YBkOHX73/1lerrh+7XHYAKL8TmrIwtcuo+qCMAa2Zq8ba9fqkxhcIyvWNYuVV19Sx/7pxVmwEYmaOfr9s2e2P0Xu30Ggu3hX1ndtkLAFe1DIDKVokF1jaX6evKCExSIqYp67eq/h4zQY9bp5+VuE4/p3VWQjsssFaRvMBatAAbJNPwazFCj7SD8wNS0dqrF1zbcYG1VGqrRNfy13ZOUy3H27JwUNXCJ33n3DvAOyLSRkTaOOcWAY1SYdMwDKOxaap6fSqkaow+QkQ+B74EvhKRT0XENH3DMJon9bdOf48jVXnnXuC3zrnJACIyFrgPOKSBxmUYhrF7cA5SL8PQ5Eh10s8NJnwA59wUkciicsMwjGZCc5Z3Up30F4nI1cB/fPs0YFHDDKk6s5Zu4OmLYl8qtl/6YwB6HagLicbc/GcALszbH4C8E/8PgEs/06jZD++4FIBBR14GwHfSNLg67dK/A3DPeX3Dvo/pqIHMB3x7bs5AAM46QoOq57+oBdnWvKRuV3m9RgCwZPpLAHx3eFcAPgzcraa/Ffbd7QANOH/8mF7f9dKAc3GlJnLNLdTAbODWtWattjt20jGVFmnwuO0+eo3yWVvDvjO69vHPtJhbVa4WYAudsnxyVlqGJoht9MlZGT5wWxS0fRC2tDjmnJWZnZic1baDT8aKFFgLArVB4lXlDpKzogXWMtMSg6phuzJakC2x4FpNLllQu1PWzlDfBdaaskNTEx56LdRvctaeRl2M0TsDzwL/A/L9NsMwjOZHS9X0RSQHOA8YCMwCfuecK9/ROYZhGE2aei7DsKdRm7zzCFAOvAscDwxF1+wbhmE0S4SWrekPc86NABCRB6iHsp47Q1VFOc//4E9he/7hRwEwfYsaloy7S3Xsa3zy0+DfqhvZDTeqwUnau2pc88/7DwJgzHHnAXDd8dcBMLnvzLDv636qCVMdV2qBtdve+RqAv313CABnbdTEqgUvqmd8z+/8AICtz+gfyYG+GNq6Nqqdr3z387Dvbgerqcvi+9SPZnNOfsLrnL1S4wads/TXEpimBMlYpT65rG2frv59WRWeKx27J/QVJGMFBdUKtyeapBRuLQUgo5WONyiwluVjEYF+DzUXWKso0z5b+fEGyVlRE5Wkmn4kuSozPdquW4G1+GZNOn9Ugq7NNGV3adYNUWCtIUxTmi8OKpvv6p3aNP1QyqmriYqI9BaRySLylYh8KSIX+u0dRWSSiCzwPzvsxLgNwzAahqAMQzPV9Gub9PcTkc3+sQXYN3guIptrObcCjQEMAw4Cfu3d3a8A3nLODQLe8m3DMIw9huZcZbO2evo7XVTN1+Jf5Z9vEZE5qKnveGCsP+wRYApw+c5exzAMo35p2YHcekFE+gGjgI+BrnHmLKuBrjWccy5wLkCPXr258qKbw31Tj+4PwGeHjAVgWrpq5eOmPg3A0RtUw79q4xogVsBszJKXAVg8/EQAisrVx2Dd3JjhfN8/6+fP0Bf0i8yUKZqOkNt/KRArsDb7K9XXx41Wc/MSf43cgs8A6D1U9fqCj5aHffc752wACsseAmDJprKE8c1cruYup+UEpim6Tr99f1XAyufqmLJ6DgXAVRWEfVe2VROVmgqsFXrNvqYCa5t8OzMnWJMfU/Nat8sGai+wFrYj6/ZzMhI1fqi+7j5Ylx+YptS1wFpKxuiNUGAt2kW1/aatNw2a8aRf37km1RCRNuja/ouccwmSkPeBTOpL5pyb4Jwb7Zwb3bFTfrJDDMMw6p+gDEMqjyZIg076IpKJTviPOuee9ZvXiEh3v787sLYhx2AYhlE3HK6iPKXHrpDKohYRGSkiH/rFMF+IyMlx+x4WkcUiMsM/RqZy3Qab9EW/xz4AzHHO3Ra3K975/XTghYYag2EYRp1xNNadfiqLWrYDP3PODQeOA/4uIu3j9l/qnBvpHzNSuWhDavqHol66s0QkGMzvgZuBp0TkLGAp8KMGHINhGEadcLiw5lMDU+uiFufc/LjnK0VkLVoSZ9POXrTBJn3n3HvUnEdyVF36Kp03j/2v/kvY7vaLbwBwU74GcHueo45Zxz+j8eFLbr8YgNHn6ReMH3ZfAMDkc24H4JYL+gHwu25tAXjIBzMB3invoX0c0w2Ak55SVWrZY9p3p4GaEDb/kxcBOH2kFlF7u5UmY21591UAeh2iTlZvT4gFiQ/pq9++ggJrM9doiKOjD3x+vFoLqHXupsHiEp8I1m60d+OaqclamT36+R7fD/uuaKWJaUEy1sZi74yVlQPEArmZPhC9YVtiMlaZD9wGiVjJkrOCQG7bHJ+MVZ6YjBUEYVtFkrOixdWgeoG1MMiaYoG1aKA3WcG16kHUaHvHQdUGD3g1EA2RiNWi4s+Oujhn5YvI9Lj2BOfchBTPTWlRS4CIjAGygK/jNt8oItfgvyk450pru2ijrN4xDMNoOtSpnn6hc250TTtF5E2gW5JdVyVc0TknIkkXtfh+uqNVjk93LlxadCX6YZEFTEC/JVxf24Bt0jcMw4jHuV0O0sa6ckfXtE9E1ohId+fcqh0tahGRdsDLwFXOuVA6iPuWUCoiDwGXpDKmpvoN1jAMo4FwuKrKlB67SK2LWkQkC3gO+Ldz7pnIvmAVpAAnArNTuWiTuNPfXFLB7CNjcYu9LtLX/o43VrngsmMAOOAENUkZuGgjAC/+UrX/Nj++A4D7ex8PwMzXpgBwxM1qttLz4/3Cvq974UsAJp0xGIDybUUAzH32K+37d78CoOy/+k1sRFvVtdfma1xgyetaTG3Iz08A4Ovbp4Z9r6psnfC6pi3RcY7yGvmmdZqM1WGABudLvGlK3kA1eamq0NiE69gr+haxscRr45mq6a/ZlpiMtW5zYoG19b7gWmag6fsYQNDetjkmDbby46so023RAmvRZK1ogbWc9GQmKrqtKqL7h/sjyVjpacmTooI+k2nOdZWhU9Gt65qMVdf+ktGS5PQ9gmD1TsOTdFGLiIwGznPOne23HQ50EpGf+/N+7lfqPCoindE/kRloGfxaaRKTvmEYRuPh6hLI3fmrOLeeJItanHPTgbP98/8C/63h/HE7c12b9A3DMOJxNNaSzd2CTfqGYRgJ1Gn1TpOjSUz6PYf04uojLg3bG8aoScqCP6ix+ZC/XwBA/uDDAThyqerohVf8HID7fqjG6b39Wvqta5YAUPb9uwD4cddlYd933/U8AMXt3wSgbXddb//RnHcAOOeIAQDMDnRsv16/7+FqTL7oTe17+G06lg1lt4R9z1qbaHz+0VLV9E/I04JmWws1eN9hiK7LL5uq6/gz++iKMFc1F4DKdroCLFiTD7DJa/qB0fnabV6z9+vy124J2rpuf4vX/LNb6Z9AaYmuVmjfOReAirLYH310XX5NBdaCu6Oohp+RRNPPjpqmpCUeU7042o4NTpJp43UtsBbdXx/F0ZpqgbUmOuz6oR5X7+yJNIlJ3zAMo/GwO33DMIyWQ+Ot3tkt2KRvGIYRh8MllAxpbtikbxiGEY/d6e9+5m3N4M/9csN215vOB+DUC+8B4My33gXg0bl/A+CgszRge93x1wHwn6L3AHjn3AMBuHOl/rzs5XkA/O27Q8K+b7pCi9p9/q85APT/zrUArHv1Pj1nSCcA0n3wtWDi6wD0OVb7fO4ZDbYenKfuXpVx1TQ+WqJuWz1ydHzrV2mBtY6DtFhasS+w1vEYTcaqfFOzrNO69U94P4oq9dcWH8hd5ZOtMnL0fVpVVAJAZm4eAGs3azvbX7tkmwaqgmSskg1azC3bt8tLy8K+2/hzKsv0mCCwW1lDclZ26JSld0s5GdUTv8OCapU1JGelJw/c1hjYrXaF2gus7Y5gZUMkYzVEgbUWjXO48rLaj2uiNIlJ3zAMo/FonOSs3YVN+oZhGFFM3jEMw2ghOFcfxdT2WJrEpL994wYGzYj5FBz0giY83ZimiUj9WqvmvPf/VMN/4bgrAUgXba+ZrclaPd+7F4DvvqweBC8+rVr/PzLfCvtu3UlNVN7/QOMEZ92lev+Sm1SXzv5ck7GGfLM3AAtf1SJo/X+nTmdrSh8CYOYaTcRqE6dnf7igEICL26gWX7RG25330WSs0mmarJUzUAvFuaoCACo66LUkTbXyDT4RK9MXTwNYFSRf+W2rNqmGn9VaNf4NvoBaVpCMVayafruO+h6u9yYqbQK9vrQ47LtNdmKBtTaRZK3czETTlGz/moPjA8OUqviCa5FkrGg7apISyeWq1o7XtVNNxooS1fyTHV9bgbWmmoxlJGKrdwzDMFoKzuEqbdI3DMNoETjnqCqv2N3DaDBs0jcMw4jHYXf6u5sevbox+rTbw/aZbz0GwNNzPgbg0CWqw1/3nRsA+M+sAwCY8gtdO//Aav35qxcXAvCX76hO//BNdwIw/da5Yd97HXMNAMvf0hLW549Qr+LX2muhsmWPq4HLXuMP1u2vPQrAgfl7A1BWpQvz3/b6fY+c2Fv82jI1ZOk8PB+Abeu00Fv+uIEAVEzVdfnpfYb6M94AYDN67XRfTK1gc+KafIBlG7cDkNVW1/yvKvLr7v0a++KtQYE1b+Du1+Xn+HawLr99a403BGvyYdfX5Qcaf3y52vpel5/URKWWdfmNYRtXaxxhp/o04/OGxiZ9wzCMFoJzjiqrp28YhtFyaM6rd8wY3TAMIx6/eieVx64gIh1FZJKILPA/O9RwXKWIzPCPiXHb+4vIxyKyUESe9CbqtWKTvmEYRhzB6p1UHrvIFcBbzrlBwFu+nYxi59xI/zghbvstwO3OuYHARuCsVC7aJOSdjkWrcB26he0DO2hgs8/ffw3A3SffBEA7HzAMkrHaT30QgHM+0IBp4Ip127b/ATFXrElvvxP2/bt79gFg9q0anMx+X4PGI47TY+c+q4XY+l3xRwCWFz8MwIcFW4CYK9a7X60B4IpOrcK+N65YCUDX/dVlq2SqBntz9j4CiEvG6tQPiBVUW7tN/7iCxKtlPkib5YupARRs9Nt8MtZ6X3AtJ9cXWNvuA7XeGWv9Kh1ve5/YFiRjRROxoO7JWIErVlUNiVfJtu1sMlZNiVh6TKQd2V9bMlay2GZzScZqosNuNKoaJ5A7Hhjrnz8CTAEuT+VE0T+8ccCP486/FvhXbefanb5hGEY8fslmivJOvohMj3ucW4crdXXOrfLPVwNdazgux/f9kYic6Ld1AjY554KvGwVAz1Qu2iTu9A3DMBqNumXkFjrnRte0U0TeBLol2XVV4iWdExGX5DiAvs65FSIyAHhbRGYBRakOMIpN+oZhGHE46m/1jnPu6Jr2icgaEenunFslIt2BtTX0scL/XCQiU4BRwP+A9iKS4e/2ewErUhlTk5j0V63ZwrKHfha2MzYfA8AFXccC8MRcLXK28sEzAXj4g2EAnHD3RwBMOXMAADcVqEHKO3/4BIBRV6kJS2CQAnB1X1W8OvZqB8Ccfz4JwNDzTgLg8ae02NvwnD4JY5w4S7+ljc5VHf75JZsA6H5A7EM+SMbq8oPhAFS8oUlhaf329Ue8rOMpU808PVvjAYs3qd6ematjWrROi7kFiVgASwt1W45Prireovp6jh/PhjVq2NLaJ2OVFWufef74ihLdH2j8FXHJWaGm7zX71plBclZ5Yrsq0RAlSMZKZqKSlZFcw69J468tGSuZtl6bbl2bhp+K4UltfUbZU5KxjB3gHFVljVKGYSJwOnCz//lC9AC/ome7c65URPKBQ4Fb/TeDycBJwBM1nZ8M0/QNwzDicVBVVZXSYxe5GfiWiCwAjvZtRGS0iNzvjxkKTBeRmcBk4Gbn3Fd+3+XAb0VkIarxP5DKRZvEnb5hGEZj4WicKpvOufXAUUm2TwfO9s8/AEbUcP4iYExdr2uTvmEYRjwusU5Uc6NJTPrdurbhmV6jwvYdv/47AH89QM1HHvPa8v8G/RSAJw7T9ewHnai5DvNmLQeg9zdU8399wtsA3P0j1dInXZUd9r3pQdXs9zv7EACev0UNVoY9eioA60r/DMDLYUE11cCfnaWm5qcNVp19wzI1V+k5dljYd8ljfl3+fsf7LarpF+f1AmIF1ZYFhietVcP/eoPX69t1BmDROtXfW7WNFVzbXFTqt6lGv90XWOviYxNl3jSlkzdwqSjWPjp5zT/Q8PO8pl8VZwzdNivQ9LWPVpF1+jmRgmphO6rxx63Tr7Yuv5Y18+lpiX3UdjzUvi5/Z2iMdflWUG1346wMw84gIg+KyFoRGoaY5wAAEsxJREFUmR23LaW0Y8MwjN1G3dbpNzkaMpD7MHBcZFuqaceGYRi7BecclWUVKT2aIg026TvnpgIbIpvHo+nC+J8nYhiGsUeh8k4qj6ZIY2v6qaYd49OZzwXo0TYXUqofZxiGsYuYc1bDUEvaMc65CcAEgN57j3ArlpeE+76YqAlTI6ZqkPViX1Dt4j+q29XXJ2qQMrdzbwCe/N8kAP704TcAmP2QBiL7zngagHHjB4d9f3KbBnmP++QJPfYqTZiatEydqYKCak9/sBSAK7q0BuCfC3UMfcYOAmDbVA0e5x10RNh31b+1r/IeWtQtKKi2rEgDpEEBtblBolWeBm7n+uJoOXkaAlm5XseS2y4WgN7qi7AFBdU2rdU+8v0x87dpHx1ztV1ZQ+C2XZKCa60yE52yoslYQYG1sABbemKgNyiuFk+1ZKxogbVaCqpVC/Sm4JxV12SsVIK2DZGMtatY0HYXceAqa5yamjyNPemnlHZsGIaxu3C4xqqyuVto7IzcIO0Y6pA2bBiG0Wg4cFUupUdTpMHu9EXkcbRWdL6IFAB/RNOMnxKRs4ClwI8a6vqGYRg7g3NQWWbJWXXGOXdqDbuqpR3Xxorlq7lk3pSw/ebzGwEY/btXAJh3hoqYf92oxiUPX6zbz338OQCKXtcyFie3WgxA/0M1GerDyycAcPh//hz2fd9jZwPQ3Wlp6iwv2t777iIATu+gCVRPfKmGKAOOUXOVzXO1mFu3Mw4HoOKN97XDIQeHfUvaawAsL9YvWIGGP2ut6u3ZefkAzF6xGYAcbxwzf6W227RX85gtG1SPbx2n6a9dppVW+w3Q5LBF2zSu0bmtnlO+Xfd38eeU++SsDr7gWqDxx0xUysO+22YlavjRZKxA4w+IFlPL8LtTSc6KJV+RuD8inqdScK0paPhWTG0PxDnT9A3DMFoSVTbpG4ZhtBBsyaZhGEbLwQFVTTRImwo26RuGYcTjnAVydzet23dkxN++Dtuzz9HKkW3+MxmA/3xHk7R+co8mVM0/RQO4dw7XZKL3R2s1zo/O/j0AY26/FIArD7kIgPxOMYvLQMq79S0NzI73gdvnp6sT2fBva+B246KZAPS97FsAlF41DYD0UdqWNHXtKqhqG/YdBG5nrvbJVh00IfmzZeqyldtZ3bi+WK7tdh018avIJ2O1ydOxFPrAbu++7cO+l35ZAED39v0BKN+WPHDbMTcxcJuXkxi4beMralbGJWcFgdpo4DYIugaB21gy1o4rYiY/JnF/bYHbVKps7qoTVirH7wmBW4sF1y/OkrMMwzBaEDbpG4ZhtCQsI9cwDKPl0EgZuan4i4jIkSIyI+5RIiIn+n0Pi8jiuH0jU7luk7jTH9KugrnTJoftux7Q5KuLfPLVzBO0/a99VSv/ZGxfAKZ+/xdALPnqkpGaeJXTTROoKp3+0n7/YuAzDKfnq47+u6kLAbj++3sDUDhXNfr+fxgPQMnlmnyVdtCFAEjaZwAsRX9v2W01SeoTn2gF0KpTDwDeX6QVpwMN/9PF2s7z1964RvX3dp1Uww8Sr3r11pjAsjmq3/fq0D/s+6MtG/w2PafMa/pd22lyVqDhd2jlC6x5DT8vO1HDDxKx4u3iAp0/dMrKTCywlhVxxsqIiOFR/R7qX8NPJmvXlnxVW0G2ZJiG3/xxNNo6/cBf5GYRucK3L08Yi3OTgZGgHxLAQuCNuEMudc49U5eLNolJ3zAMo9FwjqrGWb0zHi1VA+ovMoXIpB/hJOBV59z2XbmoyTuGYRhxOKd3+qk8dpGU/UU8pwCPR7bdKCJfiMjtIpKd7KQodqdvGIYRoQ6uWPkiMj2uPcF7gQAgIm8C3ZKcd1XC9WrxF/Gl6EcAr8dtvhL9sMhCvUcuB66vbcBNYtJfMa+AZ76K2elOG/UiAFeXqJa/4twDAHjmcNXwfzBLzUou6HYkAOuqhgLQyjt1/OZR1d+vGaD6+xlvzQj7/td5h+g5b6iGv9ddZwFQevb/9IDDTgEgLUPX5c8tUdOSVn7N/Vter2/TtR8Ak+bELAPyeqgG/+nCQgA6dm0DwHq/bj8wQClYsB6AIYM6AbB4hhZ7G9B5IAAfFK0DoK+PAUBMw++epxp+RYk3UfEmKZVlakLTIce3vYYfrtMvj7Tj1umHBdZq0PAza9HwkxmcRDX8ahr/LhqgQO0F1BrCAKU+NPzqxeR2uUujLrg63cUXOudG17TTOXd0TftEpC7+Ij8CnnPOhZUQ474llIrIQ8AlqQzY5B3DMIx4/Dr9VB67SF38RU4lIu34DwpE725OBGanctEmcadvGIbRWDgareBaUn8RERkNnOecO9u3+wG9gXci5z8qIp3RL6UzgPNSuahN+oZhGPE4R2VZw0/6zrn1JPEXcc5NB86Oay8BeiY5btzOXNcmfcMwjDicgypnZRh2K+2yM+hy6Wlh+/IXNfB93XduAODMAg3ETr13BABvTNaCZYd00KDmVfd+DMAz4wcDcPcbbwLwzZt+DEDhDdPCvrveoX1XTLwRgJX9jwAgM1fPeWOJBl3b9tDCa0/NVAetvD7DAHjhcy3M1qmvL542b13YdxefXLW2QBO2Bg7trMd8pI5eY0Zq8ta8D2YBMKir9vnG5nW+rYHfoJhaT594BbHAbZdcXbVV4ZOx8gNnLB+o7RgkZ/l22+xI4lUkaAuQHSmolhWJgGZFArfR5KyMJJHc2pKzqgd2E9upuF5Fj6ktGJxKvDQaqN3VwK0FafdMKm3SNwzDaBk4YtV2myM26RuGYUSwO33DMIwWQpWDMnPO2r1kDxnCgy8vCNslP9Ficofkqj59/LWqtz9zkiZhHXG/JlL94z4NgP/yBk3mGvbqXQAUH696feGRaqqSefvVYd+vbtAEqbw+2teEj5cDkD/4QADumaqJUt2GqN7++ie6v9dgTbpbPE8Tr6J6PcCxx+k5L36qBd72P05jDB++qCuxRvXRxLCnffLVkC6q4Zdt2QhAb2+iUrZdYwIJmn6pavhdvUlKoNl3bB0UWAs0/PSEdquIhp+dRH/PiSRjZaUnnhPV7DMj2R/R5C2orvvXVbOPxgBSMVGpTT6vb70eLNGqqWLyjmEYRgvB4UzeMQzDaClYINcwDKOFYZP+bmbO4jW8/8BZYbvzX/4JwITPnwTglyfeAUD3KeolUHbclQB8sK8anLTtrkXvbv1SNehu+2khtouf/xKAfmNiiW1/flbLV+x14CgAnpukZip7j1Zjlq+mq4Z/1NGqx7/6nBZmO/PnYwG4956XADjvpH0AeO+Z18K+vzlQzVueXK9r+w/orcbmpUUaBxiSr/GEUq/hD/DG6IGpeR9fTK3S6/edvX4PMZOU9pGCaW0ihietI+2opt8qs/o6/ayI4B5tRzX72vR6SLIuv7b2Tqyxr02j3xnNvjaN3jT7po9ztnrHMAyjxeCw1TuGYRgtBtP0/7+9+w+ysqrjOP7+sAvLgvxWmfgx7qKUIqUSGhZTDGYCkTpmCZFamlgJWqMVSDNOMzFTU0Q2IgyiaQ4DTSTF2CQa2TBNIyJEhCKJwiQOv5wAnTIE+vbHOXf3uXd3XX4s9zl37/c1c4d7nvvce797du+X557zPN/jnHNVxod3nHOuSoQx/byjOH0qIul3qe3KV2s+09RuHBsmQj+xPKxSddG1YTWrK+b+CYDLp34OgNvnrQVg0heuAuDBJeHxm744FoAli8MKW7Pvua7ptb8/dykA8+d+GYA7v7UwbL9lZnju8pUATP1OmPxddv/W8B4XfB6AeXt2htga+gPwzoG9Ta/94UG9ATj8doj7gjhxW1j1qqFvnKiNk7KDenUrag+oL56k7de9pum1CxOvfeqKJ2LP6FZT1O5ZcuVUfW3xzGP3VmZd62qLn9PuxG7Ne0/sQvsrZbVcOevEJ2VPdNLVJ2VdgR/pO+dclTCgLEuo5MSTvnPOZRjmZ+8451y1CGfveNLP1QfP6c+K+Qub2m/9ZQEAvT96R6vt9SXth+bH9rxwUdd9428EYN53w3j810cPanrtWXt3AnDDiDMBuO3AHgAmnhsvpIrj8WOHhGJoR/8bLpwaNTBcSFUYfz+/f1jMpDD+DjCsT3Hxs6G9ihcwGdSzuH12ffOYPcCA7sVj6/3qWq5r37tb8bZeXYsHpnuWjOH3OJ4x/S7v3S55ixbt2lbGxku3dcE6tA2gkg/uqbZPx2uW4z0q5TU74j06RCefyG2ZNcpA0gRJ2yRtlzQrjxicc641hSP947lVorIf6UuqARYAVwK7gPWSVpnZS+WOxTnnWtOZj/TzGN65DNhuZq8BSFoOXAN40nfO5e5/dO4yDLIyf0WRdD0wwcy+Ets3Ah8xsxkl+00HpsfmSGBLWQM9OWcCb+YdxHGohDgrIUbwODtaR8R5jpmddbJPlvRUjON4vGlmE072vfKQ7ESumS0GFgNIesHMRuccUrs8zo5TCTGCx9nRUoiz0pL4icpjIvcNYGimPSRuc845d5rlkfTXA8MlNUrqBkwBVuUQh3POVZ2yD++Y2VFJM4DVQA3wiJm92M7TFp/+yDqEx9lxKiFG8Dg7WqXEWbHKPpHrnHMuP7lcnOWccy4fnvSdc66KJJ30Uy3XIGmopGclvSTpRUl3xe39JT0j6ZX4b7+8Y4VwFbSkv0p6MrYbJa2L/frLOKGed4x9Ja2Q9LKkrZIuT7E/JX0z/s63SFomqXsK/SnpEUn7JG3JbGu1/xT8LMa7WdKonOP8Ufy9b5a0UlLfzGOzY5zbJF1Vrjg7s2STfqZcw0RgBDBV0oh8o2pyFLjbzEYAY4A7YmyzgDVmNhxYE9spuAvYmmn/EJhvZucBB4Bbc4mq2P3AU2Z2PnARId6k+lPSYOBOYLSZjSSciDCFNPrzUaD0/PK2+m8iMDzepgMLKZ9HaRnnM8BIM/sQ8A9gNkD8TE0BLozPeTDmBXcKkk36ZMo1mNm7QKFcQ+7MbLeZbYz33yYkqMGE+B6Luz0GXJtPhM0kDQE+DSyJbQHjgRVxl9zjlNQH+DjwMICZvWtmB0mwPwlnvNVLqgV6ALtJoD/NbC3wr5LNbfXfNcAvLHgO6CvpfXnFaWZPm9nR2HyOcO1OIc7lZnbYzHYA2wl5wZ2ClJP+YOD1THtX3JYUSQ3AJcA6YKCZ7Y4P7QEG5hRW1k+Bb9O8GNAA4GDmQ5ZCvzYC+4Gfx2GoJZJ6klh/mtkbwI+BfxKS/SFgA+n1Z0Fb/ZfyZ+sW4PfxfspxVqyUk37yJJ0B/Br4hpm9lX3MwrmwuZ4PK2kysM/MNuQZx3GoBUYBC83sEuDflAzlJNKf/QhHn43AIKAnLYcqkpRC/7VH0hzC0OnSvGPpzFJO+kmXa5DUlZDwl5rZE3Hz3sLX5Pjvvrziiz4GXC1pJ2F4bDxh7LxvHJ6ANPp1F7DLzNbF9grCfwKp9ecngR1mtt/MjgBPEPo4tf4saKv/kvtsSfoSMBmYZs0XDyUXZ2eQctJPtlxDHBd/GNhqZj/JPLQKuDnevxn4bbljyzKz2WY2xMwaCP33RzObBjwLXB93SyHOPcDrkj4QN11BKLWdVH8ShnXGSOoR/wYKcSbVnxlt9d8q4KZ4Fs8Y4FBmGKjsJE0gDEFebWb/yTy0CpgiqU5SI2Hi+fk8YuxUzCzZGzCJMJv/KjAn73gycY0lfFXeDGyKt0mE8fI1wCvAH4D+eceaiXkc8GS8P4zw4dkO/AqoSyC+i4EXYp/+BuiXYn8C3wNeJpT6fhyoS6E/gWWEeYYjhG9Ot7bVf4AIZ8a9CvydcDZSnnFuJ4zdFz5LizL7z4lxbgMm5v377ww3L8PgnHNVJOXhHeeccx3Mk75zzlURT/rOOVdFPOk751wV8aTvnHNVxJO+y52kY5I2xeqVf5N0t6ST/tuUdG/mfkO2oqNz1c6TvkvBO2Z2sZldCFxJqAJ53ym83r3t7+JcdfKk75JiZvsI5X5nxCtGa2K99fWx3vrtAJLGSVor6Xex1voiSV0k/YBQBXOTpEINlxpJD8VvEk9Lqs/r53Mub570XXLM7DVCrfqzCVdsHjKzS4FLgdviJfkQyuzOJKy3cC5wnZnNovmbw7S433BgQfwmcRD4bPl+GufS4knfpe5ThDoxmwjlqwcQkjjA8xbWWzhGuLx/bBuvscPMNsX7G4CG0xivc0mrbX8X58pL0jDgGKEqpICZZra6ZJ9xtCwV3FZNkcOZ+8cAH95xVcuP9F1SJJ0FLAIesFAYajXwtVjKGknvjwusAFwWq7B2AW4A/hy3Hyns75wr5kf6LgX1cfimK2ERjceBQsnqJYThmI2xnPF+mpf9Ww88AJxHKG+8Mm5fDGyWtJFQpdE5F3mVTVeR4vDOPWY2Oe9YnKskPrzjnHNVxI/0nXOuiviRvnPOVRFP+s45V0U86TvnXBXxpO+cc1XEk75zzlWR/wMZQswxTUEs8AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    angle_rads = np.zeros(angle_rads.shape)\n",
        "    angle_rads[:, 0::2] = sines\n",
        "    angle_rads[:, 1::2] = cosines\n",
        "    pos_encoding = tf.constant(angle_rads)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    print(pos_encoding.shape)\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "sample_pos_encoding = PositionalEncoding(50, 128)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 128))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brDUywR2hKF8"
      },
      "source": [
        "Scaled-dot-product-attention 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXyClATlhNWK",
        "outputId": "dc46b753-816b-4ae7-eb44-02a9ad01eea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
            "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n",
            "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
            "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.  0.  0.5 0.5]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[550.    5.5]\n",
            " [ 10.    0. ]\n",
            " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 스케일링\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output, attention_weights\n",
        "\n",
        "  # 임의의 Query, Key, Value인 Q, K, V 행렬 생성\n",
        "np.set_printoptions(suppress=True)\n",
        "temp_k = tf.constant([[10,0,0],\n",
        "                      [0,10,0],\n",
        "                      [0,0,10],\n",
        "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[   1,0],\n",
        "                      [  10,0],\n",
        "                      [ 100,5],\n",
        "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "\n",
        "# 함수 실행\n",
        "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
        "print(temp_attn) # 어텐션 분포\n",
        "print(temp_out) # 어텐션 값\n",
        "\n",
        "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
        "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
        "print(temp_attn) # 어텐션 분포\n",
        "print(temp_out) # 어텐션 값\n",
        "\n",
        "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
        "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
        "print(temp_attn) # 어텐션 분포\n",
        "print(temp_out) # 어텐션 값"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TwLqN3giC4r"
      },
      "source": [
        "Multi-head Attention 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0fbmXPIiGFP"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    # d_model을 num_heads로 나눈 값.\n",
        "    # 논문 기준 : 64\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
        "    # q : (batch_size, query의 문장 길이, d_model)\n",
        "    # k : (batch_size, key의 문장 길이, d_model)\n",
        "    # v : (batch_size, value의 문장 길이, d_model)\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 2. 헤드 나누기\n",
        "    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
        "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 4. 헤드 연결(concatenate)하기\n",
        "    # (batch_size, query의 문장 길이, d_model)\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 5. WO에 해당하는 밀집층 지나기\n",
        "    # (batch_size, query의 문장 길이, d_model)\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqvj8voSiOOq"
      },
      "source": [
        "padding mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ1ODbeCi5i5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVgHCn7PiQFJ",
        "outputId": "b3cd0702-37c8-4148-e160-0490d5ea888c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, key의 문장 길이)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOJV_xXQiWTr"
      },
      "source": [
        "Position-wise FFNN\n",
        "인코더와 디코더 내부에서 사용할 코드.</br>\n",
        "이게 PWFFNN</br>\n",
        "outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)</br>\n",
        "outputs = tf.keras.layers.Dense(units=d_model)(outputs)</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwZB1k3Qjysm"
      },
      "source": [
        "# Encoder 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-TiMdK2j_RF"
      },
      "source": [
        "Encoder-layer 구현 및 Encoder 쌓기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M42xumj5ifYl"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 인코더는 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 멀티-헤드 어텐션\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "          'mask': padding_mask # 패딩 마스크\n",
        "      })\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "def encoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용 (인코더)\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 포지셔널 인코딩과 드롭아웃\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # 인코더를 num_layers개 쌓기\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3pieyGPK93i"
      },
      "source": [
        "# **디코더 구현하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjhzvBaNkbW9"
      },
      "source": [
        "Decoder의 first sub-layer : self-attention, look-a-head mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzZcWzqHkjl7",
        "outputId": "1a24b49a-4922-47f7-ba07-f9806de6b107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x) # 패딩 마스크\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)\n",
        "\n",
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxGvBu2PkqI7"
      },
      "source": [
        "Decoder의 second sub-layer : Encoder-Decoder Attention </br>\n",
        "여기서, 인코더의 first - sub layer: Query = Key = Value</br>\n",
        "디코더의 first - sub layer: Query = Key = Value</br>\n",
        "디코더의 Second - sub layer: Query : decoder 행렬 / Key = Value : Encoder 행렬</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id7HGO3ylZ2C"
      },
      "source": [
        "Decoder 구현."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNopJU0Elcbi"
      },
      "outputs": [],
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "\n",
        "  # 룩어헤드 마스크(첫번째 서브층)\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "\n",
        "  # 패딩 마스크(두번째 서브층)\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
        "      })\n",
        "\n",
        "  # 잔차 연결과 층 정규화\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
        "          'mask': padding_mask # 패딩 마스크\n",
        "      })\n",
        "\n",
        "  # 드롭아웃과 잔차 연결과 층 정규화\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC-7yAYKlgKe"
      },
      "source": [
        "디코더 쌓기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "437oJ9bYlhIz"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층)\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 포지셔널 인코딩과 드롭아웃\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # 디코더를 num_layers개 쌓기\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdCptp7pLH0P"
      },
      "source": [
        "# **Transformer 만들기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pIovOV4lqfO"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size, num_layers, dff,\n",
        "                d_model, num_heads, dropout,\n",
        "                name=\"transformer\"):\n",
        "\n",
        "  # 인코더의 입력\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 디코더의 입력\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더의 패딩 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더의 룩어헤드 마스크(1번째 서브층)\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 디코더의 패딩 마스크(2번째 서브층)\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더의 출력은 enc_outputs. 디코더로 전달\n",
        "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력\n",
        "\n",
        "  # 디코더의 출력은 dec_outputs. 출력층으로 전달\n",
        "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 다음 단어 예측을 위한 출력층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXM5bSNJluFY"
      },
      "source": [
        "transformer 하이퍼 파라미터 정하기 / 손실함수 정하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBqcxmgClxK5",
        "outputId": "2210d8d8-c060-49d9-b20b-934bde0dae9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 9000, 512)\n",
            "(1, 9000, 512)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "small_transformer = transformer(\n",
        "    vocab_size = 9000,\n",
        "    num_layers = 4,\n",
        "    dff = 512,\n",
        "    d_model = 512,\n",
        "    num_heads = 4,\n",
        "    dropout = 0.3,\n",
        "    name=\"small_transformer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    small_transformer, to_file='small_transformer.png', show_shapes=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN6jgRmdmFcw"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  assert not np.any(np.isnan(mask))\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfzL5yyamInl"
      },
      "source": [
        "학습률 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iKKzQMOmKNK"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px_Fe3yXmN9S"
      },
      "source": [
        "학습률 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p6xtuZMmO4n",
        "outputId": "5218f5da-c106-4631-e070-4b731169b5ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAERCAYAAABxZrw0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5hU9dnG8e9DZylL7yxL730BwY4NuwiJGmNXNDGJeWME7NjFmKgpFoz11ZhEWASxV+wFFHaX3jssdVnKsu15/5jRbHgpA8zZmZ25P9c1186cOXPO81uH27O/OfMcc3dERCTxVIp1ASIiEgwFvIhIglLAi4gkKAW8iEiCUsCLiCQoBbyISIKKu4A3s2fNLNfMcqK0vRIzmxW+TY3GNkVEKgKLt/Pgzew4YAfworv3iML2drh77SOvTESkYom7I3h3/wTYUnaZmbU3s7fNbKaZfWpmXWJUnohIhRF3Ab8fE4Bfu3t/4PfA44fw2hpmNsPMvjKz84IpT0Qk/lSJdQEHY2a1gSHAq2b2w+Lq4efOB+7ex8vWuPtp4ftt3H2NmbUDPjSzbHdfEnTdIiKxFvcBT+ivjG3u3mfvJ9w9E8g80IvdfU3451Iz+xjoCyjgRSThxf0UjbtvB5aZ2U8ALKR3JK81s/pm9sPRfiPgaGBuYMWKiMSRuAt4M3sF+BLobGarzewq4GLgKjObDcwBzo1wc12BGeHXfQQ86O4KeBFJCnF3mqSIiERH3B3Bi4hIdMTVh6yNGjXy9PT0WJchIlJhzJw5c5O7N97Xc3EV8Onp6cyYMSPWZYiIVBhmtmJ/z2mKRkQkQSngRUQSlAJeRCRBKeBFRBKUAl5EJEEp4EVEEpQCXkQkQSngRURi6NvlW3hyejANbuPqi04iIslix55iHnp7Pi9+uYK0BilcOrgNKdWiG8kKeBGRcjZ94UZuycxmbd5urjg6nd+f2jnq4Q4BB7yZ1QP+DvQAHLjS3b8Mcp8iIvFq685C7nljLpnfraFDk9pMvG4I/dvUD2x/QR/BPwa87e4jzawakBLw/kRE4o6781bOeu6YksO2XUX8emgHfjW0A9WrVA50v4EFvJmlAscBlwO4eyFQGNT+RETiUe72Am6fksM7czbQs2UqL145iG4t6pbLvoM8gm8LbASeC19ibyZwg7vvDHCfIiJxwd15deZq7p02lz3FpYw9vQtXH9OWKpXL7+TFIPdUBegHPOHufYGdwNi9VzKzUWY2w8xmbNy4McByRETKx6otu7jkmW8YPTGLLs3q8tYNx3Ld8e3LNdwh2CP41cBqd/86/Hgi+wh4d58ATADIyMjQ9QNFpMIqKXVe+GI5f3hnAZUrGfec14OLB6ZRqZLFpJ7AAt7d15vZKjPr7O4LgJMAXfBaRBLSog35jJmUxXcrt3FC58bcP7wnLerVjGlNQZ9F82vg5fAZNEuBKwLen4hIuSoqKeXJj5fwlw8XU6t6ZR69oA/n9mmBWWyO2ssKNODdfRaQEeQ+RERiJXt1HjdNnM389fmc1as5487pTqPa1WNd1o/0TVYRkUNUUFTCI+8v5OlPltKodnUmXNKfU7s3i3VZ/48CXkTkEHy9dDNjM7NZtmknFw1szdjTu5Jas2qsy9onBbyISATyC4oY//Z8XvpqJWkNUvjH1YMY0qFRrMs6IAW8iMhBfDQ/l1smZ7NhewFXH9OW353aKZDmYNEW/xWKiMTIlp2F3P36HF6btZaOTWrz+C+G0DctuOZg0aaAFxHZi7szLWsd46bOIW93ETec1JFfntg+8OZg0aaAFxEpY8P2Am6dnMP78zbQq1UqL18ziC7Nyqc5WLQp4EVECB21/+vbVdz35jyKSkq59YyuXHF0ern3j4kmBbyIJL0Vm3dyc2Y2XyzZzFHtGvDg+b1Ib1Qr1mUdMQW8iCStklLnuc+X8fC7C6haqRL3D+/JhQNax6w5WLQp4EUkKS1Yn8/oSVnMXrWNk7o04d7hPWieGtvmYNGmgBeRpFJYXMrjHy/mbx8tpk6Nqjx2YR/O6R0fzcGiTQEvIklj9qptjJ6YxYIN+ZzbpwV3nNWNhnHUHCzaFPAikvB2F5bwp/cW8Mxny2hSpwbPXJbBSV2bxrqswCngRSShfbFkE2MnZbNyyy5+NiiNsad3oW6N+GwOFm0KeBFJSNsLinjgzfm88s1K2jRM4ZVrjmJw+4axLqtcKeBFJOG8P3cDt76Wzcb8PYw6rh3/c3InalarWG0GokEBLyIJY/OOPdz1+lymzl5Ll2Z1mHBJBr1b14t1WTGjgBeRCs/dmTp7LeOmzmHHnmJ+d0onrju+PdWqVNw2A9GggBeRCm1d3m5um5zDB/Nz6dO6Hg+N7EWnpnViXVZcUMCLSIVUWuq88u1KHnhzPiWlzu1ndePyIelUTpA2A9GggBeRCmfZpp2MnZTF18u2cHSHhjwwvBdpDVNiXVbcUcCLSIVRXFLKs58v44/vLqRalUqMH9GTn2a0Tsg2A9EQaMCb2XIgHygBit09I8j9iUjimrduO2MmZZG1Oo9TujXl3vN60LRujViXFdfK4wj+RHffVA77EZEEtKe4hL99uJjHP15Cas2q/PVnfTmzZ3MdtUdAUzQiEre+W7mVMROzWJS7g/P7tuT2s7pRv1a1WJdVYQQd8A68a2YOPOXuEwLen4gkgF2FxTz8zkKe+2IZzevW4LkrBnBi5yaxLqvCCTrgj3H3NWbWBHjPzOa7+ydlVzCzUcAogLS0tIDLEZF49/niTYzNzGLVlt1cclQbRg/rTJ0kaQ4WbYEGvLuvCf/MNbPJwEDgk73WmQBMAMjIyPAg6xGR+JW3u4j735jHv2asom2jWvxr1FEMapdczcGiLbCAN7NaQCV3zw/fPxW4O6j9iUjF9e6c9dz2Wg6bdxZy3fHt+e3JHalRNfmag0VbkEfwTYHJ4U+6qwD/cPe3A9yfiFQwG/P3MO71ObyRtY6uzevyzGUD6NkqNdZlJYzAAt7dlwK9g9q+iFRc7s7k79dw97S57NpTwk2ndWbUce2oWjm5m4NFm06TFJFytWbbbm6dnM3HCzbSLy3UHKxDEzUHC4ICXkTKRWmp8/LXK3jwrfk4MO7sblwyWM3BgqSAF5HALd24g7GTsvlm+RaO7diI+4f3pHUDNQcLmgJeRAJTXFLK058u45H3F1KjSiX+MLIXI/u3UpuBcqKAF5FAzFmbx5hJWeSs2c6w7s24+9zuNFFzsHKlgBeRqCooKuEvHy7iyelLqZ9SjScu7sfpPZvHuqykpIAXkaiZuWILoydmsWTjTkb0a8XtZ3WlXoqag8WKAl5EjtjOPcX84Z0FvPDlclqk1uSFKwdyfKfGsS4r6SngReSIfLJwIzdnZrM2bzeXHtWGm4Z1oXZ1RUs80H8FETks23YVcu8b85g4czXtGtfi1WsHk5HeINZlSRkKeBE5ZG9lr+P2KXPYuquQ609sz6+HqjlYPFLAi0jEcvMLuHPKHN7KWU/3FnV54coBdG+h5mDxSgEvIgfl7kycuZp735jH7qISRg/rzDXHqjlYvFPAi8gBrdqyi1smZ/Ppok0MSK/PgyN60b5x7ViXJRFQwIvIPpWWOi9+uZyH3lmAAXef252fD2pDJTUHqzAU8CLy/yzO3cHYSVnMWLGV4zs15r7hPWhVX83BKhoFvIj8qKiklAmfLOWx9xeRUr0yf/ppb4b3banmYBWUAl5EAMhZk8foiVnMXbedM3s2Z9w53Wlcp3qsy5IjoIAXSXIFRSU89sEiJnyylAa1qvHkz/szrEezWJclUaCAF0li3y7fwpiJWSzdtJOfZrTi1jO6kZpSNdZlSZQo4EWS0I49xTz09nxe/HIFrerX5KWrBnFMx0axLkuiTAEvkmQ+WpDLrZnZrNtewJVHt+XGUztRS83BEpL+q4okia07C7ln2lwyv19Dhya1mXjdEPq3qR/rsiRAgQe8mVUGZgBr3P2soPcnIv/N3Xkzez13Ts1h264ifjO0A9cP7UD1KmoOlugOGvBm1gl4Amjq7j3MrBdwjrvfG+E+bgDmAXUPv0wRORy52wu47bUc3p27gZ4tU3nxykF0a6F/iskikk5BTwM3A0UA7p4FXBjJxs2sFXAm8PfDLVBEDp278+9vV3HSn6YzfeFGbj69C5N/OUThnmQimaJJcfdv9vomW3GE238UGA3UOdTCROTwrNwcag722eJNDGzbgAfP70k7NQdLSpEE/CYzaw84gJmNBNYd7EVmdhaQ6+4zzeyEA6w3ChgFkJaWFknNIrIPJaXO818s5+F3FlC5knHveT342cA0NQdLYpEE/PXABKCLma0BlgEXR/C6o4FzzOwMoAZQ18xecvefl13J3SeEt09GRoYfSvEiErJoQz6jJ2Xx/cptnNi5MfcN70mLejVjXZbEWCQB7+5+spnVAiq5e76ZtY3gRTcTmrsnfAT/+73DXUSOTGFxKU9OX8JfP1xMreqVefSCPpzbp4WagwkQWcBPAvq5+84yyyYC/YMpSUQikbV6G6MnZjF/fT5n927BnWd3o1FtNQeT/9hvwJtZF6A7kGpm55d5qi6hKZeIufvHwMeHUZ+I7GV3YQmPvr+Qpz9dSuM61Xn60gxO6dY01mVJHDrQEXxn4CygHnB2meX5wDVBFiUi+/bV0s2MnZTF8s27uGhga8ae3pXUmmoOJvu234B39ynAFDMb7O5flmNNIrKX/IIiHnxrPi9/vZK0Bin84+pBDOmg5mByYJHMwX9vZtcTmq75cWrG3a8MrCoR+dGH8zdw6+QcNmwv4Opj2nLjqZ2pWU1tBuTgIgn4/wXmA6cBdxM6RXJekEWJCGzZWcjdr8/htVlr6dS0No9fPIS+aWoOJpGLJOA7uPtPzOxcd3/BzP4BfBp0YSLJyt15PWsd46bOIb+giBtO6sj1J3agWpVIOouI/EckAV8U/rnNzHoA64EmwZUkkrzW54Wag70/bwO9W6UyfuQgujRT/xg5PJEE/AQzqw/cBkwFagO3B1qVSJJxd/757Sruf2MeRaWl3HZmV644ui2V1WZAjsBBA97df+gE+QnQDsDM1DRGJEpWbN7J2EnZfLl0M4PbNeTBET1p07BWrMuSBHDAgDezwUBL4BN3zw33gh8LHAu0Lof6RBJWSanz3OfLePjdBVStVIkHzu/JhQNaq82ARM2Bvsn6B0JfdJoFjDGzd4CrgQcAnSIpcgQWrA81B5u9ahsnd23Cvef1pFnqIX1BXOSgDnQEfybQ190LwnPwq4Ae7r68XCoTSUCFxaX87aPFPP7xYurUqMqfL+rL2b2a66hdAnGggC9w9wIAd99qZosU7iKHb9aqbYyeOJuFG3Zwbp8W3Hl2dxrUqhbrsiSBHSjg25nZ1DKP25Z97O7nBFeWSOLYXVjCH99dwLOfL6NJnRo8c1kGJ3VVczAJ3oEC/ty9Hv8xyEJEEtEXSzYxdlI2K7fs4uJBaYw9vQt1aqg5mJSPAzUbm16ehYgkku0FRTzw5jxe+WYV6Q1T+OeooziqXcNYlyVJJpIvOonIIXh/7gZufS2bjfl7uPa4dvz25E5qDiYxoYAXiZJNO/Zw1+tzeX32Wro0q8PTl2bQq1W9WJclSUwBL3KE3J0ps9Zy1+tz2LGnmN+d0onrjm+v5mAScwcNeDN7HfC9FucBM4CnfjiVUiQZrd22m9tey+HD+bn0TavH+BG96NS0TqzLEgEiO4JfCjQGXgk/voDQZfs6AU8DlwRTmkj8Ki11/vHNSh58az4lpc4dZ3XjsiHpag4mcSWSgB/i7gPKPH7dzL519wFmNieowkTi1bJNOxk7KYuvl23h6A4NeWB4L9IapsS6LJH/J5KAr21mae6+En7sJFk7/FxhYJWJxJniklKe+WwZf3pvIdWqVOKhEb34SUYrtRmQuBVJwN8IfGZmSwAD2gK/NLNawAtBFicSL+au3c6YSVlkr8njlG5Nufe8HjStq+ZgEt8i6Qf/ppl1BLqEFy0o88Hqo4FVJhIH9hSX8NcPF/PEx0uol1KVv/2sH2f0bKajdqkQIj1Nsj+QHl6/t5nh7i8e6AVmVoPQRUKqh1830d3vPIJaRcrVzBVbGTMpi8W5Ozi/X0tuP7Mb9dUcTCqQSE6T/F+gPaG+8CXhxQ4cMOCBPcBQd99hZlUJTfO85e5fHUnBIkHbVVjMH95ZwPNfLKd53Ro8d8UATuysyxBLxRPJEXwG0M3d9z4X/oDC6+8IP6wavh3SNkTK22eLNjE2M4vVW3dz6eA2jB7WhdrV9X1AqZgieefmAM2AdYe6cTOrDMwEOgB/c/ev97HOKGAUQFqaLvUqsZG3q4j73pzLv2espm2jWvz72sEMbNsg1mWJHJFIAr4RMNfMviE07QJE1g/e3UuAPmZWD5hsZj3cPWevdSYAEwAyMjJ0hC/l7u2c9dw+JYctOwv5xQntueGkjtSoquZgUvFFEvDjjnQn7r7NzD4ChhH6i0Ak5jbm72Hc1Dm8kb2Obs3r8tzlA+jRMjXWZYlETSSnSR5WX3gzawwUhcO9JnAKMP5wtiUSTe5O5ndruHvaXHYXlnDTaZ0ZdVw7qlZWczBJLPsNeDP7zN2PMbN8/vvDUSP0GWrdg2y7OfBCeB6+EvBvd592xBWLHIE123ZzS2Y20xdupH+b+owf0YsOTWof/IUiFdCBruh0TPjnYbXGc/csoO9h1iUSVaWlzktfr2D8W/NxYNzZ3bh0cDqV1BxMElhE53+Fj8Kbll3/h940IvFuycYdjJ2UxbfLt3Jsx0bcP7wnrRuoOZgkvki+6PRr4E5gA1AaXuxArwDrEjliRSWlPP3pUh59fxE1qlTiDyN7MbK/moNJ8ojkCP4GoLO7bw66GJFoyVmTx5hJWcxZu53TezTjrnO706SOmoNJcokk4FcRuoKTSNwrKCrhLx8u4snpS6mfUo0nLu7H6T2bx7oskZiI9IpOH5vZG/z3F53+FFhVIodhxvItjJ6UxdKNOxnZvxW3ndmVeilqDibJK5KAXxm+VQvfROLKzj2h5mAvfLmcFqk1efHKgRzXqXGsyxKJuQMGfPjsmU7ufnE51SNySKYv3MgtmdmszdvNZYPTuem0ztRSczAR4CAB7+4lZtbGzKq5uy7PJ3Fj265C7pk2j0nfraZ941q8eu1gMtLVHEykrEjn4D83s6nAzh8Wag5eYuWt7HXcPmUOW3cV8qsTO/CroR3UHExkHyIJ+CXhWyXgsL7VKhINudsLuGPKHN6es57uLerywpUD6N5CzcFE9ieSZmN3lUchIvvj7kycuZp7ps2loLiUMcO6cM2xbami5mAiBxTJN1kbA6OB7sCP3xRx96EB1iUCwKotu7hlcjafLtrEgPT6PDiiF+0bqzmYSCQimaJ5GfgXcBZwHXAZsDHIokRKSp0Xv1zOH95ZgAH3nNudiwe1UXMwkUMQScA3dPdnzOyGcG/46Wb2bdCFSfJanJvPmEnZzFyxleM7Neb+83vSsl7NWJclUuFEEvBF4Z/rzOxMYC2g89Ek6opKSnlq+hL+/MFiUqpX5k8/7c3wvi3VHEzkMEUS8PeaWSpwI/AXoC7wP4FWJUknZ00eN03MYt667ZzZqznjzu5O4zrVY12WSIUWyVk0P1yFKQ84MdhyJNkUFJXw6PuLePrTpTSoVY2nLunPad2bxboskYQQyVk0nYAngKbu3sPMegHnuPu9gVcnCe3rpZsZm5nNsk07uSCjNbec0ZXUlKqxLkskYURyIvHTwM2E5+LDl+K7MMiiJLHlFxRx+2s5XDDhK4pKSnnpqkGMH9lL4S4SZZHMwae4+zd7fdBVHFA9kuA+WpDLrZnZrNtewJVHt+X3p3UipZqag4kEIZJ/WZvMrD2hy/RhZiOBdYFWJQln685C7pk2l8zv19CxSW0m/WII/dLqx7oskYQWScBfD0wAupjZGmAZoPbBEhF3543sddw5ZQ55u4v4zdAOXD+0A9WrqDmYSNAiOYtmKXCymdUCKrl7vpn9Fng08OqkQtuwvYDbXsvhvbkb6NkylZeuHkTX5nVjXZZI0oh48tPdd5Z5+DsOEvBm1hp4EWhKaHpngrs/djhFSsXi7vx7xirufWMehcWl3Hx6F646Rs3BRMrb4X66FclXC4uBG939OzOrA8w0s/fcfe5h7lMqgJWbdzE2M4svlmxmYNsGjB/Ri7aNasW6LJGkdLgB7wddwX0d4Q9jw9M684CWgAI+AZWUOs9/sZyH31lA5UrGfcN7cNGANDUHE4mh/Qa8meWz7yA34JA6P5lZOtAX+Hofz40CRgGkpaUdymYlTizckM/oiVnMWrWNoV2acN/wHjRPVXMwkVjbb8C7e1Su3mRmtYFJwG/dffs+9jOB0Fk6ZGRkHPQvA4kfhcWlPDl9CX/5cBG1q1fhsQv7cE7vFmoOJhInAv2GiZlVJRTuL7t7ZpD7kvI1e9U2xkzKYv76fM7u3YJxZ3ejYW01BxOJJ4EFvIUO454B5ukC3Yljd2EJj7y/kL9/upTGdarz9KUZnNKtaazLEpF9CPII/mjgEiDbzGaFl93i7m8GuE8J0JdLNnNzZhbLN+/iooFp3HxGF+rWUP8YkXgVWMC7+2dEdjqlxLntBUU8+NZ8/vH1Sto0TOEf1wxiSPtGsS5LRA5CXZ7kgD6cv4FbMnPIzS/gmmPb8rtTOlOzmtoMiFQECnjZp8079nD3tLlMmbWWzk3r8OQl/enTul6syxKRQ6CAl//i7kydvZa7Xp9LfkERvz25I788oQPVqqjNgEhFo4CXH63L281tk3P4YH4uvVvX46ERvejcLCpfhxCRGFDAC6Wlzj+/XcUDb86jqLSU287syhVHt6Wy2gyIVGgK+CS3fNNOxmZm8dXSLQxu15AHR/SkTUM1BxNJBAr4JFVS6jz72TL++N4CqlaqxIPn9+SCAa3VZkAkgSjgk9D89dsZMzGL2avzOLlrE+49ryfNUmvEuiwRiTIFfBLZU1zC3z5awuMfLSa1ZlX+clFfzurVXEftIglKAZ8kvl+5lTGTsli4YQfn9WnBHWd3p0GtarEuS0QCpIBPcLsKi/njuwt59vNlNKtbg2cvz2BoFzUHE0kGCvgE9sXiTYzNzGblll38/Kg0xgzrQh01BxNJGgr4BJS3u4gH3pzHP79dRXrDFP456iiOatcw1mWJSDlTwCeYd+es57bXcti0Yw/XHt+O/zm5EzWqqjmYSDJSwCeITTv2MG7qHKZlraNLszr8/bIMerVSczCRZKaAr+DcnddmreGu1+eya08JN57SiWuPb6/mYCKigK/I1m7bza2Ts/lowUb6poWag3VsquZgIhKigK+ASkudl79Zyfi35lNS6txxVjcuG5Ku5mAi8l8U8BXM0o07GJuZzTfLtnBMh0Y8cH5PWjdIiXVZIhKHFPAVRHFJKX//bBmPvLeQalUq8dCIXvwko5XaDIjIfingK4C5a7czetJsctZs59RuTbnnvB40ravmYCJyYAr4OLanuIS/friYJz5eQr2Uqjx+cT9O79FMR+0iEhEFfJyauSLUHGxx7g7O79eS28/sRn01BxORQxBYwJvZs8BZQK679whqP4lm555iHn53Ac9/sZwWqTV5/ooBnNC5SazLEpEKKMgj+OeBvwIvBriPhPLpoo3cnJnN6q27uXRwG0YP60Lt6vojS0QOT2Dp4e6fmFl6UNtPJHm7irj3jbm8OnM17RrV4t/XDmZg2waxLktEKriYHx6a2ShgFEBaWlqMqyl/b+es5/YpOWzZWcgvTmjPDSd1VHMwEYmKmAe8u08AJgBkZGR4jMspN7n5BYybOoc3s9fTrXldnrt8AD1apsa6LBFJIDEP+GTj7mR+t4a7p81ld1EJN53WmVHHtaNqZTUHE5HoUsCXo9Vbd3HL5Bw+WbiR/m3qM35ELzo0qR3rskQkQQV5muQrwAlAIzNbDdzp7s8Etb94Vlrq/O9XKxj/9nwA7jqnO5cc1YZKag4mIgEK8iyai4LadkWyZOMOxkzMYsaKrRzbsRH3D1dzMBEpH5qiCUhRSSkTPlnKYx8sombVyjz8k96M6NdSbQZEpNwo4AOQsyaPMZOymLN2O2f0bMa4c7rTpI6ag4lI+VLAR1FBUQl//mART32ylPop1Xjy5/0Y1qN5rMsSkSSlgI+Sb5dvYcykLJZu3MlP+rfitjO7kZpSNdZliUgSU8AfoR17inno7fm8+OUKWtaryYtXDuS4To1jXZaIiAL+SExfuJFbMrNZm7eby4ekc9Npnaml5mAiEieURodh265C7p42l8zv1tC+cS1evXYwGelqDiYi8UUBf4jezF7HHVNy2LariF+d2IFfDe2g5mAiEpcU8BHK3V7A7VNyeGfOBnq0rMsLVw6kews1BxOR+KWAPwh359WZq7l32lwKiksZM6wL1xzblipqDiYicU4BfwCrtuzi5sxsPlu8iYHpDXhwRE/aNVZzMBGpGBTw+1BS6rz45XIeensBlQzuObc7Fw9SczARqVgU8HtZnJvP6IlZfLdyGyd0bsx9w3vSsl7NWJclInLIFPBhRSWlPDV9CX/+YDEp1SvzyAW9Oa+PmoOJSMWlgAeyV+dx08TZzF+fz5m9mnPXOd1pVLt6rMsSETkiSR3wBUUlPPL+Qp7+ZCmNalfnqUv6c1r3ZrEuS0QkKpI24L9eupmxmdks27STCzJac8uZXUmtqeZgIpI4ki7g8wuKGP/2fF76aiWtG9Tk5asHcXSHRrEuS0Qk6pIq4D+an8utk7NZt72Aq45py42ndiKlWlL9CkQkiSRFum3ZWcg90+Yy+fs1dGxSm0m/GEK/tPqxLktEJFAJHfDuzrSsdYybOoe83UX85qSOXH9ie6pXUXMwEUl8CRvwG7YXcOvkHN6ft4FerVJ56epBdG1eN9ZliYiUm4QLeHfnX9+u4r4351FYXMotZ3ThyqPVHExEkk+gAW9mw4DHgMrA3939wSD3t3LzLsZmZvHFks0MatuA8SN6kd6oVpC7FBGJW4EFvJlVBv4GnAKsBr41s6nuPjfa+yopdZ77fBkPv7uAKpUqcd/wHlw0IE3NwUQkqQV5BD8QWOzuSwHM7J/AuUBUAz5vVxGXPfcNs1R9SZkAAAb1SURBVFZtY2iXJtw3vAfNU9UcTEQkyIBvCawq83g1MGjvlcxsFDAKIC0t7ZB3UrdmFdo0TOGKo9M5p3cLNQcTEQmL+Yes7j4BmACQkZHhh/p6M+OxC/tGvS4RkYouyFNL1gCtyzxuFV4mIiLlIMiA/xboaGZtzawacCEwNcD9iYhIGYFN0bh7sZn9CniH0GmSz7r7nKD2JyIi/y3QOXh3fxN4M8h9iIjIvunrnSIiCUoBLyKSoBTwIiIJSgEvIpKgzP2Qv1sUGDPbCKw4zJc3AjZFsZyKQGNODhpzcjjcMbdx98b7eiKuAv5ImNkMd8+IdR3lSWNODhpzcghizJqiERFJUAp4EZEElUgBPyHWBcSAxpwcNObkEPUxJ8wcvIiI/LdEOoIXEZEyFPAiIgmqwge8mQ0zswVmttjMxsa6nmgxs2fNLNfMcsosa2Bm75nZovDP+uHlZmZ/Dv8OssysX+wqP3xm1trMPjKzuWY2x8xuCC9P2HGbWQ0z+8bMZofHfFd4eVsz+zo8tn+FW25jZtXDjxeHn0+PZf1Hwswqm9n3ZjYt/Dihx2xmy80s28xmmdmM8LJA39sVOuDLXNj7dKAbcJGZdYttVVHzPDBsr2VjgQ/cvSPwQfgxhMbfMXwbBTxRTjVGWzFwo7t3A44Crg//90zkce8Bhrp7b6APMMzMjgLGA4+4ewdgK3BVeP2rgK3h5Y+E16uobgDmlXmcDGM+0d37lDnfPdj3trtX2BswGHinzOObgZtjXVcUx5cO5JR5vABoHr7fHFgQvv8UcNG+1qvIN2AKcEqyjBtIAb4jdO3iTUCV8PIf3+eErq8wOHy/Sng9i3XthzHWVuFAGwpMAywJxrwcaLTXskDf2xX6CJ59X9i7ZYxqKQ9N3X1d+P56oGn4fsL9HsJ/hvcFvibBxx2eqpgF5ALvAUuAbe5eHF6l7Lh+HHP4+TygYflWHBWPAqOB0vDjhiT+mB1418xmmtmo8LJA39sxv+i2HB53dzNLyHNczaw2MAn4rbtvN7Mfn0vEcbt7CdDHzOoBk4EuMS4pUGZ2FpDr7jPN7IRY11OOjnH3NWbWBHjPzOaXfTKI93ZFP4JPtgt7bzCz5gDhn7nh5QnzezCzqoTC/WV3zwwvTvhxA7j7NuAjQtMT9czshwOwsuP6cczh51OBzeVc6pE6GjjHzJYD/yQ0TfMYiT1m3H1N+Gcuof+RDyTg93ZFD/hku7D3VOCy8P3LCM1R/7D80vAn70cBeWX+7KswLHSo/gwwz93/VOaphB23mTUOH7ljZjUJfeYwj1DQjwyvtveYf/hdjAQ+9PAkbUXh7je7eyt3Tyf0b/ZDd7+YBB6zmdUyszo/3AdOBXII+r0d6w8eovDBxRnAQkLzlrfGup4ojusVYB1QRGj+7SpC844fAIuA94EG4XWN0NlES4BsICPW9R/mmI8hNE+ZBcwK385I5HEDvYDvw2POAe4IL28HfAMsBl4FqoeX1wg/Xhx+vl2sx3CE4z8BmJboYw6PbXb4NueHrAr6va1WBSIiCaqiT9GIiMh+KOBFRBKUAl5EJEEp4EVEEpQCXkQkQSngpcIzs4bhDn2zzGy9ma0p87jaQV6bYWZ/PsT9XRnuCphlZjlmdm54+eVm1uJIxiISTTpNUhKKmY0Ddrj7w2WWVfH/9Dg50u23AqYD/dw9L9xWobG7LzOzj4Hfu/uMaOxL5EjpCF4Skpk9b2ZPmtnXwENmNtDMvgz3H//CzDqH1zuhTD/ycRbqw/+xmS01s9/sY9NNgHxgB4C77wiH+0ggA3g5/JdDTTPrb2bTw82l3inzlfSPzeyx8Ho5ZjawPH4nknwU8JLIWgFD3P13wHzgWHfvC9wB3L+f13QBTiPUJ+TOcG+csmYDG4BlZvacmZ0N4O4TgRnAxe7eh1Bv+78AI929P/AscF+Z7aSE1/tl+DmRqFM3SUlkr3qoUyOEGlS9YGYdCbVD2Du4f/CGu+8B9phZLqH2rat/eNLdS8xsGDAAOAl4xMz6u/u4vbbTGehBqGsgQGVCrSd+8Ep4e5+YWV0zq+ehZmMiUaOAl0S2s8z9e4CP3H14uNf8x/t5zZ4y90vYx78RD31w9Q3wjZm9BzwHjNtrNQPmuPvg/exn7w+/9GGYRJ2maCRZpPKfdquXH+5GzKzFXtfH7AOsCN/PB+qE7y8AGpvZ4PDrqppZ9zKvuyC8/BhCnQLzDrcmkf3REbwki4cITdHcBrxxBNupCjwcPh2yANgIXBd+7nngSTPbTain+0jgz2aWSujf2qOEOgkCFJjZ9+HtXXkE9Yjsl06TFClnOp1SyoumaEREEpSO4EVEEpSO4EVEEpQCXkQkQSngRUQSlAJeRCRBKeBFRBLU/wHuQfxxGOlMowAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=1024)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(500, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN1P1M3HmbXm"
      },
      "source": [
        "# ** 입력 -> 출력물 결과보기** -> 위에서는 Transformer를 만들어본 것."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "TbCp28Wsmi-L",
        "outputId": "060b127d-c888-4601-c042-ef9168c40203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.125.160.154:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.125.160.154:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Q  \\\n",
              "0  UNKNOWN MESSAGE Please choose the Technical Su...   \n",
              "1  UNKNOWN MESSAGE Please choose the Technical Su...   \n",
              "2  UNKNOWN MESSAGE Please choose the Technical Su...   \n",
              "3  OF_MINE MESSAGE Please choose the Technical Sp...   \n",
              "4  GOD_IS MESSAGE Anyone_wishing choose the Techn...   \n",
              "\n",
              "                                                   A  \n",
              "0  알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...  \n",
              "1  알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...  \n",
              "2  알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...  \n",
              "3  알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...  \n",
              "4  알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f926f400-3448-4b77-bdf8-05cf4b135636\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UNKNOWN MESSAGE Please choose the Technical Su...</td>\n",
              "      <td>알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UNKNOWN MESSAGE Please choose the Technical Su...</td>\n",
              "      <td>알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UNKNOWN MESSAGE Please choose the Technical Su...</td>\n",
              "      <td>알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OF_MINE MESSAGE Please choose the Technical Sp...</td>\n",
              "      <td>알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GOD_IS MESSAGE Anyone_wishing choose the Techn...</td>\n",
              "      <td>알 수 없는 메시지. 자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f926f400-3448-4b77-bdf8-05cf4b135636')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f926f400-3448-4b77-bdf8-05cf4b135636 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f926f400-3448-4b77-bdf8-05cf4b135636');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "import time\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import os\n",
        "# 아래부분은 tpu 사용시에만 쓰길 바람\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "#\n",
        "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/eda.csv') # , encoding='CP949'\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLF_siJGm29n",
        "outputId": "da869869-6720-48de-af10-9d13d8252d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 샘플의 개수 : 11224\n",
            "Q    0\n",
            "A    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('데이터 샘플의 개수 :', len(train_data))\n",
        "print(train_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQgWlPG8nBZw"
      },
      "source": [
        "질문 데이터와 답변 데이터의 preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7TwrB9AnHKA",
        "outputId": "f1a05dcb-427e-49bd-deff-fc3788cc5ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['UNKNOWN MESSAGE Please choose the Technical Support command on the Visual C++ Help menu ,  or open the Technical Support help file for more information', 'UNKNOWN MESSAGE Please choose the Technical Support command on the Multisensory C + + Help entrees ,  or open the Technical Support help file for more information', 'UNKNOWN MESSAGE Please choose the Technical Support command on the Visual Polyzene_® + + Help menu ,  or open the Technical Support help file for more info', 'OF_MINE MESSAGE Please choose the Technical Sponsors_Sunbelt_Software command on the Visual C + + Help menu ,  or open the Technical Support help file for more information', 'GOD_IS MESSAGE Anyone_wishing choose the Technical Support command on the Visual C + + Help menu ,  or open the Technical Support help file for more information']\n",
            "['알 수 없는 메시지 .  자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 [기술 지원] 명령을 선택하거나 기술 지원 도움말 파일을 참조하세요 .', '알 수 없는 메시지 .  자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 [기술 지원] 명령을 선택하거나 기술 지원 도움말 파일을 참조하세요 .', '알 수 없는 메시지 .  자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 [기술 지원] 명령을 선택하거나 기술 지원 도움말 파일을 참조하세요 .', '알 수 없는 메시지 .  자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 [기술 지원] 명령을 선택하거나 기술 지원 도움말 파일을 참조하세요 .', '알 수 없는 메시지 .  자세한 내용을 보려면 Visual C++ [도움말] 메뉴에서 [기술 지원] 명령을 선택하거나 기술 지원 도움말 파일을 참조하세요 .']\n"
          ]
        }
      ],
      "source": [
        "questions = []\n",
        "for sentence in train_data['Q']:\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", str(sentence))     # 구두점에 대해서 띄어쓰기\n",
        "    sentence = sentence.strip()\n",
        "    questions.append(sentence)\n",
        "\n",
        "answers = []\n",
        "for sentence in train_data['A']:\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", str(sentence))     # 구두점에 대해서 띄어쓰기\n",
        "    sentence = sentence.strip()\n",
        "    answers.append(sentence)\n",
        "\n",
        "print(questions[:5])\n",
        "print(answers[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi6rHX58nW4O"
      },
      "source": [
        "단어 집함 생성 -> 서브워드 토크나이저에서 서브워드텍스트인코더 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGJR1TSanb-L",
        "outputId": "e59e51ee-ed5d-41f0-b6f8-534675a62d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시작 토큰 번호 : [8833]\n",
            "종료 토큰 번호 : [8834]\n",
            "단어 집합의 크기 : 8835\n"
          ]
        }
      ],
      "source": [
        "# 서브워드 텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)\n",
        "\n",
        "# 시작 토큰과 종료 토큰 정수 부여\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기 + 2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "\n",
        "print('시작 토큰 번호 :',START_TOKEN)\n",
        "print('종료 토큰 번호 :',END_TOKEN)\n",
        "print('단어 집합의 크기 :',VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdaFu7Uinrow"
      },
      "source": [
        "정수 encoding과 padding</br>\n",
        "# 샘플 하나로 정수 인코딩, 디코딩 수행 (test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z8kCXFCntvO",
        "outputId": "85cb6a0c-511d-4af2-8a0d-2956337d54be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임의의 질문 샘플을 정수 인코딩 : [615, 963, 8622, 171, 8622, 256, 424]\n",
            "정수 인코딩 후의 문장 [615, 963, 8622, 171, 8622, 256, 424]\n",
            "기존 문장: unexpected end-of-file found\n",
            "615 ----> unexpected \n",
            "963 ----> end\n",
            "8622 ----> -\n",
            "171 ----> of\n",
            "8622 ----> -\n",
            "256 ----> file \n",
            "424 ----> found\n"
          ]
        }
      ],
      "source": [
        "# 샘플 하나로 정수 인코딩, 디코딩 수행\n",
        "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))\n",
        "\n",
        "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
        "sample_string = questions[20]\n",
        "\n",
        "# encode() : 텍스트 시퀀스 -> 정수 시퀀스\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# decode() : 정수 시퀀스 -> 텍스트 시퀀스\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))\n",
        "\n",
        "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOraa2YqoFM1",
        "outputId": "304222d6-53f7-4799-ca14-07745a1d71eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문 데이터의 크기(shape) : (11224, 90)\n",
            "답변 데이터의 크기(shape) : (11224, 90)\n"
          ]
        }
      ],
      "source": [
        "# 최대 길이를 90으로 정의\n",
        "MAX_LENGTH = 90\n",
        "\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print('질문 데이터의 크기(shape) :', questions.shape)\n",
        "print('답변 데이터의 크기(shape) :', answers.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJwsrYpIoT6A"
      },
      "source": [
        "임의의 0번 test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuW22ar5oWt1",
        "outputId": "0c5bbf94-3922-4dc0-9213-bfcdf95f5f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8833 2389 8296 1419 1859   41  852  853  488  121   41  851 8644  966\n",
            " 1884 1743   62   33  685   41  852  853 1643  256   27  487  700 8834\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "[8833  332    6  192 2941   53 1564 1606 2918  851 8644 3351 2950  270\n",
            " 2942  131  810 2825  270 1597 2036  810 1011 1045  260 2815    1 8834\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# 0번 샘플을 임의로 출력\n",
        "print(questions[0])\n",
        "print(answers[0])\n",
        "for i in questions:\n",
        "  if 0 not in i:\n",
        "    print(i)\n",
        "for j in answers:\n",
        "  if 0 not in j:\n",
        "    print(j)\n",
        "\n",
        "# 길이가 90을 맞추기 위해 0이 패딩됨."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovw3jrzyoerp"
      },
      "source": [
        "인코더와 디코더 입력, 레이블 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdnnXKHeoh5y",
        "outputId": "702549fd-a1f2-418a-e27e-802616b78871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<TensorSliceDataset element_spec=({'inputs': TensorSpec(shape=(90,), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(89,), dtype=tf.int32, name=None)}, {'outputs': TensorSpec(shape=(89,), dtype=tf.int32, name=None)})>\n",
            "[8833  332    6  192 2941   53 1564 1606 2918  851 8644 3351 2950  270\n",
            " 2942  131  810 2825  270 1597 2036  810 1011 1045  260 2815    1 8834\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "[[8833  332    6  192 2941   53 1564 1606 2918  851 8644 3351 2950  270\n",
            "  2942  131  810 2825  270 1597 2036  810 1011 1045  260 2815    1 8834\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0]]\n",
            "[[ 332    6  192 2941   53 1564 1606 2918  851 8644 3351 2950  270 2942\n",
            "   131  810 2825  270 1597 2036  810 1011 1045  260 2815    1 8834    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0]]\n"
          ]
        }
      ],
      "source": [
        "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
        "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
        "    },\n",
        "))\n",
        "print(dataset)\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
        "print(answers[0]) # 기존 샘플\n",
        "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
        "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRR2LceMooFI"
      },
      "source": [
        "# **Transformer 사용하기**\n",
        "하이퍼 파라미터 값 순서대로: 256, 2, 8, 512로 설정</br>\n",
        "학습률과 옵티마이저 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J65OTOER_KPA",
        "outputId": "ce024e97-3cc0-4650-8393-8f4327940dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8835, 512)\n",
            "(1, 8835, 512)\n",
            "Epoch 1/500\n",
            "176/176 [==============================] - 169s 387ms/step - loss: 0.9366 - accuracy: 0.0123\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.6740 - accuracy: 0.0261\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.5093 - accuracy: 0.0422\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.3629 - accuracy: 0.0599\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.2565 - accuracy: 0.0759\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.1769 - accuracy: 0.0887\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.1538 - accuracy: 0.0912\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.1107 - accuracy: 0.0978\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0993 - accuracy: 0.1001\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0752 - accuracy: 0.1042\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0833 - accuracy: 0.1037\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0634 - accuracy: 0.1060\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 15s 84ms/step - loss: 0.1153 - accuracy: 0.0996\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 15s 84ms/step - loss: 0.0768 - accuracy: 0.1043\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0748 - accuracy: 0.1045\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0887 - accuracy: 0.1028\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 15s 84ms/step - loss: 0.0898 - accuracy: 0.1014\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 15s 84ms/step - loss: 0.0759 - accuracy: 0.1039\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0833 - accuracy: 0.1021\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.1023 - accuracy: 0.1000\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 15s 84ms/step - loss: 0.1196 - accuracy: 0.0976\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 15s 84ms/step - loss: 0.0843 - accuracy: 0.1011\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 15s 84ms/step - loss: 0.0754 - accuracy: 0.1030\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 16s 92ms/step - loss: 0.0654 - accuracy: 0.1048\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.0262 - accuracy: 0.1127\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 16s 92ms/step - loss: 0.0505 - accuracy: 0.1080\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0480 - accuracy: 0.1094\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0221 - accuracy: 0.1138\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0364 - accuracy: 0.1122\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0191 - accuracy: 0.1147\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 15s 84ms/step - loss: 0.0257 - accuracy: 0.1135\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0152 - accuracy: 0.1159\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0176 - accuracy: 0.1157\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0128 - accuracy: 0.1167\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0114 - accuracy: 0.1170\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0139 - accuracy: 0.1165\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 15s 84ms/step - loss: 0.0122 - accuracy: 0.1170\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0105 - accuracy: 0.1174\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0089 - accuracy: 0.1178\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0106 - accuracy: 0.1175\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0106 - accuracy: 0.1174\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0112 - accuracy: 0.1175\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0073 - accuracy: 0.1182\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0070 - accuracy: 0.1184\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0070 - accuracy: 0.1184\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0068 - accuracy: 0.1184\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0066 - accuracy: 0.1185\n",
            "Epoch 48/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0051 - accuracy: 0.1189\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0076 - accuracy: 0.1183\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0046 - accuracy: 0.1190\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0053 - accuracy: 0.1188\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0051 - accuracy: 0.1189\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0049 - accuracy: 0.1189\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 16s 91ms/step - loss: 0.0041 - accuracy: 0.1192\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 17s 95ms/step - loss: 0.0048 - accuracy: 0.1191\n",
            "Epoch 56/500\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.0041 - accuracy: 0.1192\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0047 - accuracy: 0.1191\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0036 - accuracy: 0.1193\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0039 - accuracy: 0.1193\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0035 - accuracy: 0.1193\n",
            "Epoch 61/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0037 - accuracy: 0.1193\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0030 - accuracy: 0.1195\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 0.0036 - accuracy: 0.1193\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0033 - accuracy: 0.1194\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0033 - accuracy: 0.1194\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0027 - accuracy: 0.1196\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0030 - accuracy: 0.1195\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0028 - accuracy: 0.1195\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0028 - accuracy: 0.1196\n",
            "Epoch 70/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0027 - accuracy: 0.1195\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0030 - accuracy: 0.1195\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0027 - accuracy: 0.1196\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0023 - accuracy: 0.1197\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0028 - accuracy: 0.1196\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0035 - accuracy: 0.1194\n",
            "Epoch 76/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 0.0021 - accuracy: 0.1197\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0025 - accuracy: 0.1196\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0024 - accuracy: 0.1196\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0021 - accuracy: 0.1198\n",
            "Epoch 80/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0022 - accuracy: 0.1198\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0021 - accuracy: 0.1197\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0016 - accuracy: 0.1198\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 18s 100ms/step - loss: 0.0037 - accuracy: 0.1195\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 0.0020 - accuracy: 0.1198\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 16s 92ms/step - loss: 0.0021 - accuracy: 0.1198\n",
            "Epoch 86/500\n",
            "176/176 [==============================] - 17s 94ms/step - loss: 0.0019 - accuracy: 0.1198\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0018 - accuracy: 0.1198\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0022 - accuracy: 0.1197\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0019 - accuracy: 0.1198\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0018 - accuracy: 0.1199\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0018 - accuracy: 0.1198\n",
            "Epoch 92/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0020 - accuracy: 0.1198\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0019 - accuracy: 0.1198\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0017 - accuracy: 0.1199\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0016 - accuracy: 0.1199\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0015 - accuracy: 0.1199\n",
            "Epoch 97/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0017 - accuracy: 0.1198\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0016 - accuracy: 0.1199\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0016 - accuracy: 0.1199\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0017 - accuracy: 0.1199\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0015 - accuracy: 0.1199\n",
            "Epoch 102/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0014 - accuracy: 0.1199\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0015 - accuracy: 0.1199\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0015 - accuracy: 0.1199\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0016 - accuracy: 0.1199\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0013 - accuracy: 0.1200\n",
            "Epoch 107/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0015 - accuracy: 0.1199\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0012 - accuracy: 0.1200\n",
            "Epoch 109/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0011 - accuracy: 0.1200\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0014 - accuracy: 0.1200\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 16s 93ms/step - loss: 0.0014 - accuracy: 0.1200\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 0.0013 - accuracy: 0.1200\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 9.8342e-04 - accuracy: 0.1200\n",
            "Epoch 114/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0012 - accuracy: 0.1200\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0012 - accuracy: 0.1200\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0020 - accuracy: 0.1198\n",
            "Epoch 117/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0012 - accuracy: 0.1200\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 0.0011 - accuracy: 0.1200\n",
            "Epoch 119/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0011 - accuracy: 0.1200\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0012 - accuracy: 0.1200\n",
            "Epoch 121/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 8.8140e-04 - accuracy: 0.1201\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0014 - accuracy: 0.1200\n",
            "Epoch 123/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0010 - accuracy: 0.1201\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0011 - accuracy: 0.1200\n",
            "Epoch 125/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 8.9945e-04 - accuracy: 0.1201\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0016 - accuracy: 0.1200\n",
            "Epoch 127/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 8.8922e-04 - accuracy: 0.1201\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 0.0011 - accuracy: 0.1200\n",
            "Epoch 129/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 8.4355e-04 - accuracy: 0.1201\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0010 - accuracy: 0.1200\n",
            "Epoch 131/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 9.3213e-04 - accuracy: 0.1201\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 0.0010 - accuracy: 0.1200\n",
            "Epoch 133/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 9.1152e-04 - accuracy: 0.1200\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 7.8525e-04 - accuracy: 0.1201\n",
            "Epoch 135/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 9.6271e-04 - accuracy: 0.1201\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 9.9250e-04 - accuracy: 0.1200\n",
            "Epoch 137/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 8.7629e-04 - accuracy: 0.1201\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0011 - accuracy: 0.1201\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 9.2498e-04 - accuracy: 0.1201\n",
            "Epoch 140/500\n",
            "176/176 [==============================] - 17s 96ms/step - loss: 8.6400e-04 - accuracy: 0.1201\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 16s 93ms/step - loss: 8.3461e-04 - accuracy: 0.1201\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 8.2810e-04 - accuracy: 0.1201\n",
            "Epoch 143/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 9.0210e-04 - accuracy: 0.1201\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 16s 93ms/step - loss: 8.8963e-04 - accuracy: 0.1201\n",
            "Epoch 145/500\n",
            "176/176 [==============================] - 17s 98ms/step - loss: 9.4954e-04 - accuracy: 0.1201\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 8.4880e-04 - accuracy: 0.1201\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 8.9463e-04 - accuracy: 0.1201\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 8.5096e-04 - accuracy: 0.1201\n",
            "Epoch 149/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 7.3210e-04 - accuracy: 0.1201\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0012 - accuracy: 0.1200\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 0.0011 - accuracy: 0.1201\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 7.3034e-04 - accuracy: 0.1201\n",
            "Epoch 153/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 9.4580e-04 - accuracy: 0.1200\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0010 - accuracy: 0.1200\n",
            "Epoch 155/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 0.0011 - accuracy: 0.1200\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.3182e-04 - accuracy: 0.1202\n",
            "Epoch 157/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 9.1303e-04 - accuracy: 0.1201\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 8.4211e-04 - accuracy: 0.1201\n",
            "Epoch 159/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 9.4992e-04 - accuracy: 0.1201\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.7265e-04 - accuracy: 0.1202\n",
            "Epoch 161/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 6.9888e-04 - accuracy: 0.1201\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 6.0510e-04 - accuracy: 0.1201\n",
            "Epoch 163/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 8.6011e-04 - accuracy: 0.1201\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 7.3275e-04 - accuracy: 0.1201\n",
            "Epoch 165/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 5.6064e-04 - accuracy: 0.1202\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 7.1563e-04 - accuracy: 0.1201\n",
            "Epoch 167/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 7.9518e-04 - accuracy: 0.1201\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 18s 102ms/step - loss: 4.8383e-04 - accuracy: 0.1202\n",
            "Epoch 169/500\n",
            "176/176 [==============================] - 17s 94ms/step - loss: 6.7869e-04 - accuracy: 0.1201\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.5845e-04 - accuracy: 0.1202\n",
            "Epoch 171/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 6.3563e-04 - accuracy: 0.1201\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 6.6021e-04 - accuracy: 0.1202\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.9835e-04 - accuracy: 0.1202\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.2681e-04 - accuracy: 0.1202\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 8.3524e-04 - accuracy: 0.1201\n",
            "Epoch 176/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.8225e-04 - accuracy: 0.1202\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 6.4801e-04 - accuracy: 0.1202\n",
            "Epoch 178/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 6.7823e-04 - accuracy: 0.1201\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 6.0908e-04 - accuracy: 0.1202\n",
            "Epoch 180/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 6.8176e-04 - accuracy: 0.1201\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 4.8337e-04 - accuracy: 0.1202\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.7421e-04 - accuracy: 0.1202\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.5418e-04 - accuracy: 0.1202\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 6.4800e-04 - accuracy: 0.1202\n",
            "Epoch 185/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 4.8308e-04 - accuracy: 0.1202\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.6642e-04 - accuracy: 0.1202\n",
            "Epoch 187/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 4.8954e-04 - accuracy: 0.1202\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.9516e-04 - accuracy: 0.1202\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 6.8135e-04 - accuracy: 0.1201\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.5289e-04 - accuracy: 0.1202\n",
            "Epoch 191/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.5324e-04 - accuracy: 0.1202\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.0911e-04 - accuracy: 0.1202\n",
            "Epoch 193/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.5657e-04 - accuracy: 0.1202\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 4.3175e-04 - accuracy: 0.1202\n",
            "Epoch 195/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.3806e-04 - accuracy: 0.1202\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 5.2476e-04 - accuracy: 0.1202\n",
            "Epoch 197/500\n",
            "176/176 [==============================] - 16s 93ms/step - loss: 4.1361e-04 - accuracy: 0.1202\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.8759e-04 - accuracy: 0.1202\n",
            "Epoch 199/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.8564e-04 - accuracy: 0.1202\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.1627e-04 - accuracy: 0.1202\n",
            "Epoch 201/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 5.5734e-04 - accuracy: 0.1202\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.9252e-04 - accuracy: 0.1202\n",
            "Epoch 203/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 5.4411e-04 - accuracy: 0.1202\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.9829e-04 - accuracy: 0.1202\n",
            "Epoch 205/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.2703e-04 - accuracy: 0.1202\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.0734e-04 - accuracy: 0.1202\n",
            "Epoch 207/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.2532e-04 - accuracy: 0.1202\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 15s 85ms/step - loss: 4.5745e-04 - accuracy: 0.1202\n",
            "Epoch 209/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.8991e-04 - accuracy: 0.1202\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 4.7273e-04 - accuracy: 0.1202\n",
            "Epoch 211/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.4743e-04 - accuracy: 0.1202\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.0318e-04 - accuracy: 0.1202\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 4.0041e-04 - accuracy: 0.1202\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.7101e-04 - accuracy: 0.1202\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.2661e-04 - accuracy: 0.1202\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 3.8218e-04 - accuracy: 0.1202\n",
            "Epoch 217/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.6007e-04 - accuracy: 0.1202\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.2868e-04 - accuracy: 0.1202\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.7696e-04 - accuracy: 0.1202\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.9685e-04 - accuracy: 0.1202\n",
            "Epoch 221/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.7777e-04 - accuracy: 0.1202\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.1159e-04 - accuracy: 0.1202\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.4156e-04 - accuracy: 0.1202\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.9267e-04 - accuracy: 0.1202\n",
            "Epoch 225/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.2389e-04 - accuracy: 0.1202\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 4.1466e-04 - accuracy: 0.1202\n",
            "Epoch 227/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.3081e-04 - accuracy: 0.1202\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.2626e-04 - accuracy: 0.1202\n",
            "Epoch 229/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.0304e-04 - accuracy: 0.1202\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.3862e-04 - accuracy: 0.1202\n",
            "Epoch 231/500\n",
            "176/176 [==============================] - 17s 94ms/step - loss: 4.6335e-04 - accuracy: 0.1202\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 4.3330e-04 - accuracy: 0.1202\n",
            "Epoch 233/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 4.1482e-04 - accuracy: 0.1202\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 5.2765e-04 - accuracy: 0.1202\n",
            "Epoch 235/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 4.9271e-04 - accuracy: 0.1202\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.0914e-04 - accuracy: 0.1202\n",
            "Epoch 237/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.2690e-04 - accuracy: 0.1202\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 5.0295e-04 - accuracy: 0.1202\n",
            "Epoch 239/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.7906e-04 - accuracy: 0.1202\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.9696e-04 - accuracy: 0.1202\n",
            "Epoch 241/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.8652e-04 - accuracy: 0.1202\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.7651e-04 - accuracy: 0.1202\n",
            "Epoch 243/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.1691e-04 - accuracy: 0.1202\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.9631e-04 - accuracy: 0.1202\n",
            "Epoch 245/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.2763e-04 - accuracy: 0.1203\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.1787e-04 - accuracy: 0.1202\n",
            "Epoch 247/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.3120e-04 - accuracy: 0.1202\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.2204e-04 - accuracy: 0.1202\n",
            "Epoch 249/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 4.1858e-04 - accuracy: 0.1202\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.9628e-04 - accuracy: 0.1202\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.3028e-04 - accuracy: 0.1202\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.1159e-04 - accuracy: 0.1202\n",
            "Epoch 253/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.3569e-04 - accuracy: 0.1202\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 4.4908e-04 - accuracy: 0.1202\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.8534e-04 - accuracy: 0.1202\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.0085e-04 - accuracy: 0.1203\n",
            "Epoch 257/500\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 4.9360e-04 - accuracy: 0.1202\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 3.4717e-04 - accuracy: 0.1202\n",
            "Epoch 259/500\n",
            "176/176 [==============================] - 16s 91ms/step - loss: 3.3631e-04 - accuracy: 0.1202\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.3947e-04 - accuracy: 0.1202\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.6374e-04 - accuracy: 0.1202\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.2325e-04 - accuracy: 0.1203\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.9780e-04 - accuracy: 0.1202\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.6274e-04 - accuracy: 0.1202\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.0462e-04 - accuracy: 0.1202\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.4589e-04 - accuracy: 0.1202\n",
            "Epoch 267/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.2310e-04 - accuracy: 0.1202\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.3186e-04 - accuracy: 0.1202\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.3562e-04 - accuracy: 0.1202\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.5758e-04 - accuracy: 0.1202\n",
            "Epoch 271/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.6413e-04 - accuracy: 0.1202\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.4583e-04 - accuracy: 0.1202\n",
            "Epoch 273/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.9839e-04 - accuracy: 0.1202\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.9441e-04 - accuracy: 0.1202\n",
            "Epoch 275/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.6005e-04 - accuracy: 0.1202\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.2416e-04 - accuracy: 0.1202\n",
            "Epoch 277/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.9337e-04 - accuracy: 0.1203\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.8022e-04 - accuracy: 0.1203\n",
            "Epoch 279/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.1748e-04 - accuracy: 0.1203\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.8048e-04 - accuracy: 0.1202\n",
            "Epoch 281/500\n",
            "176/176 [==============================] - 18s 100ms/step - loss: 3.1801e-04 - accuracy: 0.1202\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 16s 93ms/step - loss: 2.9244e-04 - accuracy: 0.1202\n",
            "Epoch 283/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.9452e-04 - accuracy: 0.1202\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.5996e-04 - accuracy: 0.1202\n",
            "Epoch 285/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.2785e-04 - accuracy: 0.1202\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.0715e-04 - accuracy: 0.1202\n",
            "Epoch 287/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.8924e-04 - accuracy: 0.1202\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.4457e-04 - accuracy: 0.1202\n",
            "Epoch 289/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.5318e-04 - accuracy: 0.1202\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 4.1535e-04 - accuracy: 0.1202\n",
            "Epoch 291/500\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 3.4003e-04 - accuracy: 0.1202\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 16s 91ms/step - loss: 1.9593e-04 - accuracy: 0.1203\n",
            "Epoch 293/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.9381e-04 - accuracy: 0.1202\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.5485e-04 - accuracy: 0.1203\n",
            "Epoch 295/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.4889e-04 - accuracy: 0.1203\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.6595e-04 - accuracy: 0.1202\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.3568e-04 - accuracy: 0.1203\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.2733e-04 - accuracy: 0.1203\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.9673e-04 - accuracy: 0.1202\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.9045e-04 - accuracy: 0.1202\n",
            "Epoch 301/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.8388e-04 - accuracy: 0.1202\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.3097e-04 - accuracy: 0.1202\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.7326e-04 - accuracy: 0.1202\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.4600e-04 - accuracy: 0.1202\n",
            "Epoch 305/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.4931e-04 - accuracy: 0.1202\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.1325e-04 - accuracy: 0.1203\n",
            "Epoch 307/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.1679e-04 - accuracy: 0.1202\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 3.0325e-04 - accuracy: 0.1202\n",
            "Epoch 309/500\n",
            "176/176 [==============================] - 17s 99ms/step - loss: 2.4482e-04 - accuracy: 0.1203\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 16s 91ms/step - loss: 2.7259e-04 - accuracy: 0.1202\n",
            "Epoch 311/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.8851e-04 - accuracy: 0.1202\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.9916e-04 - accuracy: 0.1202\n",
            "Epoch 313/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.5890e-04 - accuracy: 0.1202\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 1.7493e-04 - accuracy: 0.1203\n",
            "Epoch 315/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.5071e-04 - accuracy: 0.1203\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.6645e-04 - accuracy: 0.1203\n",
            "Epoch 317/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.7168e-04 - accuracy: 0.1203\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.6660e-04 - accuracy: 0.1203\n",
            "Epoch 319/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.3041e-04 - accuracy: 0.1203\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.9278e-04 - accuracy: 0.1203\n",
            "Epoch 321/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.9393e-04 - accuracy: 0.1202\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.2713e-04 - accuracy: 0.1202\n",
            "Epoch 323/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.4873e-04 - accuracy: 0.1203\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.2026e-04 - accuracy: 0.1203\n",
            "Epoch 325/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.3693e-04 - accuracy: 0.1203\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.1431e-04 - accuracy: 0.1202\n",
            "Epoch 327/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.2531e-04 - accuracy: 0.1203\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.8457e-04 - accuracy: 0.1202\n",
            "Epoch 329/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 1.7924e-04 - accuracy: 0.1203\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.8193e-04 - accuracy: 0.1202\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 5.5404e-04 - accuracy: 0.1202\n",
            "Epoch 332/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.0834e-04 - accuracy: 0.1202\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.3984e-04 - accuracy: 0.1202\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.7942e-04 - accuracy: 0.1202\n",
            "Epoch 335/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.9252e-04 - accuracy: 0.1203\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 2.4528e-04 - accuracy: 0.1202\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 18s 100ms/step - loss: 2.2720e-04 - accuracy: 0.1203\n",
            "Epoch 338/500\n",
            "176/176 [==============================] - 16s 91ms/step - loss: 2.3736e-04 - accuracy: 0.1202\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.0201e-04 - accuracy: 0.1202\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.1356e-04 - accuracy: 0.1202\n",
            "Epoch 341/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.4795e-04 - accuracy: 0.1203\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.0857e-04 - accuracy: 0.1203\n",
            "Epoch 343/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.1784e-04 - accuracy: 0.1203\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 2.4879e-04 - accuracy: 0.1202\n",
            "Epoch 345/500\n",
            "176/176 [==============================] - 15s 86ms/step - loss: 3.0460e-04 - accuracy: 0.1202\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.6477e-04 - accuracy: 0.1203\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.1661e-04 - accuracy: 0.1203\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.8760e-04 - accuracy: 0.1202\n",
            "Epoch 349/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.2461e-04 - accuracy: 0.1203\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.2433e-04 - accuracy: 0.1203\n",
            "Epoch 351/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.2666e-04 - accuracy: 0.1203\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.6040e-04 - accuracy: 0.1203\n",
            "Epoch 353/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.0112e-04 - accuracy: 0.1203\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.0345e-04 - accuracy: 0.1203\n",
            "Epoch 355/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 2.5636e-04 - accuracy: 0.1203\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 3.2515e-04 - accuracy: 0.1203\n",
            "Epoch 357/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.6845e-04 - accuracy: 0.1203\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.8334e-04 - accuracy: 0.1203\n",
            "Epoch 359/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.6439e-04 - accuracy: 0.1203\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 3.7154e-04 - accuracy: 0.1202\n",
            "Epoch 361/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.1757e-04 - accuracy: 0.1203\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.6975e-04 - accuracy: 0.1203\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.1597e-04 - accuracy: 0.1202\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 2.2505e-04 - accuracy: 0.1203\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 18s 101ms/step - loss: 2.3175e-04 - accuracy: 0.1203\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 16s 91ms/step - loss: 3.2021e-04 - accuracy: 0.1202\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.0614e-04 - accuracy: 0.1203\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.6352e-04 - accuracy: 0.1202\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.1389e-04 - accuracy: 0.1203\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.2678e-04 - accuracy: 0.1203\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.7083e-04 - accuracy: 0.1202\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.2283e-04 - accuracy: 0.1203\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.9182e-04 - accuracy: 0.1203\n",
            "Epoch 374/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.7527e-04 - accuracy: 0.1203\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.9393e-04 - accuracy: 0.1203\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 3.0507e-04 - accuracy: 0.1202\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.5165e-04 - accuracy: 0.1202\n",
            "Epoch 378/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.9401e-04 - accuracy: 0.1203\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.7396e-04 - accuracy: 0.1203\n",
            "Epoch 380/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.8012e-04 - accuracy: 0.1202\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.6436e-04 - accuracy: 0.1203\n",
            "Epoch 382/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.9254e-04 - accuracy: 0.1203\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.2617e-04 - accuracy: 0.1203\n",
            "Epoch 384/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.7722e-04 - accuracy: 0.1203\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.2076e-04 - accuracy: 0.1203\n",
            "Epoch 386/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.9419e-04 - accuracy: 0.1203\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.7829e-04 - accuracy: 0.1202\n",
            "Epoch 388/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.9734e-04 - accuracy: 0.1203\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.9452e-04 - accuracy: 0.1203\n",
            "Epoch 390/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.4327e-04 - accuracy: 0.1203\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.5284e-04 - accuracy: 0.1203\n",
            "Epoch 392/500\n",
            "176/176 [==============================] - 16s 92ms/step - loss: 2.2098e-04 - accuracy: 0.1203\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 18s 104ms/step - loss: 2.4870e-04 - accuracy: 0.1203\n",
            "Epoch 394/500\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 1.5837e-04 - accuracy: 0.1203\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.8432e-04 - accuracy: 0.1203\n",
            "Epoch 396/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.6213e-04 - accuracy: 0.1203\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.7718e-04 - accuracy: 0.1203\n",
            "Epoch 398/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.5326e-04 - accuracy: 0.1203\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 2.4686e-04 - accuracy: 0.1202\n",
            "Epoch 400/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.7535e-04 - accuracy: 0.1203\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.8758e-04 - accuracy: 0.1203\n",
            "Epoch 402/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.5844e-04 - accuracy: 0.1203\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.3577e-04 - accuracy: 0.1203\n",
            "Epoch 404/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.8486e-04 - accuracy: 0.1203\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.4961e-04 - accuracy: 0.1203\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.0900e-04 - accuracy: 0.1203\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.3588e-04 - accuracy: 0.1203\n",
            "Epoch 408/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.6067e-04 - accuracy: 0.1203\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.8883e-04 - accuracy: 0.1203\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.1476e-04 - accuracy: 0.1203\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.6491e-04 - accuracy: 0.1203\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 2.1838e-04 - accuracy: 0.1203\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 15s 87ms/step - loss: 1.6904e-04 - accuracy: 0.1203\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.8024e-04 - accuracy: 0.1203\n",
            "Epoch 415/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.5476e-04 - accuracy: 0.1202\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.4081e-04 - accuracy: 0.1203\n",
            "Epoch 417/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 2.1325e-04 - accuracy: 0.1203\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.0902e-04 - accuracy: 0.1203\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.6085e-04 - accuracy: 0.1203\n",
            "Epoch 420/500\n",
            "176/176 [==============================] - 17s 95ms/step - loss: 1.6247e-04 - accuracy: 0.1203\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 18s 101ms/step - loss: 1.9115e-04 - accuracy: 0.1203\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.4579e-04 - accuracy: 0.1203\n",
            "Epoch 423/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.5227e-04 - accuracy: 0.1203\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 2.4172e-04 - accuracy: 0.1203\n",
            "Epoch 425/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.9047e-04 - accuracy: 0.1203\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.6925e-04 - accuracy: 0.1203\n",
            "Epoch 427/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 2.1174e-04 - accuracy: 0.1203\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.1467e-04 - accuracy: 0.1203\n",
            "Epoch 429/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.6109e-04 - accuracy: 0.1203\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.7516e-04 - accuracy: 0.1203\n",
            "Epoch 431/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.9642e-04 - accuracy: 0.1203\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.5464e-04 - accuracy: 0.1203\n",
            "Epoch 433/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.7098e-04 - accuracy: 0.1203\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.9231e-04 - accuracy: 0.1203\n",
            "Epoch 435/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.5528e-04 - accuracy: 0.1203\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.5356e-04 - accuracy: 0.1203\n",
            "Epoch 437/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.4733e-04 - accuracy: 0.1203\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.9146e-04 - accuracy: 0.1203\n",
            "Epoch 439/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 2.0313e-04 - accuracy: 0.1203\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.3206e-04 - accuracy: 0.1203\n",
            "Epoch 441/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.5133e-04 - accuracy: 0.1203\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 3.0068e-04 - accuracy: 0.1203\n",
            "Epoch 443/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.0612e-04 - accuracy: 0.1203\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.5740e-04 - accuracy: 0.1203\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.6473e-04 - accuracy: 0.1203\n",
            "Epoch 446/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.6712e-04 - accuracy: 0.1203\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 3.5190e-04 - accuracy: 0.1202\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 18s 101ms/step - loss: 1.6122e-04 - accuracy: 0.1203\n",
            "Epoch 449/500\n",
            "176/176 [==============================] - 17s 97ms/step - loss: 1.2646e-04 - accuracy: 0.1203\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.2846e-04 - accuracy: 0.1203\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.9412e-04 - accuracy: 0.1203\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.8244e-04 - accuracy: 0.1203\n",
            "Epoch 453/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.3697e-04 - accuracy: 0.1203\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.7371e-04 - accuracy: 0.1203\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.4071e-04 - accuracy: 0.1203\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.7128e-04 - accuracy: 0.1203\n",
            "Epoch 457/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.2260e-04 - accuracy: 0.1203\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.2173e-04 - accuracy: 0.1203\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.6957e-04 - accuracy: 0.1203\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.7595e-04 - accuracy: 0.1203\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.6561e-04 - accuracy: 0.1203\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 2.1806e-04 - accuracy: 0.1203\n",
            "Epoch 463/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.6349e-04 - accuracy: 0.1203\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.6164e-04 - accuracy: 0.1203\n",
            "Epoch 465/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.1874e-04 - accuracy: 0.1203\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.9229e-04 - accuracy: 0.1203\n",
            "Epoch 467/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.6053e-04 - accuracy: 0.1203\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.8822e-04 - accuracy: 0.1203\n",
            "Epoch 469/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.5635e-04 - accuracy: 0.1203\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.2648e-04 - accuracy: 0.1203\n",
            "Epoch 471/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 2.0236e-04 - accuracy: 0.1203\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.6649e-04 - accuracy: 0.1203\n",
            "Epoch 473/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.3474e-04 - accuracy: 0.1203\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.5187e-04 - accuracy: 0.1203\n",
            "Epoch 475/500\n",
            "176/176 [==============================] - 16s 92ms/step - loss: 1.4123e-04 - accuracy: 0.1203\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 18s 101ms/step - loss: 1.2085e-04 - accuracy: 0.1203\n",
            "Epoch 477/500\n",
            "176/176 [==============================] - 16s 91ms/step - loss: 1.4671e-04 - accuracy: 0.1203\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 7.7134e-05 - accuracy: 0.1203\n",
            "Epoch 479/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.5836e-04 - accuracy: 0.1203\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.5020e-04 - accuracy: 0.1203\n",
            "Epoch 481/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.1983e-04 - accuracy: 0.1203\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 7.5784e-04 - accuracy: 0.1202\n",
            "Epoch 483/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.1263e-04 - accuracy: 0.1203\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.2002e-04 - accuracy: 0.1203\n",
            "Epoch 485/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.7593e-04 - accuracy: 0.1203\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.5948e-04 - accuracy: 0.1203\n",
            "Epoch 487/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 1.5634e-04 - accuracy: 0.1203\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 9.9364e-05 - accuracy: 0.1203\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 2.1905e-04 - accuracy: 0.1203\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 2.0313e-04 - accuracy: 0.1203\n",
            "Epoch 491/500\n",
            "176/176 [==============================] - 15s 88ms/step - loss: 6.1565e-05 - accuracy: 0.1203\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.4497e-04 - accuracy: 0.1203\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.8783e-04 - accuracy: 0.1203\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 2.1034e-04 - accuracy: 0.1203\n",
            "Epoch 495/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.3417e-04 - accuracy: 0.1203\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 1.5683e-04 - accuracy: 0.1203\n",
            "Epoch 497/500\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.6377e-04 - accuracy: 0.1203\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.5187e-04 - accuracy: 0.1203\n",
            "Epoch 499/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.3963e-04 - accuracy: 0.1203\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 16s 88ms/step - loss: 1.7516e-04 - accuracy: 0.1203\n",
            "{'loss': [0.9365642070770264, 0.6740368008613586, 0.5092710852622986, 0.3629242777824402, 0.2564675211906433, 0.1768568456172943, 0.15378810465335846, 0.11065693944692612, 0.09927374124526978, 0.0752328410744667, 0.08325556665658951, 0.06341920793056488, 0.11533024162054062, 0.07680357992649078, 0.07482903450727463, 0.08871744573116302, 0.08978345990180969, 0.07587279379367828, 0.08333687484264374, 0.10229042172431946, 0.11964623630046844, 0.08426419645547867, 0.0753648430109024, 0.06544004380702972, 0.026249289512634277, 0.05046404153108597, 0.04796869307756424, 0.022120824083685875, 0.03637435659766197, 0.01914876140654087, 0.025746602565050125, 0.01519998162984848, 0.017635896801948547, 0.012764200568199158, 0.011433465406298637, 0.01386749092489481, 0.01224365085363388, 0.010544348508119583, 0.008881555870175362, 0.010577831417322159, 0.010573245584964752, 0.011199959553778172, 0.007294159382581711, 0.007043711841106415, 0.007012608926743269, 0.0067931972444057465, 0.006588756572455168, 0.005141381174325943, 0.007622516714036465, 0.004573906771838665, 0.005293709691613913, 0.005115221720188856, 0.004866068717092276, 0.004144253209233284, 0.004842217080295086, 0.004106032662093639, 0.0046707624569535255, 0.0036070526111871004, 0.003917972091585398, 0.0035120672546327114, 0.003669723868370056, 0.0029925077687948942, 0.003617862006649375, 0.0032502354588359594, 0.0033001364208757877, 0.00271392404101789, 0.0030437877867370844, 0.0028028308879584074, 0.0028018541634082794, 0.002713540568947792, 0.003022332675755024, 0.00265456922352314, 0.0022638768423348665, 0.002784706884995103, 0.003485084045678377, 0.0021268415730446577, 0.002546025440096855, 0.0024475089740008116, 0.002063145861029625, 0.0022115104366093874, 0.002137748058885336, 0.0016479549231007695, 0.0036754340399056673, 0.0020200267899781466, 0.00205673067830503, 0.0018754033371806145, 0.0018312641186639667, 0.002235440770164132, 0.001938392175361514, 0.0017524559516459703, 0.0017918433295562863, 0.0019873259589076042, 0.001940753310918808, 0.001668436685577035, 0.0015875023091211915, 0.0015053882962092757, 0.001708069583401084, 0.0015658520860597491, 0.0015540346503257751, 0.0016567298443987966, 0.0014587173936888576, 0.0014374624006450176, 0.0014741347404196858, 0.001483157742768526, 0.0016131395241245627, 0.0012632488505914807, 0.0014528926694765687, 0.0012050176737830043, 0.0011029874440282583, 0.0014056946383789182, 0.0013896486489102244, 0.001254577306099236, 0.00098341703414917, 0.0012055978877469897, 0.001234392635524273, 0.0019729554187506437, 0.0012401011772453785, 0.0011244851630181074, 0.0011205034097656608, 0.001192638766951859, 0.0008813984459266067, 0.0013720544520765543, 0.0010098506463691592, 0.0011491688201203942, 0.0008994537638500333, 0.0016444348730146885, 0.0008892204496078193, 0.0010724624153226614, 0.0008435542695224285, 0.001002651173621416, 0.0009321277029812336, 0.0010326056508347392, 0.0009115159045904875, 0.0007852459093555808, 0.0009627118124626577, 0.0009924983605742455, 0.0008762903744354844, 0.0010997802019119263, 0.0009249814320355654, 0.0008639955776743591, 0.0008346146205440164, 0.000828096061013639, 0.000902102270629257, 0.0008896347717382014, 0.0009495397680439055, 0.0008487993036396801, 0.0008946292218752205, 0.0008509578183293343, 0.0007321005687117577, 0.001159080071374774, 0.0010606839787214994, 0.0007303403108380735, 0.0009458016138523817, 0.001009077299386263, 0.0010563057148829103, 0.0005318229668773711, 0.0009130279649980366, 0.000842110370285809, 0.0009499227162450552, 0.0005726516828872263, 0.0006988801760599017, 0.0006051026866771281, 0.0008601066074334085, 0.000732751504983753, 0.0005606436170637608, 0.0007156304782256484, 0.0007951821899041533, 0.0004838294116780162, 0.0006786947487853467, 0.0005584548343904316, 0.0006356264930218458, 0.0006602089270018041, 0.0005983493174426258, 0.000526808958966285, 0.0008352358127012849, 0.00048225390492007136, 0.000648005458060652, 0.0006782253040000796, 0.0006090811220929027, 0.0006817550165578723, 0.0004833684943150729, 0.0005742079811170697, 0.0005541807622648776, 0.0006480009178631008, 0.00048308048280887306, 0.0005664206109941006, 0.0004895380116067827, 0.0004951576702296734, 0.00068135024048388, 0.000552886922378093, 0.0004532373568508774, 0.0005091072525829077, 0.00045656756265088916, 0.00043174627353437245, 0.0005380600341595709, 0.0005247594090178609, 0.0004136134230066091, 0.0004875877348240465, 0.0005856375792063773, 0.0005162672023288906, 0.0005573416710831225, 0.0004925213288515806, 0.0005441055982373655, 0.0004982850514352322, 0.00042702979408204556, 0.0005073445499874651, 0.0005253228009678423, 0.00045744871022179723, 0.0003899146104231477, 0.00047272900701500475, 0.0004474295419640839, 0.00040317518869414926, 0.00040041017928160727, 0.000371010770322755, 0.0005266087246127427, 0.00038217558176256716, 0.00036006831214763224, 0.00042868120362982154, 0.00047696277033537626, 0.0004968493594788015, 0.0005777666810899973, 0.0005115867243148386, 0.0003415555984247476, 0.0004926698165945709, 0.0004238923138473183, 0.0004146608989685774, 0.00033080598223023117, 0.00042625839705578983, 0.0004030445124953985, 0.00033862103009596467, 0.0004633489006664604, 0.00043329523759894073, 0.0004148164880461991, 0.0005276465089991689, 0.0004927068366669118, 0.0005091401981189847, 0.00032690141233615577, 0.0005029472522437572, 0.000379056204110384, 0.00039695549639873207, 0.0002865218557417393, 0.00037651241291314363, 0.0004169094900134951, 0.0004963105893693864, 0.0002276290178997442, 0.0003178715123794973, 0.0003311987966299057, 0.0004220428236294538, 0.00041858316399157047, 0.000396276474930346, 0.0004302846791688353, 0.00031159029458649457, 0.0003356903325766325, 0.00044908205745741725, 0.0002853355836123228, 0.00030085095204412937, 0.0004935989272780716, 0.00034716870868578553, 0.0003363064315635711, 0.0003394689119886607, 0.0003637359768617898, 0.00022325133613776416, 0.000297801336273551, 0.00026273998082615435, 0.00030462289578281343, 0.00034588974085636437, 0.00032309573725797236, 0.00043185753747820854, 0.00033562027965672314, 0.00035757970181293786, 0.00026413300656713545, 0.00034583386150188744, 0.0002983862068504095, 0.0002944102161563933, 0.0003600524505600333, 0.0003241629747208208, 0.00019336979312356561, 0.0002802231174428016, 0.00021747943537775427, 0.0002804823452606797, 0.0003180143248755485, 0.000292435463052243, 0.00029451987938955426, 0.0002599626313894987, 0.0003278455405961722, 0.0003071515529882163, 0.00028924294747412205, 0.0003445700858719647, 0.00025317983818240464, 0.00041534629417583346, 0.0003400330024305731, 0.00019592598255258054, 0.0002938107936643064, 0.0002548515039961785, 0.00024888620828278363, 0.00036595415440388024, 0.00023568030155729502, 0.00022732933575753123, 0.00029672589153051376, 0.0002904472057707608, 0.00028387646307237446, 0.00033096614060923457, 0.0002732629654929042, 0.0003459958825260401, 0.00024930990184657276, 0.00021324875706341118, 0.000316786696203053, 0.0003032461681868881, 0.00024481923901475966, 0.0002725945378188044, 0.00028850941453129053, 0.0003991576377302408, 0.00025889938115142286, 0.00017492586630396545, 0.00025070985429920256, 0.00026645162142813206, 0.0002716750022955239, 0.000266603019554168, 0.00023041227541398257, 0.00019278131367173046, 0.0002939332334790379, 0.00032713418477214873, 0.00024872805806808174, 0.00022026049555279315, 0.00023693335242569447, 0.00031430739909410477, 0.00022530871501658112, 0.00028456930886022747, 0.00017924046551343054, 0.00028193474281579256, 0.0005540410056710243, 0.0003083392512053251, 0.0002398419164819643, 0.00027941667940467596, 0.0001925239630509168, 0.00024528303765691817, 0.00022719547268934548, 0.00023735640570521355, 0.00030200782930478454, 0.00021355653007049114, 0.00024794702767394483, 0.00020857210620306432, 0.0002178418217226863, 0.00024879039847292006, 0.00030459807021543384, 0.0002647717483341694, 0.000216613058000803, 0.0002876015496440232, 0.00022460825857706368, 0.00022433491540141404, 0.00022666249424219131, 0.0002603955508675426, 0.00020111801859457046, 0.00020345473603811115, 0.00025635756901465356, 0.00032514563645236194, 0.0002684513165149838, 0.00018333923071622849, 0.00016438931925222278, 0.0003715445345733315, 0.0002175683039240539, 0.00016974704340100288, 0.0002159655705327168, 0.00022505162633024156, 0.00023175204114522785, 0.000320214603561908, 0.000206136261112988, 0.0002635188866406679, 0.00021388778986874968, 0.0002267784293508157, 0.00027082700398750603, 0.00012282874376978725, 0.0002918156678788364, 0.0001752651878632605, 0.0001939257635967806, 0.00030507222982123494, 0.0002516458334866911, 0.0001940112852025777, 0.0001739647559588775, 0.0002801188675221056, 0.00026436051120981574, 0.00019254465587437153, 0.00022617208014708012, 0.00017721713811624795, 0.0002207552461186424, 0.00019419351883698255, 0.00027828506426885724, 0.0001973398175323382, 0.0001945214462466538, 0.00014326715609058738, 0.00015283760149031878, 0.00022098272165749222, 0.00024869866319932044, 0.0001583677949383855, 0.00018431883654557168, 0.00016212643822655082, 0.00017717877926770598, 0.0001532590831629932, 0.0002468622988089919, 0.0001753477699821815, 0.00018757976067718118, 0.00015844282461330295, 0.00023576967942062765, 0.00018486428598407656, 0.0001496110635343939, 0.00020900000527035445, 0.0001358834415441379, 0.0001606699952390045, 0.00018882527365349233, 0.0002147562918253243, 0.00016491219867020845, 0.00021837999520357698, 0.00016903651703614742, 0.00018024034216068685, 0.0002547616313677281, 0.00014081397966947407, 0.0002132494410034269, 0.00020901646348647773, 0.0002608508220873773, 0.00016247329767793417, 0.00019115000031888485, 0.00014578587433788925, 0.0001522735256003216, 0.0002417244395473972, 0.00019046540546696633, 0.00016924715600907803, 0.00021174146968405694, 0.00021467045007739216, 0.00016109253920149058, 0.00017515712534077466, 0.00019642246479634196, 0.00015463818272110075, 0.00017098477110266685, 0.00019230549514759332, 0.0001552821631776169, 0.00015355735376942903, 0.00014732922136317939, 0.00019146395788993686, 0.00020313214918132871, 0.00023205921752378345, 0.00015132765111047775, 0.00030067950137890875, 0.00020611735817510635, 0.00015740448725409806, 0.00016472704010084271, 0.00016711514035705477, 0.0003518973826430738, 0.00016121850057970732, 0.00012645557580981404, 0.00022846048523206264, 0.00019411816901993006, 0.00018243640079163015, 0.00013696939276997, 0.00017371303692925721, 0.0001407113450113684, 0.00017127861792687327, 0.0002225992502644658, 0.000221729525947012, 0.0001695700193522498, 0.00017594645032659173, 0.00016561026859562844, 0.0002180551236961037, 0.00016348868666682392, 0.0001616423251107335, 0.00021873867081012577, 0.00019229177269153297, 0.00016053076251409948, 0.0001882166980067268, 0.00015635398449376225, 0.00012647865514736623, 0.00020236028649378568, 0.00016648531891405582, 0.0001347421493846923, 0.00015187080134637654, 0.00014122734137345105, 0.00012084864283679053, 0.00014671152166556567, 7.713389641139656e-05, 0.00015836447710171342, 0.0001501958176959306, 0.00011982646537944674, 0.0007578418008051813, 0.00011263458873145282, 0.00012002249422948807, 0.0001759259612299502, 0.00015948066720739007, 0.00015634289593435824, 9.936405695043504e-05, 0.00021905121684540063, 0.00020313389541115612, 6.156472227303311e-05, 0.0002449660678394139, 0.0001878282055258751, 0.00021034068777225912, 0.00013417047739494592, 0.0001568317093187943, 0.00016376514395233244, 0.00015186666860245168, 0.00013963470701128244, 0.00017516121442895383], 'accuracy': [0.012330119498074055, 0.026094764471054077, 0.04217487573623657, 0.05986970290541649, 0.07590476423501968, 0.08867835253477097, 0.09122906625270844, 0.09776201844215393, 0.1000794842839241, 0.10418985784053802, 0.10366830229759216, 0.10598176717758179, 0.09957895427942276, 0.10429196804761887, 0.10453622788190842, 0.10279136896133423, 0.10138287395238876, 0.10385249555110931, 0.10207260400056839, 0.0999893918633461, 0.09763889014720917, 0.10113460570573807, 0.1030416339635849, 0.10475745797157288, 0.1126939058303833, 0.10800492018461227, 0.10944144427776337, 0.11380308866500854, 0.11224142462015152, 0.1146860271692276, 0.11354581266641617, 0.11591333150863647, 0.11566507071256638, 0.11667914688587189, 0.11695344001054764, 0.11652298271656036, 0.11695744097232819, 0.11743094772100449, 0.11782436817884445, 0.11754707247018814, 0.11741192638874054, 0.11748800426721573, 0.1182347983121872, 0.11836894601583481, 0.11837294697761536, 0.11839596927165985, 0.11846504360437393, 0.11886446923017502, 0.11834892630577087, 0.11902163922786713, 0.1188434511423111, 0.11893855035305023, 0.11894755810499191, 0.11916178464889526, 0.11905467510223389, 0.11919882893562317, 0.11906769126653671, 0.11931294947862625, 0.11926189064979553, 0.11929993331432343, 0.11928492039442062, 0.11947912722826004, 0.11931294947862625, 0.11941505968570709, 0.11944008618593216, 0.1196022555232048, 0.11946110427379608, 0.11954719573259354, 0.11957623064517975, 0.11954619735479355, 0.11950214952230453, 0.11958223581314087, 0.11970836669206619, 0.1195652186870575, 0.11938402056694031, 0.11974640935659409, 0.11960826069116592, 0.11964129656553268, 0.11975942552089691, 0.1197524145245552, 0.11974941194057465, 0.11984651535749435, 0.11947312206029892, 0.11977243423461914, 0.11975541710853577, 0.11983450502157211, 0.11982549726963043, 0.11970436573028564, 0.11978144943714142, 0.11986052989959717, 0.11981548368930817, 0.1198204904794693, 0.1197904571890831, 0.11987754702568054, 0.11986653506755829, 0.11991558969020844, 0.11984951794147491, 0.11988255381584167, 0.1199035793542862, 0.11988155543804169, 0.11992960423231125, 0.11993160843849182, 0.11992960423231125, 0.11992260068655014, 0.11994262039661407, 0.11998866498470306, 0.11992260068655014, 0.11997765302658081, 0.12002570927143097, 0.11996864527463913, 0.11995162814855576, 0.11996764689683914, 0.12001769989728928, 0.11999467015266418, 0.12001068890094757, 0.11984651535749435, 0.12000568211078644, 0.12002470344305038, 0.11999967694282532, 0.12000568211078644, 0.12007175385951996, 0.11997565627098083, 0.12005974352359772, 0.11998466402292252, 0.12007976323366165, 0.11995763331651688, 0.12007075548171997, 0.12003471702337265, 0.12009978294372559, 0.1200457289814949, 0.12007775902748108, 0.12002570927143097, 0.12003571540117264, 0.1201057955622673, 0.1200757622718811, 0.12004672735929489, 0.12007175385951996, 0.1200607419013977, 0.12009377777576447, 0.12010679394006729, 0.12008677423000336, 0.12009377777576447, 0.12007876485586166, 0.12008176743984222, 0.12005574256181717, 0.12011279910802841, 0.12009277939796448, 0.1201288178563118, 0.12012781202793121, 0.1200457289814949, 0.12005173414945602, 0.12010178714990616, 0.1200457289814949, 0.12003271281719208, 0.12004773318767548, 0.1201808750629425, 0.1200837716460228, 0.12009578198194504, 0.1200687512755394, 0.12017185986042023, 0.12012781202793121, 0.12013782560825348, 0.12010679394006729, 0.12012381106615067, 0.12016285210847855, 0.12013082206249237, 0.12009978294372559, 0.12020289897918701, 0.12013482302427292, 0.12015384435653687, 0.12014183402061462, 0.1201508417725563, 0.12016686052083969, 0.12017086148262024, 0.12010379135608673, 0.12018487602472305, 0.12015584856271744, 0.12014082819223404, 0.12017686665058136, 0.12012681365013123, 0.12017086148262024, 0.12017887085676193, 0.12017586827278137, 0.1201658546924591, 0.12019088119268417, 0.12016385048627853, 0.12019288539886475, 0.1201958879828453, 0.12014283239841461, 0.12017686665058136, 0.12019088119268417, 0.12019188702106476, 0.12020189315080643, 0.12019488960504532, 0.1201808750629425, 0.12016986310482025, 0.12020089477300644, 0.12019188702106476, 0.12017286568880081, 0.12019288539886475, 0.1201888769865036, 0.12020689994096756, 0.12018187344074249, 0.12017887085676193, 0.12019889056682587, 0.12019488960504532, 0.12018988281488419, 0.12019488960504532, 0.12021590769290924, 0.12018487602472305, 0.12019488960504532, 0.12021290510892868, 0.12019188702106476, 0.12022391706705093, 0.12018787860870361, 0.12020990252494812, 0.12022191286087036, 0.12021190673112869, 0.1201888769865036, 0.12020590156316757, 0.12016285210847855, 0.12019789218902588, 0.1202189102768898, 0.12019388377666473, 0.12020689994096756, 0.12020789831876755, 0.12022892385721207, 0.12021590769290924, 0.12021090090274811, 0.12022992223501205, 0.12019889056682587, 0.12021190673112869, 0.12020990252494812, 0.12019088119268417, 0.12020990252494812, 0.12018187344074249, 0.12022792547941208, 0.12017486244440079, 0.12022091448307037, 0.12020789831876755, 0.12023292481899261, 0.12021190673112869, 0.12019988894462585, 0.1201968863606453, 0.12026596069335938, 0.12023192644119263, 0.12023292481899261, 0.12020689994096756, 0.12019188702106476, 0.12022091448307037, 0.12021390348672867, 0.12022792547941208, 0.12021490931510925, 0.12020890414714813, 0.12024194002151489, 0.12025094777345657, 0.12019789218902588, 0.12023793160915375, 0.12024594098329544, 0.12022291868925095, 0.12022992223501205, 0.12025795131921768, 0.12022892385721207, 0.12024393677711487, 0.12023592740297318, 0.12022191286087036, 0.12023693323135376, 0.12020890414714813, 0.12022992223501205, 0.12021490931510925, 0.12024693936109543, 0.1202259212732315, 0.12023192644119263, 0.12024794518947601, 0.12023092806339264, 0.12023192644119263, 0.12027297168970108, 0.12025395035743713, 0.12025895714759827, 0.12024293839931488, 0.12023292481899261, 0.12024494260549545, 0.12023693323135376, 0.12024494260549545, 0.12023793160915375, 0.12023592740297318, 0.12024194002151489, 0.12023092806339264, 0.12024494260549545, 0.12021691352128983, 0.12023192644119263, 0.12025795131921768, 0.12024393677711487, 0.12025295197963715, 0.12025295197963715, 0.12021791189908981, 0.12025295197963715, 0.12025895714759827, 0.12024093419313431, 0.12023793160915375, 0.12024794518947601, 0.12023492902517319, 0.12024994194507599, 0.12022792547941208, 0.120248943567276, 0.12025094777345657, 0.12023693323135376, 0.12024393677711487, 0.1202559545636177, 0.1202339306473732, 0.120248943567276, 0.12022491544485092, 0.12024994194507599, 0.12026696652173996, 0.12025194615125656, 0.1202559545636177, 0.1202569529414177, 0.12025194615125656, 0.1202569529414177, 0.12026596069335938, 0.12023993581533432, 0.12024994194507599, 0.12025295197963715, 0.12026896327733994, 0.12026496231555939, 0.12023492902517319, 0.12025395035743713, 0.12023993581533432, 0.12027297168970108, 0.12023893743753433, 0.12021090090274811, 0.12022091448307037, 0.12024794518947601, 0.12022992223501205, 0.12026496231555939, 0.12024994194507599, 0.12026295810937881, 0.120248943567276, 0.12024594098329544, 0.12024994194507599, 0.12025094777345657, 0.12027096748352051, 0.12025995552539825, 0.12024594098329544, 0.12024693936109543, 0.12025194615125656, 0.12026195973157883, 0.12024494260549545, 0.1202559545636177, 0.12026095390319824, 0.12025995552539825, 0.12025895714759827, 0.12026596069335938, 0.12026496231555939, 0.12025995552539825, 0.12025194615125656, 0.12025395035743713, 0.12025995552539825, 0.12027297168970108, 0.12024594098329544, 0.1202569529414177, 0.12026195973157883, 0.12024994194507599, 0.12025295197963715, 0.12025094777345657, 0.12024293839931488, 0.12026796489953995, 0.120248943567276, 0.12025795131921768, 0.1202569529414177, 0.12024994194507599, 0.12028297781944275, 0.12025094777345657, 0.12026596069335938, 0.12025795131921768, 0.12024494260549545, 0.120248943567276, 0.12026496231555939, 0.12026295810937881, 0.12024494260549545, 0.12025395035743713, 0.12026996910572052, 0.12025395035743713, 0.12026696652173996, 0.12025995552539825, 0.12027697265148163, 0.12024293839931488, 0.12027096748352051, 0.1202639639377594, 0.12026896327733994, 0.12027797847986221, 0.12026195973157883, 0.12026696652173996, 0.12026496231555939, 0.12026796489953995, 0.12027297168970108, 0.12026696652173996, 0.12027997523546219, 0.12024693936109543, 0.12028498202562332, 0.12027697265148163, 0.1202719658613205, 0.12026696652173996, 0.12028197944164276, 0.12027997523546219, 0.1202639639377594, 0.12027797847986221, 0.1202639639377594, 0.12027496844530106, 0.12026095390319824, 0.1202719658613205, 0.12026496231555939, 0.12027297168970108, 0.12027297168970108, 0.12024794518947601, 0.12028297781944275, 0.12026095390319824, 0.12027397006750107, 0.1202569529414177, 0.12026996910572052, 0.12026195973157883, 0.12026596069335938, 0.12027397006750107, 0.12025995552539825, 0.12026896327733994, 0.12026896327733994, 0.12026195973157883, 0.1202719658613205, 0.12026295810937881, 0.12026896327733994, 0.1202719658613205, 0.12028297781944275, 0.12026496231555939, 0.12025494873523712, 0.12027697265148163, 0.12027096748352051, 0.12028098106384277, 0.12027297168970108, 0.12025995552539825, 0.12025995552539825, 0.12028098106384277, 0.12025094777345657, 0.12025795131921768, 0.12026996910572052, 0.12027997523546219, 0.12027997523546219, 0.12023993581533432, 0.12026896327733994, 0.12027597427368164, 0.12026596069335938, 0.12026295810937881, 0.12027496844530106, 0.12027797847986221, 0.12028398364782333, 0.12027397006750107, 0.12027096748352051, 0.12025895714759827, 0.12026996910572052, 0.12027597427368164, 0.12027397006750107, 0.12026896327733994, 0.1202559545636177, 0.12027397006750107, 0.1202719658613205, 0.12026796489953995, 0.12026896327733994, 0.12026896327733994, 0.12027297168970108, 0.12027096748352051, 0.12028197944164276, 0.1202719658613205, 0.12026996910572052, 0.12027397006750107, 0.12027397006750107, 0.12027797847986221, 0.12028598040342331, 0.12026696652173996, 0.12029599398374557, 0.12027496844530106, 0.12027697265148163, 0.12028398364782333, 0.12023192644119263, 0.12029098719358444, 0.12028197944164276, 0.12026195973157883, 0.12027496844530106, 0.12026896327733994, 0.12028998881578445, 0.12026496231555939, 0.12028197944164276, 0.12029299139976501, 0.12025494873523712, 0.12027997523546219, 0.12025494873523712, 0.12028498202562332, 0.12027297168970108, 0.12027496844530106, 0.12027797847986221, 0.12027797847986221, 0.12027597427368164]}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# *중요* TPU 사용 전용이므로 GPU 사용시에는 이것을 사용하면 안됨\n",
        "\n",
        "# 하이퍼파라미터\n",
        "D_MODEL = 512\n",
        "NUM_LAYERS = 6\n",
        "NUM_HEADS = 8\n",
        "DFF = 2048\n",
        "DROPOUT = 0.1\n",
        "EPOCHS = 500\n",
        "# 총 500회 학습\n",
        "\n",
        "# 1. 저장할 폴더와 형식을 선택\n",
        "checkPoint_path = \"saved_epoch/model_{epoch:04d}.ckpt\" # 저장할 당시 epoch가 파일이름이 된다.\n",
        "checkPoint_dir = os.path.dirname(checkPoint_path)\n",
        "\n",
        "# 2. 콜백 변수를 생성\n",
        "my_period = 1\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkPoint_path,\n",
        "\t\t\t\t\tsave_weights_only=True, verbose=1, period=my_period) \n",
        "\n",
        "with strategy.scope():\n",
        "  model = transformer(\n",
        "      vocab_size=VOCAB_SIZE,\n",
        "      num_layers=NUM_LAYERS,\n",
        "      dff=DFF,\n",
        "      d_model=D_MODEL,\n",
        "      num_heads=NUM_HEADS,\n",
        "      dropout=DROPOUT)\n",
        "  \n",
        "  learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(\n",
        "      learning_rate, beta_1=0.28, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "  def accuracy(y_true, y_pred):\n",
        "    # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "  def loss_function(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')(y_true, y_pred)\n",
        "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "  history = model.fit(dataset, epochs=EPOCHS,\n",
        "                      verbose=1)\n",
        "  \n",
        "  print(history.history)\n",
        "\n",
        "  # 6 훈련 과정 시각화 (정확도)\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend(['Train'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # 7 훈련 과정 시각화 (손실)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend(['Train'], loc='upper left')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **모델 불러오기 (안쓰는 코드)**"
      ],
      "metadata": {
        "id": "HKdG6YMERaeU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqUSZ6VX6OXy",
        "outputId": "f4c11c57-7e47-46da-a4c4-0d7cc7cdb6c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Couldn't match files for checkpoint /content/drive/MyDrive/Colab Notebooks/saved_epoch/model_0002.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:Couldn't match files for checkpoint /content/drive/MyDrive/Colab Notebooks/saved_epoch/model_0002.ckpt\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-70096cfa39f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# 2. 해당체크포인트에 저장한 모델의 가중치 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mis_hdf5_filepath\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m   return (filepath.endswith('.h5') or filepath.endswith('.keras') or\n\u001b[0m\u001b[1;32m    336\u001b[0m           filepath.endswith('.hdf5'))\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'endswith'"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  # 1. 해당 폴더에서 가장 마지막 체크포인트 선택\n",
        "  latest = tf.train.latest_checkpoint(checkPoint_dir)\n",
        "\n",
        "  # 2. 해당체크포인트에 저장한 모델의 가중치 불러오기\n",
        "  model.load_weights(latest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBguAJ7GPq-3"
      },
      "source": [
        "# **GPU 사용시.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "F4mm6GuyonLJ",
        "outputId": "135affc3-14d2-4dad-977e-d247d0f19d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 8127, 1024)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-50e886d33f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_HEADS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     dropout=DROPOUT) \n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomSchedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-917355b573c8>\u001b[0m in \u001b[0;36mtransformer\u001b[0;34m(vocab_size, num_layers, dff, d_model, num_heads, dropout, name)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m# 인코더의 출력은 enc_outputs. 디코더로 전달된다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m   )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-c6a4a877ef56>\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(vocab_size, num_layers, dff, d_model, num_heads, dropout, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m     outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n\u001b[1;32m     48\u001b[0m         \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"encoder_layer_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     )([outputs, padding_mask])\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   return tf.keras.Model(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m-> 1033\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1174\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    940\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \"\"\"\n\u001b[1;32m    451\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 452\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filewrzmux38.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mscaled_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0m_attach_error_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileh6jxb1hj.py\u001b[0m in \u001b[0;36mtf__split_heads\u001b[0;34m(self, inputs, batch_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m   \"\"\"\n\u001b[0;32m--> 194\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8545\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8546\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 8547\u001b[0;31m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   8548\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8549\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m               inferred = ops.convert_to_tensor(\n\u001b[0;32m--> 489\u001b[0;31m                   values, name=input_arg.name, as_ref=input_arg.is_ref)\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m               \u001b[0;31m# When converting a python object such as a list of Dimensions, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1545\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1481\u001b[0m           elems_as_tensors.append(\n\u001b[1;32m   1482\u001b[0m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0;32m-> 1483\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6564\u001b[0m   \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6565\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 6566\u001b[0;31m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   6567\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6568\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3782\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3784\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3785\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2173\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2175\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack_for_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36mextract_stack_for_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    183\u001b[0m   return _tf_stack.extract_stack_for_node(\n\u001b[1;32m    184\u001b[0m       \u001b[0m_source_mapper_stacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthread_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m       _source_filter_stacks[thread_key][-1].internal_set, node)\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# *중요* TPU 사용때는 안되고, GPU 사용시 사용될 코드\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "D_MODEL = 1024\n",
        "NUM_LAYERS = 6\n",
        "NUM_HEADS = 16\n",
        "DFF = 4096\n",
        "DROPOUT = 0.3\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT) \n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "\n",
        "# 총 10회 학습\n",
        "EPOCHS = 150\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLStl1dRP43v"
      },
      "source": [
        "# **모델 세이브 방식 두가지**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkeb_Hn7qwyF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "aqGEPX146Sfz",
        "outputId": "45c438bc-60b6-489e-bb2e-b58990a45a10"
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-c2403f0759dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/test.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m                       \u001b[0;34m\"arg2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                   }})\n\u001b[0;32m--> 776\u001b[0;31m                   return config\"\"\"))\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: \nLayer PositionalEncoding has arguments ['self', 'position', 'd_model']\nin `__init__` and therefore must override `get_config()`.\n\nExample:\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2):\n        super().__init__()\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/test.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyOjF4jY7ZaL"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "file_uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U39L6drI4O3b"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/Colab Notebooks/result_smal_tpu_v5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syZcKMQ_pJFA"
      },
      "source": [
        "# **평가하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhMyPfQ0pMKd"
      },
      "outputs": [],
      "source": [
        "# 평가를 위해 함수 정의 (입력 값에 대한 preprocessing, evalueate로 전처리->디코더로 예측 시작, 디코더 결과확인)\n",
        "def preprocess_sentence(sentence):\n",
        "  # 단어와 구두점 사이에 공백 추가.\n",
        "  # ex) 12시 땡! -> 12시 땡 !\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence\n",
        "\n",
        "def evaluate(sentence):\n",
        "  # 입력 문장에 대한 전처리\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 예측 시작\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # 현재 시점의 예측 단어를 받아온다.\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
        "    # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  # 단어 예측이 모두 끝났다면 output을 리턴.\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
        "  # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu8d0dcApm3L"
      },
      "source": [
        "결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnEuL3cIpn0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6276c6-6cd7-41bc-ee04-3b5ef502303f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MS 오류들\n",
            "Input: unexpected #elif\n",
            "Output: 예기치 않은 #elif입니다 .\n",
            "Input: unknown option 'string' in 'option'\n",
            "Output: 알 수 없는 옵션 'string'이 'option'에 있습니다 .\n",
            "Input: cannot open file 'file'\n",
            "Output: 'file' 파일을 열 수 없습니다 .\n",
            "Input: unexpected end of file found in comment\n",
            "Output: 주석에서 예기치 않은 파일의 끝이 나타났습니다 .\n",
            "Input: compiler limit: internal heap limit reached; use /Zm to specify a higher limit\n",
            "Output: 컴파일러 한계: 내부 힙 한계에 도달했습니다 .  /Zm을 사용하여 한계를 더 높게 지정하세요 .\n",
            "Input: profile database 'file' is for a different architecture\n",
            "Output: 'file' 프로필 데이터베이스는 다른 아키텍처용입니다 .\n",
            "Input: initializers put in unrecognized initialization area\n",
            "Output: 이니셜라이저가 인식할 수 없는 초기화 영역에 있습니다 .\n",
            "Input: 'name': not available as a #pragma component\n",
            "Output: 'name': #pragma 구성 요소로 사용할 수 없음\n",
            "Input: 'label': unreferenced label\n",
            "Output: 'label': 참조되지 않은 레이블\n",
            "Input: illegal initialization\n",
            "Output: 불법 초기화\n",
            "\n",
            "의미없는 메시지\n",
            "Input: hello\n",
            "Output: 'character': 인식할 수 없는 문자 이스케이프 시퀀스\n",
            "Input: Choe-ji-hwan\n",
            "Output: 비배열의 첨자\n",
            "Input: 'num' is not defined\n",
            "Output: pragma 이름 '%s'이(가) 정의되지 않았습니다 .\n",
            "\n",
            "Watcom 오류들\n",
            "Input: too many parm sets\n",
            "Output: 너무 많은 매개변수 집합\n",
            "Input: const object must be initialized\n",
            "Output: const 개체를 초기화해야 합니다 .\n",
            "Input: destructor has a return type\n",
            "Output: 소멸자에 반환 유형이 있습니다 .\n",
            "Input: function '%S' has already been declared as a friend\n",
            "Output: 함수 '%S'은(는) 이미 friend로 선언되었습니다 .\n",
            "Input: expression for 'while' is always true\n",
            "Output: while'에 대한 식은 항상 참입니다 .\n",
            "Input: cannot find a constructor for given initializer argument list\n",
            "Output: 주어진 이니셜라이저 인수 목록에 대한 생성자를 찾을 수 없습니다 .\n",
            "\n",
            "digital mar 오류들\n",
            "Input: 'identifier' is a member of 'identifier' and 'identifier'\n",
            "Output: 함수 'identifier'의 배열 요소 형식은 함수가 될 수 없습니다 .\n",
            "Input: 'identifier' is a pure virtual function\n",
            "Output: 함수 'identifier'에 이미 본문이 있습니다 .\n",
            "Input: 'identifier' is already defined\n",
            "Output: 심볼 'identifier'이(가) 이미 정의되었습니다 .\n",
            "Input: 'identifier' is a virtual base class of 'identifier'\n",
            "Output: 'identifier': 부분적으로 초기화된 배열의 요소에는 기본 생성자가 있어야 합니다 .\n",
            "Input: 'identifier' is far\n",
            "Output: 함수 'identifier'의 배열 요소 있습니다 .\n",
            "Input: 'identifier' is not a class template\n",
            "Output: 피연산자는 클래스 멤버에 대한 유효한 포인터가 아닙니다 .\n",
            "Input: 'identifier' is not a constructor\n",
            "Output: ': 함수가 아닙니다 .\n",
            "Input: 'identifier' is not a correct struct\n",
            "Output: ': 함수가 아닙니다 .\n",
            "Input: 'identifier' is not a member of enum 'identifier'\n",
            "Output: 열거형 'enumeration'의 when에 있는 'identifier' 열거자가 처리되지 않습니다 .\n",
            "Input: 'identifier' is not a member of struct 'identifier'\n",
            "Output: 'identifier': 함수가 아닙니다 .\n",
            "Input: 'identifier' is not a member of forward referenced struct 'identifier'\n",
            "Output: 'identifier': 함수가 아닙니다 .\n",
            "Input: 'identifier' is not a struct or a class\n",
            "Output: tmp: 함수가 아닙니다 .\n",
            "Input: 'identifier' is not in function parameter list\n",
            "Output: 함수 선언이 다릅니다 .  한쪽에 가변 인수가 들어 있습니다 .\n",
            "Input: 'identifier' is not a variable\n",
            "Output: 'identifier': 함수가 아닙니다 .\n",
            "Input: 'identifier' must be a base class\n",
            "Output: 'identifier': 함수가 아닙니다 .\n",
            "Input: 'identifier' must be a class name preceding '::'\n",
            "Output: ': 함수가 아닙니다 .\n",
            "Input: 'identifier' must be a public base class of 'identifier'\n",
            "Output: 'identifier': 선언되지 않은 식별자\n",
            "Input: 'identifier' previously declared as something else\n",
            "Output: 'identifier': 레이블이 다시 정의됨\n",
            "Input: identifier storage class is illegal in this context\n",
            "Output: 익명 구조체/공용체는 이 컨텍스트에서 스토리지 클래스를 가질 수 없습니다 .\n",
            "Input: number actual arguments expected for identifier\n",
            "Output: 'identifier' 매크로의 실제 매개 변수가 너무 많습니다 .\n",
            "Input: number exceeds maximum of number parameters\n",
            "Output: 자동 할당이 size를 초과합니다 .\n",
            "Input: number operands expected for the identifier instruction\n",
            "Output: 구조체/클래스/소멸자에 대한 호출 규칙이 잘못되었습니다 .\n",
            "Input: ':' expected\n",
            "Output: 구문 오류\n",
            "Input: '::' or '(' expected after class 'identifier'\n",
            "Output: ('' 앞에 'else'가 와야 합니다 .\n",
            "Input: ';' expected\n",
            "Output: 점수' 앞에 ')'가 필요합니다 .\n",
            "Input: '\n",
            "Output: 비트 필드를 참조할 수 없습니다 .\n",
            "Input: ']' expected\n",
            "Output: ';' 토큰 앞에 ''이 필요합니다 .\n",
            "Input: '(' expected\n",
            "Output: %S' 심볼에 대한 참조가 없습니다 .\n",
            "Input: ')' expected\n",
            "Output: 익명 구조체/공용체에 열거형 인수 '%S'이(가) 포함되어 있습니다 .\n",
            "Input: '{' expected\n",
            "Output: break가 잘못되었습니다 .\n",
            "Input: '}' expected\n",
            "Output: 구문 오류\n",
            "Input: '{' or tag identifier expected\n",
            "Output: 괄호 안에 명명되지 않은 형식 정의\n",
            "Input: '='\n",
            "Output: 선언과 다른 형식 매개 변수 'parameter\\&undscnumber'입니다 .\n",
            "Input: // comments are not ANSI C\n",
            "Output: '*/'가 주석 외부에 있습니다 .\n",
            "Input: ## cannot appear at beginning or end\n",
            "Output: C를 사용하려면 구조체 또는 공용 구조체에 액세스할 수 없습니다 .\n",
            "Input: # must be followed by a parameter\n",
            "Output: 상수에 너무 많은 문자\n",
            "Input: '#else' or '#elif' found without '#if'\n",
            "Output: 소멸자를 'const' 토큰입니다 .\n",
            "Input: '#endif' found without '#if'\n",
            "Output: #line '토큰'을 찾은 줄 번호가 필요합니다 .\n",
            "Input: #include <typeinfo.h> in order to use RTTI\n",
            "Output: #include \"FILENAME\" 또는 <FILENAME>이 필요합니다 .\n",
            "Input: #pragma pack(pop) does not have corresponding push\n",
            "Output: #pragma warning(pop): 일치하는 '#pragma warning(push)'이 없습니다 .\n",
            "Input: '<' expected following cast\n",
            "Output: %u행에서 시작된 주석에서 중첩된 주석을 찾았습니다 .\n",
            "Input: '<' expected following 'identifier'\n",
            "Output: 식별자가 예상됩니다 .\n",
            "Input: '>' expected\n",
            "Output: ';' 토큰 앞에 ''이 필요합니다 .\n",
            "Input: 0 expected\n",
            "Output: 경고 수준은 0에서 9 사이의 정수여야 합니다 .\n",
            "Input: 0 or 1 expected\n",
            "Output: . '에 대한 표현식은 클래스 ,  구조체 또는 공용체여야 합니다 .\n",
            "Input: a '...' handler must be the last one for a try-block\n",
            "Output: C2 . DLL과 pgodbver . DLL의 버전이 일치하지 않습니다 .\n",
            "Input: a catch must follow a try-block\n",
            "Output: 선언문은 do문 다음에 올 수 없습니다 .\n",
            "Input: access declaration must be in public or protected section\n",
            "Output: 할당 또는 초기화 중에 정수 값이 잘릴 수 있습니다 .\n",
            "Input: a derived class member has the same name identifier\n",
            "Output: tmp: 함수가 아닙니다 .\n",
            "Input: alignment must be a power of 2\n",
            "Output: 구문 오류: 'token'\n",
            "Input: alloca() cannot be used in Windows functions\n",
            "Output: 초기화를 위한 올바른 표현식을 변환할 수 없습니다 .\n",
            "Input: already seen initializer for 'identifier'\n",
            "Output: is' 토큰 앞에 초기화문이 있어야 합니다 .\n",
            "Input: ambiguous reference to base class 'identifier'\n",
            "Output: 'identifier': 잘못된 스토리지 클래스\n",
            "Input: ambiguous reference to function\n",
            "Output: 기능에 대한 잘못된 스토리지 클래스\n",
            "Input: ambiguous type conversion\n",
            "Output: 컴파일러 한계: 배열 초기화에는 중괄호로 묶인 이니셜라이저 목록이 필요합니다 .\n",
            "Input: argument of type 'identifier' to copy constructor\n",
            "Output: #pragma 'pragma'(pop ,  .  .  . ): 이전에 푸시된 식별자 'identifier'를 팝했습니다 .\n",
            "Input: argument to postfix ++ or --must be int\n",
            "Output: type 파일을 닫을 수 없습니다 . 'file': message\n",
            "Input: array dimension must be > 0\n",
            "Output: 차원은 0일 수 없습니다 .\n",
            "Input: array of functions is illegal\n",
            "Output: a 배열 요소 형식은 함수가 될 수 없습니다 .\n",
            "Input: array of functions or refs is illegal\n",
            "Output: 배열 요소 수에 아니고 합니다 .\n",
            "Input: array or pointer required before '['\n",
            "Output: 부호 없는 또는 포인터 표현식은 항상 >= 0입니다 .\n",
            "Input: assembler opcode expected\n",
            "Output: %s\n",
            "Input: assignment to 'this' is obsolete\n",
            "Output: 시스템별 예외 처리가 없으므로 zo가 변환할 수 없습니다 .\n",
            "Input: at least one parameter must be a class or a class&\n",
            "Output: 왼쪽 피연산자는 포인터 ,  클래스 멤버에 대한 포인터 또는 산술이어야 합니다 .\n",
            "Input: bad -D switch\n",
            "Output: 비배열의 첨자\n",
            "Input: bad file name 'filename'\n",
            "Output: 예기치 않은 'token' 토큰입니다 .\n",
            "Input: bad member-initializer for 'identifier'\n",
            "Output: 스칼라가 아닌 필드 이니셜라이저 'identifier'\n",
            "Input: base class 'name' has different ambient memory model\n",
            "Output: file (message) 데이터 멤버에 액세스할 수 없습니다 .\n",
            "Input: binary exponent part required for hex floating constants\n",
            "Output: 'file' 문자열 액세스된  ';'을 열 수 없습니다 .  함수를 찾을 수 없습니다 .\n",
            "Input: blank arguments are illegal\n",
            "Output: 함수 템플릿은 형식 인수만 가질 수 있습니다 .\n",
            "Input: 'break' is valid only in a loop or switch\n",
            "Output: 표현식은 정수여야 합니다 .\n",
            "Input: can only delete pointers\n",
            "Output:  ,  데이터에 대한 포인터를 삭제할 수 없습니다 .\n",
            "Input: can't assign to const variable\n",
            "Output: const 개체를 초기화해야 합니다 .\n",
            "Input: can't build filespec 'filename'\n",
            "Output: 어셈블러 오류: '%s'\n",
            "Input: can't declare member of another class identifier\n",
            "Output: 이 컨텍스트에서 멤버 포인터의 클래스로 변환할 수 없습니다 .\n",
            "Input: can't handle constructor in this context\n",
            "Output: 이 컨텍스트에서는 type을 사용할 수 없습니다 .\n",
            "Input: can't have unnamed bit fields in unions\n",
            "Output: 구조체/공용체 멤버는 구조체 또는 공용 구조체에 하나 이상의 멤버가 있어야 합니다 .\n",
            "Input: can't open response file\n",
            "Output: 'file' 파일을 열 수 없습니다 .\n",
            "Input: can't pass const/volatile object to non-const/volatile member function\n",
            "Output: 비정적 멤버 함수에 액세스하는 데 필요한 개체(또는 개체 포인터)\n",
            "Input: can't return arrays\n",
            "Output: 함수는 배열을 반환할 수 없습니다 .\n",
            "Input: can't take address of register\n",
            "Output: 비트 필드의 주소를 사용할 수 없습니다 .\n",
            "Input: can't take sizeof bit field\n",
            "Output: 비트 필드를 참조할 수 없습니다 .\n",
            "Input: cannot convert identifier* to a private base class identifier*\n",
            "Output: 기본 생성자를 만들 수 없습니다 .\n",
            "Input: cannot create instance of abstract class 'identifier'\n",
            "Output: 오버로드된 함수 '%S'의 주소를 변환할 수 없습니다 .\n",
            "Input: cannot define parameter as extern\n",
            "Output: extern \"C\" 함수에 대한 인수에 컴파일러 생성 정보가 포함되어 있습니다 .\n",
            "Input: cannot delete pointer to const\n",
            "Output: 상수 데이터에 대한 포인터를 삭제할 수 없습니다 .\n",
            "Input: cannot find constructor for class matching\n",
            "Output: 구성원에 대한 잘못된 저장소 클래스\n",
            "Input: cannot generate identifier for class 'identifier'\n",
            "Output: 'identifier' 특성에 대한 처리기를 만들 수 없습니다 .\n",
            "Input: cannot generate template instance from -XI identifier\n",
            "Output: 템플릿 이름 '%s' 앞에 구문 오류가 있습니다 .\n",
            "Input: cannot have member initializer for 'identifier'\n",
            "Output: 'identifier' 배열 요소 형식은 함수가 될 수 없습니다 .\n",
            "Input: cannot implicitly convert\n",
            "Output: 참조 개체를 초기화해야 합니다 .\n",
            "Input: cannot mix C++ EH with NT structured EH\n",
            "Output: friend 클래스 선언은 클래스 정의를 포함할 수 없습니다 .\n",
            "Input: cannot raise or lower access to base member 'identifier'\n",
            "Output: 'identifier': 선언되지 않은 식별자\n",
            "Input: cannot throw object of 'identifier' not of ambient memory model\n",
            "Output: '%s'을(를) 생성하는 데 사용할 수 있는 세그먼트 레지스터가 충분하지 않습니다 .\n",
            "Input: case number was already used\n",
            "Output: 형식의 무해한 재정의\n",
            "Input: casts and sizeof are illegal in preprocessor expressions\n",
            "Output: 다른 기준의 식이 지정되었습니다 .\n",
            "Input: catch type masked by previous catch\n",
            "Output: 식을 함수로 사용할 수 없습니다 .\n",
            "Input: class name identifier expected after ~\n",
            "Output: 클래스 정의 내에서 데이터 멤버를 초기화할 수 없습니다 .\n",
            "Input: code segment too large\n",
            "Output: 알 수 없는 pragma입니다 .\n",
            "Input: comma not allowed in constant expression\n",
            "Output: 정수 상수 표현이 아닙니다 .\n",
            "Input: comments do not nest\n",
            "Output: '*/'가 주석 외부에 있습니다 .\n",
            "Input: compile all files with -EH to support exception handling\n",
            "Output: 임시 여는 괄호가 너무 많습니다 .\n",
            "Input: compile all files with -ER to support RTTI\n",
            "Output: 임시 객체를 초기화해야 합니다 .\n",
            "Input: const or reference 'identifier' needs initializer\n",
            "Output: 'identifier': 괄호가 있는 이니셜라이저를 사용하여 데이터 멤버를 초기화할 수 없습니다 .\n",
            "Input: constant expression does not fit in switch type\n",
            "Output: switch 식이 정수가 아님\n",
            "Input: constant initializer expected\n",
            "Output: 이니셜라이저가 이니셜라이저가 이니셜라이저가 너무 많습니다 .\n",
            "Input: 'continue' is valid only in a loop\n",
            "Output: 피연산자는 함수일 수 없습니다 .\n",
            "Input: conversion of int to far or handle pointer\n",
            "Output: 식에는 산술 ,  포인터 또는 클래스 멤버에 대한 포인터 유형이 있어야 합니다 .\n",
            "Input: data or code defined in precompiled header\n",
            "Output: 개체(또는 개체 포인터)를 사용하여 데이터에 액세스할 수 없습니다 .\n",
            "Input: declarator for 0 sized bit field\n",
            "Output: 선언자가 없는 익명 클래스는 쓸모가 없습니다 .\n",
            "Input: 'default:' is already used\n",
            "Output: default가 잘못되었습니다 .\n",
            "Input: different configuration for precompiled header\n",
            "Output: 'file' dll을 로드하는 동안 오류가 발생했습니다 .  호환되지 않는 버전입니다 .\n",
            "Input: divide by 0\n",
            "Output: '=' 토큰 앞에 기본 변환이 필요합니다 .\n",
            "Input: duplicate direct base class 'identifier'\n",
            "Output: 모호한 기능: %F가 %L을 정의하였음\n",
            "Input: DS is not equal to DGROUP\n",
            "Output: 편집하며 계속하기는 데이터 형식에 대한 변경 내용은 지원하지 않습니다 .  빌드해야 합니다 .\n",
            "Input: duplicate file names 'filename'\n",
            "Output: <' 토큰 앞에단항식이 필요합니다 .\n",
            "Input: empty declaration\n",
            "Output: 너비는 미리 너비는 양수여야 합니다 .\n",
            "Input: end of file found before '#endif'\n",
            "Output: 주석에서 예기치 않은 파일의 끝이 나타났습니다 .\n",
            "Input: end of file found before end of comment\n",
            "Output: 주석에서 예기치 않은 파일의 끝이 나타났습니다 .\n",
            "Input: end of line expected\n",
            "Output: 주석에서 예기치 않은 파일의 끝이 나타났습니다 .\n",
            "Input: error writing output file\n",
            "Output: 종료 \" 문자가 누락되었습니다 .\n",
            "Input: exception specifications must match exactly for each declaration of a function\n",
            "Output: 컴파일러 한계: 'function': 제어 흐름 상태가 너무 복잡합니다 .  함수를 간단하게 만드세요 .\n",
            "Input: expected assembler directive PTR to follow assembler cast\n",
            "Output: 'identifier1'에 대한 '(정의할 수 없습니다 .\n",
            "Input: expected data def of 'identifier'\n",
            "Output: 데이터 멤버 'identifier' 이후의 예기치 않은 토큰\n",
            "Input: exponent expected\n",
            "Output: 부울 식에서 할당을 찾았습니다 .\n",
            "Input: expression expected\n",
            "Output: ';' 토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에 ';'토큰 앞에\n",
            "Input: expression must be a pointer\n",
            "Output: 식에는 산술 ,  포인터 또는 클래스 멤버에 대한 포인터 유형이 있어야 합니다 .\n",
            "Input: expression must be a pointer or reference to a polymorphic type\n",
            "Output: if 문의 조건식은 항상 true입니다 .\n",
            "Input: external with block scope cannot have initializer\n",
            "Output: 파일은 최소한 하나의 외부 정의를 포함해야 합니다 .\n",
            "Input: '_far16' is only valid in -mf memory model\n",
            "Output: 데이터 개체의 주소가 너무 커서 'void*'로 변환할 수 없습니다 .\n",
            "Input: '_far16' functions can only be extern\n",
            "Output: extern \"C\" 함수에 대한 인수에 컴파일러 생성 정보가 포함되어 있습니다 .\n",
            "Input: field 'identifier' must be of integral type\n",
            "Output: 'identifier': 비트 필드에 간접 참조가 있을 수 없습니다 .\n",
            "Input: filespec string expected\n",
            "Output: 문자열 상수 앞에 ';'이(가) 필요합니다 .\n",
            "Input: __finally or __except expected\n",
            "Output: C 컴파일러에서 내부 오류가 발생했습니다 . \n",
            "(컴파일러 파일 'file' ,  형식 또는 네임스페이스 범위에서만 사용해야 합니다 .\n",
            "Input: forward referenced class 'identifier' cannot be a base class\n",
            "Output: 'identifier' 앞에 ')'가 있어야 합니다 .\n",
            "Input: function 'identifier' can't be in an anonymous union\n",
            "Output: identifier'의 왼쪽은 정의되지 않은 구조체/공용체 'type'을 지정합니다 .\n",
            "Input: function member 'identifier' has no prototype\n",
            "Output: 함수 a에 이미 본문이 있습니다 .\n",
            "Input: function 'identifier' is too complicated to inline\n",
            "Output: 함수 'identifier'에 이미 본문이 있습니다 .\n",
            "Input: function definition must have explicit parameter list\n",
            "Output: 순수 멤버 함수 상수는 '0'이어야 합니다 .\n",
            "Input: function expected\n",
            "Output: 함수를 초기화할 수 없습니다 .\n",
            "Input: functions can't return arrays or functions\n",
            "Output: 함수는 \\&undsc\\&undscself를 기반으로 하는 포인터를 반환할 수 없습니다 .\n",
            "Input: GetExceptionCode() only valid in exception filter or handler\n",
            "Output: def': alloc\\&undsctext는 C 링크가 있는 함수를 있습니다 .\n",
            "Input: GetExceptionInformation() only valid in exception filter\n",
            "Output: 컴파일러 한계: 'def' 함수에 예외 처리기 상태가 너무 많습니다 .  함수를 간단하게 만드세요 .\n",
            "Input: global anonymous unions must be static\n",
            "Output: 전역 익명 공용체는 '정적'으로 선언되어야 합니다 .\n",
            "Input: hex digit expected\n",
            "Output: 기본 'number'에 대한 숫자 'character'가 잘못되었습니다 .\n",
            "Input: identifier expected\n",
            "Output: 예기치 않은 식별자 i입니다 .\n",
            "Input: identifier found in abstract declarator\n",
            "Output: 클래스 템플릿 정의 시작됨 %L\n",
            "Input: identifier is longer than 254 chars\n",
            "Output: '()' 토큰 앞에 생성자 ,  소멸자 또는 형식 변환이 필요합니다 .\n",
            "Input: identifier or '(declarator) ' expected\n",
            "Output: 클래스 정의 내에서 이 함수를 정의합니다(나머지 폐기됨)\n",
            "Input: illegal addressing mode\n",
            "Output: 불법 초기화\n",
            "Input: illegal cast\n",
            "Output: continue가 잘못되었습니다 .\n",
            "Input: illegal character\n",
            "Output: )가 누락된 잘못된 매크로 정의입니다 .\n",
            "Input: illegal combination of types\n",
            "Output: 형식 한정자의 잘못된 조합\n",
            "Input: illegal constuctor or destructor declaration\n",
            "Output: 지역 변수 또는 임시 주소 반환\n",
            "Input: illegal operand\n",
            "Output: 'int' 잘못된 스토리지 클래스\n",
            "Input: illegal operand types\n",
            "Output: 피연산자는 클래스 템플릿 '%S'을(를) 오버로드할 수 없습니다 .\n",
            "Input: illegal pointer arithmetic\n",
            "Output: 포인터 또는 참조가 잘림\n",
            "Input: illegal return type for operator->()\n",
            "Output: i: 반환 형식이 없습니다 .  는 'int'를 반환하는  ?\n",
            "Input: illegal type combination\n",
            "Output: 형식 지정자의 잘못된 조합\n",
            "Input: illegal type for 'identifier' member\n",
            "Output: 식별자가 예상됩니다 .\n",
            "Input: illegal type/size of operands for the identifier instruction\n",
            "Output: 클래스/열거형 또는 토큰이 일치하지 않습니다 .\n",
            "Input: implied return at closing '}' does not return value\n",
            "Output: 설치된 런타임 버전에서는 제네릭이 지원되지 않습니다 .\n",
            "Input: initialization of 'identifier' is skipped\n",
            "Output: 'identifier': 함수 초기화\n",
            "Input: initializer for static member must be outside of class def\n",
            "Output: 선언자가 없는 익명 클래스는 쓸모가 없습니다 .\n",
            "Input: initializer or function body for dllimport not allowed\n",
            "Output: 주소 지정된 기능이 protected 클래스에 있습니다 .\n",
            "Input: integer constant expression expected\n",
            "Output: 정수 상수 식이 잘못되었습니다 .\n",
            "Input: integral expression expected\n",
            "Output: 식에는 산술 ,  포인터 또는 클래스 멤버에 대한 포인터 유형이 있어야 합니다 .\n",
            "Input: internal error identifier number\n",
            "Output: 내부 컴파일러 오류\n",
            "Input: invalid instruction set 'set' for memory model 'model'\n",
            "Output: 'file' 오브젝트 파일을 열 수 없습니다 .\n",
            "Input: invalid reference initialization\n",
            "Output: 캐스트 표현식을 변환할 수 없습니다 .\n",
            "Input: invalid storage class for friend\n",
            "Output: 기능에 대한 잘못된 스토리지 클래스\n",
            "Input: keyword not supported\n",
            "Output: 입력 파일을 지정하지 않았습니다 .\n",
            "Input: last line in file had no \n",
            "\n",
            "Output: 부울 식에서 할당을 찾았습니다 .\n",
            "Input: __leave must be within a __try block\n",
            "Output: 컴파일러 명령줄을 읽을 수 없습니다 .\n",
            "Input: line number expected\n",
            "Output: #line '토큰'을 찾은 줄 번호가 필요합니다 .\n",
            "Input: linkage specs are \"C\"\n",
            "Output: 명확성 중에 또 다른 모호한 구문이 발생했습니다 .\n",
            "Input: local class cannot have static data member 'identifier'\n",
            "Output: 익명 공용체 멤버 '%S'에 대한 참조가 없습니다 .\n",
            "Input: long long not supported for ANSI or 16 bit compiles\n",
            "Output: 함수 인수가 프로토타입의 인수와 일치하지 않습니다 .\n",
            "Input: lvalue expected\n",
            "Output: l 값은 감소 피연산자로 필요합니다 .\n",
            "Input: main()\n",
            "Output: main'을 참조할 수 없습니다 .\n",
            "Input: maximum width of number bits exceeded\n",
            "Output: 자동 할당이 size를 초과합니다 .\n",
            "Input: macro 'identifier' can't be #undef'd or #define'd\n",
            "Output: #undef에 식별자가 필요합니다 .\n",
            "Input: malformed template declaration\n",
            "Output: 템플릿 치명적인*** %s\n",
            "Input: maximum length of macro text exceeded\n",
            "Output: 잘못된 8진 상수입니다\n",
            "Input: max of number characters in string exceeded\n",
            "Output: 문자열 상수 와이드 문자 두번째 목록보다 깁니다 .\n",
            "Input: member 'identifier' can't be same type as struct 'identifier'\n",
            "Output: i: 내장 함수로 사용할 수 없음\n",
            "Input: member 'identifier' is const but there is no constructor\n",
            "Output: 'identifier': 부분적으로 초기화된 배열의 요소에는 기본 생성자가 있어야 합니다 .\n",
            "Input: member 'identifier' of class 'identifier' is not accessible\n",
            "Output: 오버로드된 함수 '%S'은(는) 구성원이 아니므로 초기화할 수 없습니다 .\n",
            "Input: member 'identifier' of class 'identifier' is private\n",
            "Output: 'identifier': 괄호가 있는 이니셜라이저를 사용하여 데이터 멤버를 초기화할 수 없습니다 .\n",
            "Input: missing '\n",
            "Output: %u행에서 시작된 주석에서 중첩된 주석을 찾았습니다 .\n",
            "Input: missing decl-specifier-seq for declaration of 'identifier'\n",
            "Output: 초기화할 수 없습니다 .  error\n",
            "Input: must be void operator delete(void *[, size_t]);\n",
            "Output: 인수가 너무 적어서 'int printf(constchar* ,   .  .  . )' 기능을 수행할 수 없습니다 .\n",
            "Input: must use delete[] for arrays\n",
            "Output: 배열 첨자의 유형 'int(constchar* ,   .  .  . )'[constchar [11]'이(가) 잘못되었습니다 .\n",
            "Input: need at least one external def\n",
            "Output: 파일은 최소한 하나의 외부 정의를 포함해야 합니다 .\n",
            "Input: no constructor allowed for class 'identifier'\n",
            "Output: 'identifier' 특성에 대한 처리기를 만들 수 없습니다 .\n",
            "Input: no definition for static 'identifier'\n",
            "Output: identifier' 뒤에 '('이 와야 합니다 .\n",
            "Input: no identifier for declarator\n",
            "Output: 내부 컴파일러 오류 %d\n",
            "Input: no input file specified\n",
            "Output: 입력 파일을 지정하지 않았습니다 .\n",
            "Input: no instance of class 'identifier'\n",
            "Output: identifier': 정렬(가) 일치하는/공용체에 변수의 주소 필요합니다 .\n",
            "Input: no instance of class 'identifier' for member 'identifier'\n",
            "Output: 'identifier': 잘못된 스토리지 클래스\n",
            "Input: no match for function 'identifier'\n",
            "Output: 'identifier' 매크로의 실제 매개 변수가 너무 많습니다 .\n",
            "Input: no return value for function 'identifier'\n",
            "Output: 'function': 반환 값 없음\n",
            "Input: no tag name for struct or enum\n",
            "Output: 포인터 또는 참조가 잘림\n",
            "Input: non-const reference initialized to temporary\n",
            "Output: const 멤버가 있는 클래스에는 생성자가 필요합니다 .\n",
            "Input: not a struct or union type\n",
            "Output: C를 사용하려면 구조체 또는 공용 구조체에 하나 이상의 멤버가 있어야 합니다 .\n",
            "Input: not an overloadable operator token\n",
            "Output: 오버로드된 레이블 '%s'이(가) 함수에 정의되어 있지 않습니다 .\n",
            "Input: not in a switch statement\n",
            "Output: 선언문이 switch 문 다음에 나옵니다 .\n",
            "Input: number 'number' is too large\n",
            "Output: 표현식은 산술 계산이어야 합니다 .\n",
            "Input: number is not representable\n",
            "Output: ##은 교체 토큰의 시작 또는 끝에 있으면 안 됩니다 .\n",
            "Input: object has 0 size\n",
            "Output: 참조 개체를 초기화해야 합니다 .\n",
            "Input: octal digit expected\n",
            "Output: 포인터 또는 참조가 잘림\n",
            "Input: one argument req'd for member initializer for 'identifier'\n",
            "Output: 'identifier': 'type'의 형식은 단일 이니셜라이저 식에서만 추론할 수 있습니다 .\n",
            "Input: only classes and functions can be friends\n",
            "Output: 전역 범위에 빈 문장이 있습니다 .\n",
            "Input: only one identifier is allowed to appear in a declaration appearing in a conditional expression\n",
            "Output: C를 사용하려면 구조체 또는 공용 구조체에 하나 이상의 멤버가 있어야 합니다 .\n",
            "Input: operator overload must be a function\n",
            "Output: i: 함수여야 합니다 .\n",
            "Input: out of memory\n",
            "Output: 메모리가 부족합니다 .\n",
            "Input: overloaded function 'identifier' has different access levels\n",
            "Output: 오버로드된 함수를 잘못 사용했습니다 .  인수 목록이 없나요 ?\n",
            "Input: parameter list is out of context\n",
            "Output: 공식 매개 변수 i의 재정의\n",
            "Input: parameter lists do not match for template 'identifier'\n",
            "Output: 'identifier' 매크로의 실제 매개 변수가 부족합니다 .\n",
            "Input: pascal string length number is longer than 255\n",
            "Output: 문자열 상수 앞에 ';'이액세스된 protected 버전이 필요합니다 .\n",
            "Input: pointer required before '->'\n",
            "Output: 이 범위에서는 'Sleep'이 선언되지 않았습니다 .\n",
            "Input: pointer required before '->' or after '*'\n",
            "Output: 포인터 또는 참조가 잘림\n",
            "Input: pointer to member expected to right of .* or ->*\n",
            "Output: 값이 0인 클래스 멤버에 대한 포인터와 함께 ' . *' 또는 '->*'로 변환하는 수 없습니다 .\n",
            "Input: possible extraneous ';'\n",
            "Output: 익명 구조체/공용체에 개인 멤버 '%S'이(가) 포함되어 있습니다 .\n",
            "Input: possible unintended assignment\n",
            "Output: 종료 \" 문자가 누락되었습니다 .\n",
            "Input: pragma cseg must be at global scope\n",
            "Output: #pragma 'pragma'는 전역 범위 또는 네임스페이스 범위에서만 사용해야 합니다 .\n",
            "Input: precompiled header compiled with C instead of C++\n",
            "Output: 부동 소수점 잘못되었습니다 .\n",
            "Input: precompiled header compiled with C++ instead of C\n",
            "Output: 'file'을 링크할 때 PGO\\&undscPATH\\&undscTRANSLATION의 설정이 잘못되었습니다 .\n",
            "Input: prefix opcode must be followed by an assembler opcode\n",
            "Output: 프로필 데이터가 수집된 이후 프로그램이 편집되었습니다 .\n",
            "Input: premature end of source file\n",
            "Output: 알 수 없는 오류 ,  Visual C++ 도움말 메뉴에서 기술 지원 명령을 선택하거나 기술 지원 도움말 파일을 열어 자세한 내용을 확인하세요 .\n",
            "Input: prototype for 'identifier' should be identifier\n",
            "Output: 표현식은 'this'를 참조할 수 없습니다 .\n",
            "Input: pure function must be virtual\n",
            "Output: 순수 멤버 함수 상수는 '0'이어야 합니다 .\n",
            "Input: qualifier or type in access declaration\n",
            "Output: 지역 변수 또는 임시 주소 반환\n",
            "Input: recursive prototype\n",
            "Output: 재귀 형식 또는 함수 종속성 맥락이 너무 복잡합니다 .\n",
            "Input: redefinition of default parameter\n",
            "Output: a: 재정의\n",
            "Input: reference to 'identifier' caused a 386 instruction to be generated\n",
            "Output: 표현식을 공용체 멤버 '%S'에 대한 참조가 없습니다 .\n",
            "Input: reference must refer to same type or be const\n",
            "Output: const 또는 volatile 참조를 일반 참조로 변환\n",
            "Input: return type cannot be specified for conversion function\n",
            "Output: 휘발성 개체에 대한 포인터나 참조를 반환할 수 없습니다 .\n",
            "Input: returning address of automatic 'identifier'\n",
            "Output: 오버로드된 함수 '%S'의 주소를 변환할 수 없습니다 .\n",
            "Input: segment size is number\n",
            "Output: 크기가 0인 배열은 마지막 데이터 멤버여야 합니다 .\n",
            "Input: should be number parameter(s) for operator\n",
            "Output: %F(%L)에서 포함됨\n",
            "Input: size of identifier is not known\n",
            "Output: ##은 교체 토큰의 시작 또는 끝에 있으면 안 됩니다 .\n",
            "Input: size of type exceeds 64KB\n",
            "Output: 자동 할당이 size를 초과합니다 .\n",
            "Input: statement expected\n",
            "Output: 레이블 뒤에 문장이 필요합니다 .\n",
            "Input: static function 'identifier' can't be virtual\n",
            "Output: 함수 'identifier'에 이미 본문이 있습니다 .\n",
            "Input: static or non-member functions can't be const or volatile\n",
            "Output: 항목이 비정적 멤버 함수도 데이터 멤버도 아닙니다 .\n",
            "Input: static variables in inline functions not allowed\n",
            "Output: 정적 데이터 멤버는 공용체에서 허용되지 않습니다 .\n",
            "Input: storage class for 'identifier' can't be both extern and inline\n",
            "Output: 'for' 앞에 ';'가 필요합니다 .\n",
            "Input: string expected\n",
            "Output: 문자열 상수 앞에 ';'이(가) 필요합니다 .\n",
            "Input: struct-declaration-list can't be empty\n",
            "Output: 서로 다른 기준 'base1'과 'base2'를 지정했습니다 .\n",
            "Input: template-argument 'identifier' must be a type-argument\n",
            "Output: '%S'에 대한 함수 템플릿 바인딩이 %L이었습니다 .\n",
            "Input: template-argument 'identifier' not used in function parameter types\n",
            "Output: 함수 템플릿 '%S'에 이미 정의가 있습니다 .\n",
            "Input: too many errors\n",
            "Output: 매크로 '%s'에 너무 많은 문자\n",
            "Input: too many initializers\n",
            "Output: 초기화 값이 너무 많습니다 .\n",
            "Input: trailing parameters must have initializers\n",
            "Output: 초기화 값이 너무 많습니다 .\n",
            "Input: __try only valid for -mn memory model\n",
            "Output: 내부 메모리 관리 오류입니다 .\n",
            "Input: type conversions must be members\n",
            "Output: 유형이 아닌 인수에 유형 매개변수가 제공됨\n",
            "Input: type is too complex\n",
            "Output: 명령문이 너무 복잡합니다 .\n",
            "Input: type mismatch\n",
            "Output: 초기화 값이 너무 많습니다 .\n",
            "Input: type must be a pointer or a reference to a defined class or void*\n",
            "Output: 함수 주소를 클래스 멤버에 대한 포인터로 변환할 수 없습니다 .\n",
            "Input: type must be void *operator new(size_t [,..]);\n",
            "Output: 오른쪽 피연산자는 'this'여야 합니다 .\n",
            "Input: type of 'identifier' does not match function prototype\n",
            "Output: 함수 인수가 프로토타입의 인수와 일치하지 않습니다 .\n",
            "Input: types may not appear more than once in an exception specification\n",
            "Output: 버전이 편집하며 계속하기는 데이터 수정자를 사용할 수 없습니다 .\n",
            "Input: unable to open input file 'filename'\n",
            "Output: 'file' 파일을 열 수 없습니다 .\n",
            "Input: unable to open output file 'filename'\n",
            "Output: 'C' 는 정의되지 않은 ID가 필요합니다 .\n",
            "Input: undefined escape sequence\n",
            "Output: 정의되지 않은 형식 'type'의 사용\n",
            "Input: undefined identifier 'identifier'\n",
            "Output: 함수 'identifier'에 이미 본문이 있습니다 .\n",
            "Input: undefined label 'identifier'\n",
            "Output: 레이블 'identifier'가 정의되지 않았습니다 .\n",
            "Input: undefined tag 'identifier'\n",
            "Output: 함수 'identifier'에 이미 본문이 있습니다 .\n",
            "Input: undefined use of struct or union\n",
            "Output: identifier'의 왼쪽은 정의되지 않은 구조체/공용체 'type'을 지정합니다 .\n",
            "Input: unknown operand type for this floating point instruction\n",
            "Output: 상수 표현식에서 0으로 나누기\n",
            "Input: union members cannot have ctors or dtors\n",
            "Output: C를 사용하려면 구조체 또는 공용 구조체에 하나 이상의 멤버가 있어야 합니다 .\n",
            "Input: unrecognized pragma\n",
            "Output: 조건식이 상수입니다 .\n",
            "Input: unrecognized parameter 'identifier'\n",
            "Output: 식별자가 예상됩니다 .\n",
            "Input: unrecognized preprocessing directive '#identifier'\n",
            "Output: #undef에 식별자가 필요합니다 .\n",
            "Input: unrecognized token\n",
            "Output: 이니셜라이저가 인식할 수 없는 초기화 영역에 있습니다 .\n",
            "Input: unsupported based type\n",
            "Output: 반환 식을 변환하기 위해 액세스한 private  클래스\n",
            "Input: unsupported __declspec type\n",
            "Output: l 값은 감소 피연산자로 필요합니다 .\n",
            "Input: unterminated macro argument\n",
            "Output: 유형 이름 '%s' 앞에 구문 오류가 있습니다 .\n",
            "Input: unterminated string\n",
            "Output: 예기치 않은 #endif입니다 .\n",
            "Input: use delete[] rather than delete[expr]\n",
            "Output: delete'에 배열 표현식은 배열 표현식은 배열 표현식은 배열 표현식은 배열 형식을 사용하지 않고 배열 초기화 유형이 너무 많고 있습니다 .\n",
            "Input: using operator++() (or --) instead of missing operator++(int)\n",
            "Output: 미리 컴파일된 헤더 파일을 사용할 수 없습니다(다른 #include 파일) .\n",
            "Input: valid memory models are -m[tsmcrzlvfnpx]\n",
            "Output: 컴파일러 한계: 내부 힙 한계에 도달했습니다 .  /Zm을 사용하여 한계를 더 높게 지정하세요 .\n",
            "Input: value of expression is not used\n",
            "Output: 정수 상수 표현이 아닙니다 .\n",
            "Input: variable 'identifier' used before set\n",
            "Output: 식별자가 예상됩니다 .\n",
            "Input: vectors cannot have initializers\n",
            "Output: 초기화 값이 너무 많습니다 .\n",
            "Input: very large automatic\n",
            "Output: 부동 소수점 상수가 너무 커서 표현할 수 없습니다 .\n",
            "Input: voids have no value\n",
            "Output: 'function': 실제 매개 변수의 형식이 'void': 매개 변수 번호\n",
            "Input: voids have no value\n",
            "Output: 'function': 실제 매개 변수의 형식이 'void': 매개 변수 번호\n",
            "Input: 'while' expected\n",
            "Output: '정의된 ID'가 필요합니다 .\n"
          ]
        }
      ],
      "source": [
        "# MS 오류들\n",
        "with strategy.scope():\n",
        "  print(\"\\nMS 오류들\")\n",
        "  output = predict(\"unexpected #elif\")\n",
        "  output = predict(\"unknown option 'string' in 'option'\")\n",
        "  output = predict(\"cannot open file 'file'\")\n",
        "  output = predict(\"unexpected end of file found in comment\")\n",
        "  output = predict(\"compiler limit: internal heap limit reached; use /Zm to specify a higher limit\")\n",
        "  output = predict(\"profile database 'file' is for a different architecture\")\n",
        "  output = predict(\"initializers put in unrecognized initialization area\")\n",
        "  output = predict(\"'name': not available as a #pragma component\")\n",
        "  output = predict(\"'label': unreferenced label\")\n",
        "  output = predict(\"illegal initialization\")\n",
        "\n",
        "  print(\"\\n의미없는 메시지\")\n",
        "  # 의미 없는 메시지\n",
        "  output = predict(\"hello\")\n",
        "  output = predict(\"Choe-ji-hwan\")\n",
        "  output = predict(\"'num' is not defined\")\n",
        "\n",
        "  # Watcom 오류들\n",
        "  print(\"\\nWatcom 오류들\")\n",
        "  output = predict(\"too many parm sets\")\n",
        "  output = predict(\"const object must be initialized\")\n",
        "  output = predict(\"destructor has a return type\")\n",
        "  output = predict(\"function '%S' has already been declared as a friend\")\n",
        "  output = predict(\"expression for 'while' is always true\")\n",
        "  output = predict(\"cannot find a constructor for given initializer argument list\")\n",
        "\n",
        "  #digital mars 오류들\n",
        "  print(\"\\ndigital mar 오류들\")\n",
        "  output = predict(\"'identifier' is a member of 'identifier' and 'identifier'\")\n",
        "  output = predict(\"'identifier' is a pure virtual function\")\n",
        "  output = predict(\"'identifier' is already defined\")\n",
        "  output = predict(\"'identifier' is a virtual base class of 'identifier'\")\n",
        "  output = predict(\"'identifier' is far\")\n",
        "  output = predict(\"'identifier' is not a class template\")\n",
        "  output = predict(\"'identifier' is not a constructor\")\n",
        "  output = predict(\"'identifier' is not a correct struct\")\n",
        "  output = predict(\"'identifier' is not a member of enum 'identifier'\")\n",
        "  output = predict(\"'identifier' is not a member of struct 'identifier'\")\n",
        "  output = predict(\"'identifier' is not a member of forward referenced struct 'identifier'\")\n",
        "  output = predict(\"'identifier' is not a struct or a class\")\n",
        "  output = predict(\"'identifier' is not in function parameter list\")\n",
        "  output = predict(\"'identifier' is not a variable\")\n",
        "  output = predict(\"'identifier' must be a base class\")\n",
        "  output = predict(\"'identifier' must be a class name preceding '::'\")\n",
        "  output = predict(\"'identifier' must be a public base class of 'identifier'\")\n",
        "  output = predict(\"'identifier' previously declared as something else\")\n",
        "  output = predict(\"identifier storage class is illegal in this context\")\n",
        "  output = predict(\"number actual arguments expected for identifier\")\n",
        "  output = predict(\"number exceeds maximum of number parameters\")\n",
        "  output = predict(\"number operands expected for the identifier instruction\")\n",
        "  output = predict(\"':' expected\")\n",
        "  output = predict(\"'::' or '(' expected after class 'identifier'\")\n",
        "  output = predict(\"';' expected\")\n",
        "  output = predict(\"'\")\n",
        "  output = predict(\"']' expected\")\n",
        "  output = predict(\"'(' expected\")\n",
        "  output = predict(\"')' expected\")\n",
        "  output = predict(\"'{' expected\")\n",
        "  output = predict(\"'}' expected\")\n",
        "  output = predict(\"'{' or tag identifier expected\")\n",
        "  output = predict(\"'='\")\n",
        "  output = predict(\"// comments are not ANSI C\")\n",
        "  output = predict(\"## cannot appear at beginning or end\")\n",
        "  output = predict(\"# must be followed by a parameter\")\n",
        "  output = predict(\"'#else' or '#elif' found without '#if'\")\n",
        "  output = predict(\"'#endif' found without '#if'\")\n",
        "  output = predict(\"#include <typeinfo.h> in order to use RTTI\")\n",
        "  output = predict(\"#pragma pack(pop) does not have corresponding push\")\n",
        "  output = predict(\"'<' expected following cast\")\n",
        "  output = predict(\"'<' expected following 'identifier'\")\n",
        "  output = predict(\"'>' expected\")\n",
        "  output = predict(\"0 expected\")\n",
        "  output = predict(\"0 or 1 expected\")\n",
        "  output = predict(\"a '...' handler must be the last one for a try-block\")\n",
        "  output = predict(\"a catch must follow a try-block\")\n",
        "  output = predict(\"access declaration must be in public or protected section\")\n",
        "  output = predict(\"a derived class member has the same name identifier\")\n",
        "  output = predict(\"alignment must be a power of 2\")\n",
        "  output = predict(\"alloca() cannot be used in Windows functions\")\n",
        "  output = predict(\"already seen initializer for 'identifier'\")\n",
        "  output = predict(\"ambiguous reference to base class 'identifier'\")\n",
        "  output = predict(\"ambiguous reference to function\")\n",
        "  output = predict(\"ambiguous type conversion\")\n",
        "  output = predict(\"argument of type 'identifier' to copy constructor\")\n",
        "  output = predict(\"argument to postfix ++ or --must be int\")\n",
        "  output = predict(\"array dimension must be > 0\")\n",
        "  output = predict(\"array of functions is illegal\")\n",
        "  output = predict(\"array of functions or refs is illegal\")\n",
        "  output = predict(\"array or pointer required before '['\")\n",
        "  output = predict(\"assembler opcode expected\")\n",
        "  output = predict(\"assignment to 'this' is obsolete\")\n",
        "  output = predict(\"at least one parameter must be a class or a class&\")\n",
        "  output = predict(\"bad -D switch\")\n",
        "  output = predict(\"bad file name 'filename'\")\n",
        "  output = predict(\"bad member-initializer for 'identifier'\")\n",
        "  output = predict(\"base class 'name' has different ambient memory model\")\n",
        "  output = predict(\"binary exponent part required for hex floating constants\")\n",
        "  output = predict(\"blank arguments are illegal\")\n",
        "  output = predict(\"'break' is valid only in a loop or switch\")\n",
        "  output = predict(\"can only delete pointers\")\n",
        "  output = predict(\"can't assign to const variable\")\n",
        "  output = predict(\"can't build filespec 'filename'\")\n",
        "  output = predict(\"can't declare member of another class identifier\")\n",
        "  output = predict(\"can't handle constructor in this context\")\n",
        "  output = predict(\"can't have unnamed bit fields in unions\")\n",
        "  output = predict(\"can't open response file\")\n",
        "  output = predict(\"can't pass const/volatile object to non-const/volatile member function\")\n",
        "  output = predict(\"can't return arrays\")\n",
        "  output = predict(\"can't take address of register\")\n",
        "  output = predict(\"can't take sizeof bit field\")\n",
        "  output = predict(\"cannot convert identifier* to a private base class identifier*\")\n",
        "  output = predict(\"cannot create instance of abstract class 'identifier'\")\n",
        "  output = predict(\"cannot define parameter as extern\")\n",
        "  output = predict(\"cannot delete pointer to const\")\n",
        "  output = predict(\"cannot find constructor for class matching\")\n",
        "  output = predict(\"cannot generate identifier for class 'identifier'\")\n",
        "  output = predict(\"cannot generate template instance from -XI identifier\")\n",
        "  output = predict(\"cannot have member initializer for 'identifier'\")\n",
        "  output = predict(\"cannot implicitly convert\")\n",
        "  output = predict(\"cannot mix C++ EH with NT structured EH\")\n",
        "  output = predict(\"cannot raise or lower access to base member 'identifier'\")\n",
        "  output = predict(\"cannot throw object of 'identifier' not of ambient memory model\")\n",
        "  output = predict(\"case number was already used\")\n",
        "  output = predict(\"casts and sizeof are illegal in preprocessor expressions\")\n",
        "  output = predict(\"catch type masked by previous catch\")\n",
        "  output = predict(\"class name identifier expected after ~\")\n",
        "  output = predict(\"code segment too large\")\n",
        "  output = predict(\"comma not allowed in constant expression\")\n",
        "  output = predict(\"comments do not nest\")\n",
        "  output = predict(\"compile all files with -EH to support exception handling\")\n",
        "  output = predict(\"compile all files with -ER to support RTTI\")\n",
        "  output = predict(\"const or reference 'identifier' needs initializer\")\n",
        "  output = predict(\"constant expression does not fit in switch type\")\n",
        "  output = predict(\"constant initializer expected\")\n",
        "  output = predict(\"'continue' is valid only in a loop\")\n",
        "  output = predict(\"conversion of int to far or handle pointer\")\n",
        "  output = predict(\"data or code defined in precompiled header\")\n",
        "  output = predict(\"declarator for 0 sized bit field\")\n",
        "  output = predict(\"'default:' is already used\")\n",
        "  output = predict(\"different configuration for precompiled header\")\n",
        "  output = predict(\"divide by 0\")\n",
        "  output = predict(\"duplicate direct base class 'identifier'\")\n",
        "  output = predict(\"DS is not equal to DGROUP\")\n",
        "  output = predict(\"duplicate file names 'filename'\")\n",
        "  output = predict(\"empty declaration\")\n",
        "  output = predict(\"end of file found before '#endif'\")\n",
        "  output = predict(\"end of file found before end of comment\")\n",
        "  output = predict(\"end of line expected\")\n",
        "  output = predict(\"error writing output file\")\n",
        "  output = predict(\"exception specifications must match exactly for each declaration of a function\")\n",
        "  output = predict(\"expected assembler directive PTR to follow assembler cast\")\n",
        "  output = predict(\"expected data def of 'identifier'\")\n",
        "  output = predict(\"exponent expected\")\n",
        "  output = predict(\"expression expected\")\n",
        "  output = predict(\"expression must be a pointer\")\n",
        "  output = predict(\"expression must be a pointer or reference to a polymorphic type\")\n",
        "  output = predict(\"external with block scope cannot have initializer\")\n",
        "  output = predict(\"'_far16' is only valid in -mf memory model\")\n",
        "  output = predict(\"'_far16' functions can only be extern\")\n",
        "  output = predict(\"field 'identifier' must be of integral type\")\n",
        "  output = predict(\"filespec string expected\")\n",
        "  output = predict(\"__finally or __except expected\")\n",
        "  output = predict(\"forward referenced class 'identifier' cannot be a base class\")\n",
        "  output = predict(\"function 'identifier' can't be in an anonymous union\")\n",
        "  output = predict(\"function member 'identifier' has no prototype\")\n",
        "  output = predict(\"function 'identifier' is too complicated to inline\")\n",
        "  output = predict(\"function definition must have explicit parameter list\")\n",
        "  output = predict(\"function expected\")\n",
        "  output = predict(\"functions can't return arrays or functions\")\n",
        "  output = predict(\"GetExceptionCode() only valid in exception filter or handler\")\n",
        "  output = predict(\"GetExceptionInformation() only valid in exception filter\")\n",
        "  output = predict(\"global anonymous unions must be static\")\n",
        "  output = predict(\"hex digit expected\")\n",
        "  output = predict(\"identifier expected\")\n",
        "  output = predict(\"identifier found in abstract declarator\")\n",
        "  output = predict(\"identifier is longer than 254 chars\")\n",
        "  output = predict(\"identifier or '(declarator) ' expected\")\n",
        "  output = predict(\"illegal addressing mode\")\n",
        "  output = predict(\"illegal cast\")\n",
        "  output = predict(\"illegal character\")\n",
        "  output = predict(\"illegal combination of types\")\n",
        "  output = predict(\"illegal constuctor or destructor declaration\")\n",
        "  output = predict(\"illegal operand\")\n",
        "  output = predict(\"illegal operand types\")\n",
        "  output = predict(\"illegal pointer arithmetic\")\n",
        "  output = predict(\"illegal return type for operator->()\")\n",
        "  output = predict(\"illegal type combination\")\n",
        "  output = predict(\"illegal type for 'identifier' member\")\n",
        "  output = predict(\"illegal type/size of operands for the identifier instruction\")\n",
        "  output = predict(\"implied return at closing '}' does not return value\")\n",
        "  output = predict(\"initialization of 'identifier' is skipped\")\n",
        "  output = predict(\"initializer for static member must be outside of class def\")\n",
        "  output = predict(\"initializer or function body for dllimport not allowed\")\n",
        "  output = predict(\"integer constant expression expected\")\n",
        "  output = predict(\"integral expression expected\")\n",
        "  output = predict(\"internal error identifier number\")\n",
        "  output = predict(\"invalid instruction set 'set' for memory model 'model'\")\n",
        "  output = predict(\"invalid reference initialization\")\n",
        "  output = predict(\"invalid storage class for friend\")\n",
        "  output = predict(\"keyword not supported\")\n",
        "  output = predict(\"last line in file had no \\n\")\n",
        "  output = predict(\"__leave must be within a __try block\")\n",
        "  output = predict(\"line number expected\")\n",
        "  output = predict('linkage specs are \"C\"')\n",
        "  output = predict(\"local class cannot have static data member 'identifier'\")\n",
        "  output = predict(\"long long not supported for ANSI or 16 bit compiles\")\n",
        "  output = predict(\"lvalue expected\")\n",
        "  output = predict(\"main()\")\n",
        "  output = predict(\"maximum width of number bits exceeded\")\n",
        "  output = predict(\"macro 'identifier' can't be #undef'd or #define'd\")\n",
        "  output = predict(\"malformed template declaration\")\n",
        "  output = predict(\"maximum length of macro text exceeded\")\n",
        "  output = predict(\"max of number characters in string exceeded\")\n",
        "  output = predict(\"member 'identifier' can't be same type as struct 'identifier'\")\n",
        "  output = predict(\"member 'identifier' is const but there is no constructor\")\n",
        "  output = predict(\"member 'identifier' of class 'identifier' is not accessible\")\n",
        "  output = predict(\"member 'identifier' of class 'identifier' is private\")\n",
        "  output = predict(\"missing '\")\n",
        "  output = predict(\"missing decl-specifier-seq for declaration of 'identifier'\")\n",
        "  output = predict(\"must be void operator delete(void *[, size_t]);\")\n",
        "  output = predict(\"must use delete[] for arrays\")\n",
        "  output = predict(\"need at least one external def\")\n",
        "  output = predict(\"no constructor allowed for class 'identifier'\")\n",
        "  output = predict(\"no definition for static 'identifier'\")\n",
        "  output = predict(\"no identifier for declarator\")\n",
        "  output = predict(\"no input file specified\")\n",
        "  output = predict(\"no instance of class 'identifier'\")\n",
        "  output = predict(\"no instance of class 'identifier' for member 'identifier'\")\n",
        "  output = predict(\"no match for function 'identifier'\")\n",
        "  output = predict(\"no return value for function 'identifier'\")\n",
        "  output = predict(\"no tag name for struct or enum\")\n",
        "  output = predict(\"non-const reference initialized to temporary\")\n",
        "  output = predict(\"not a struct or union type\")\n",
        "  output = predict(\"not an overloadable operator token\")\n",
        "  output = predict(\"not in a switch statement\")\n",
        "  output = predict(\"number 'number' is too large\")\n",
        "  output = predict(\"number is not representable\")\n",
        "  output = predict(\"object has 0 size\")\n",
        "  output = predict(\"octal digit expected\")\n",
        "  output = predict(\"one argument req'd for member initializer for 'identifier'\")\n",
        "  output = predict(\"only classes and functions can be friends\")\n",
        "  output = predict(\"only one identifier is allowed to appear in a declaration appearing in a conditional expression\")\n",
        "  output = predict(\"operator overload must be a function\")\n",
        "  output = predict(\"out of memory\")\n",
        "  output = predict(\"overloaded function 'identifier' has different access levels\")\n",
        "  output = predict(\"parameter list is out of context\")\n",
        "  output = predict(\"parameter lists do not match for template 'identifier'\")\n",
        "  output = predict(\"pascal string length number is longer than 255\")\n",
        "  output = predict(\"pointer required before '->'\")\n",
        "  output = predict(\"pointer required before '->' or after '*'\")\n",
        "  output = predict(\"pointer to member expected to right of .* or ->*\")\n",
        "  output = predict(\"possible extraneous ';'\")\n",
        "  output = predict(\"possible unintended assignment\")\n",
        "  output = predict(\"pragma cseg must be at global scope\")\n",
        "  output = predict(\"precompiled header compiled with C instead of C++\")\n",
        "  output = predict(\"precompiled header compiled with C++ instead of C\")\n",
        "  output = predict(\"prefix opcode must be followed by an assembler opcode\")\n",
        "  output = predict(\"premature end of source file\")\n",
        "  output = predict(\"prototype for 'identifier' should be identifier\")\n",
        "  output = predict(\"pure function must be virtual\")\n",
        "  output = predict(\"qualifier or type in access declaration\")\n",
        "  output = predict(\"recursive prototype\")\n",
        "  output = predict(\"redefinition of default parameter\")\n",
        "  output = predict(\"reference to 'identifier' caused a 386 instruction to be generated\")\n",
        "  output = predict(\"reference must refer to same type or be const\")\n",
        "  output = predict(\"return type cannot be specified for conversion function\")\n",
        "  output = predict(\"returning address of automatic 'identifier'\")\n",
        "  output = predict(\"segment size is number\")\n",
        "  output = predict(\"should be number parameter(s) for operator\")\n",
        "  output = predict(\"size of identifier is not known\")\n",
        "  output = predict(\"size of type exceeds 64KB\")\n",
        "  output = predict(\"statement expected\")\n",
        "  output = predict(\"static function 'identifier' can't be virtual\")\n",
        "  output = predict(\"static or non-member functions can't be const or volatile\")\n",
        "  output = predict(\"static variables in inline functions not allowed\")\n",
        "  output = predict(\"storage class for 'identifier' can't be both extern and inline\")\n",
        "  output = predict(\"string expected\")\n",
        "  output = predict(\"struct-declaration-list can't be empty\")\n",
        "  output = predict(\"template-argument 'identifier' must be a type-argument\")\n",
        "  output = predict(\"template-argument 'identifier' not used in function parameter types\")\n",
        "  output = predict(\"too many errors\")\n",
        "  output = predict(\"too many initializers\")\n",
        "  output = predict(\"trailing parameters must have initializers\")\n",
        "  output = predict(\"__try only valid for -mn memory model\")\n",
        "  output = predict(\"type conversions must be members\")\n",
        "  output = predict(\"type is too complex\")\n",
        "  output = predict(\"type mismatch\")\n",
        "  output = predict(\"type must be a pointer or a reference to a defined class or void*\")\n",
        "  output = predict(\"type must be void *operator new(size_t [,..]);\")\n",
        "  output = predict(\"type of 'identifier' does not match function prototype\")\n",
        "  output = predict(\"types may not appear more than once in an exception specification\")\n",
        "  output = predict(\"unable to open input file 'filename'\")\n",
        "  output = predict(\"unable to open output file 'filename'\")\n",
        "  output = predict(\"undefined escape sequence\")\n",
        "  output = predict(\"undefined identifier 'identifier'\")\n",
        "  output = predict(\"undefined label 'identifier'\")\n",
        "  output = predict(\"undefined tag 'identifier'\")\n",
        "  output = predict(\"undefined use of struct or union\")\n",
        "  output = predict(\"unknown operand type for this floating point instruction\")\n",
        "  output = predict(\"union members cannot have ctors or dtors\")\n",
        "  output = predict(\"unrecognized pragma\")\n",
        "  output = predict(\"unrecognized parameter 'identifier'\")\n",
        "  output = predict(\"unrecognized preprocessing directive '#identifier'\")\n",
        "  output = predict(\"unrecognized token\")\n",
        "  output = predict(\"unsupported based type\")\n",
        "  output = predict(\"unsupported __declspec type\")\n",
        "  output = predict(\"unterminated macro argument\")\n",
        "  output = predict(\"unterminated string\")\n",
        "  output = predict(\"use delete[] rather than delete[expr]\")\n",
        "  output = predict(\"using operator++() (or --) instead of missing operator++(int)\")\n",
        "  output = predict(\"valid memory models are -m[tsmcrzlvfnpx]\")\n",
        "  output = predict(\"value of expression is not used\")\n",
        "  output = predict(\"variable 'identifier' used before set\")\n",
        "  output = predict(\"vectors cannot have initializers\")\n",
        "  output = predict(\"very large automatic\")\n",
        "  output = predict(\"voids have no value\")\n",
        "  output = predict(\"voids have no value\")\n",
        "  output = predict(\"'while' expected\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  print(\"\\nGCC 컴파일 에러 메시지\")\n",
        "  output = predict(\"`##' at end of macro definition)\")\n",
        "  output = predict(\"`##' at start of macro definition\")\n",
        "  output = predict(\"`#elif' after `#else'\")\n",
        "  output = predict(\"#error XXX\")\n",
        "  output = predict(\"`#XXX' not within a conditional\")\n",
        "  output = predict(\"'#include' expects FILENAME or <FILENAME>\")\n",
        "  output = predict(\"`#' operator is not followed by a macro argument name\")\n",
        "  output = predict(\"ANSI C requires a named argument before `...'\")\n",
        "  output = predict(\"arithmetic on pointer to an incomplete type\")\n",
        "  output = predict(\"attempt to take address of bit-field structure member `XXX'\")\n",
        "  output = predict(\"badly punctuated parameter list in `#define'\")\n",
        "  output = predict(\"break statement not within loop or switch\")\n",
        "  output = predict(\"called object is not a function\")\n",
        "  output = predict(\"case label not within a switch statement\")\n",
        "  output = predict(\"character constant too long\")\n",
        "  output = predict(\"char-array initialized from wide string\")\n",
        "  output = predict(\"conflicting types for `XXX'\")\n",
        "  output = predict(\"continue statement not within a loop\")\n",
        "  output = predict(\"declaration of `XXX' as array of voids\")\n",
        "  output = predict(\"default label not within a switch statement\")\n",
        "  output = predict(\"dereferencing pointer to incomplete type\")\n",
        "  output = predict(\"duplicate case value\")\n",
        "  output = predict(\"empty character constant\")\n",
        "  output = predict(\"empty file name in `#include'\")\n",
        "  output = predict(\"empty #if expression\")\n",
        "  output = predict(\"enumerator value for `xxx' not integer constant\")\n",
        "  output = predict(\"function `XXX' is initialized like a variable\")\n",
        "  output = predict(\"incompatible type for argument N of `XXX'\")\n",
        "  output = predict(\"incompatible types in assignment\")\n",
        "  output = predict(\"invalid format `#line' directive\")\n",
        "  output = predict(\"invalid #-line\")\n",
        "  output = predict(\"invalid initializer\")\n",
        "  output = predict(\"invalid macro name `defined'\")\n",
        "  output = predict(\"invalid macro name `XXX'\")\n",
        "  output = predict(\"invalid operands to binary X\")\n",
        "  output = predict(\"invalid preprocessing directive name\")\n",
        "  output = predict(\"invalid use of undefined type `XXX'\")\n",
        "  output = predict(\"invalid type argument of `unary *'\")\n",
        "  output = predict(\"macro or `#include' recursion too deep\")\n",
        "  output = predict(\"multiple default labels in one switch\")\n",
        "  output = predict(\"negative width in bit-field `XXX'\")\n",
        "  output = predict(\"No such file or directory\")\n",
        "  output = predict(\"numeric constant contains digits beyond the radix\")\n",
        "  output = predict(\"parameter `XXX' is initialized\")\n",
        "  output = predict(\"parameter name omitted\")\n",
        "  output = predict(\"parse error\")\n",
        "  output = predict(\"parse error before `XXX'\")\n",
        "  output = predict(\"possible real start of unterminated constant\")\n",
        "  output = predict(\"redeclaration of `XXX'\")\n",
        "  output = predict(\"redefinition of `XXX'\")\n",
        "  output = predict(\"register name not specified for `XXX'\")\n",
        "  output = predict(\"request for member `XXX' in something not a structure or union\")\n",
        "  output = predict(\"`sizeof' applied to a bit-field\")\n",
        "  output = predict(\"storage size of `XXX' isn't known\")\n",
        "  output = predict(\"structure has no member named `XXX'\")\n",
        "  output = predict(\"top-level declaration of `XXX' specifies `auto'\")\n",
        "  output = predict(\"too few arguments to function `XXX'\")\n",
        "  output = predict(\"too many arguments to function `XXX'\")\n",
        "  output = predict(\"typedef `XXX' is initialized\")\n",
        "  output = predict(\"unbalanced `#endif'\")\n",
        "  output = predict(\"undefined or invalid # directive'\")\n",
        "  output = predict(\"union has no member named `XXX'\")\n",
        "  output = predict(\"unterminated character constant\")\n",
        "  output = predict(\"unterminated comment\")\n",
        "  output = predict(\"unterminated `#if' conditional\")\n",
        "  output = predict(\"unterminated macro call\")\n",
        "  output = predict(\"unterminated string or character constant\")\n",
        "  output = predict(\"variable or field `XXX' declared void\")\n",
        "  output = predict(\"void value not ignored as it ought to be\")\n",
        "  output = predict(\"'XXX' declared as function returning an array\")\n",
        "  output = predict(\"'XXX' defined as wrong kind of tag\")\n",
        "  output = predict(\"`XXX' has both `extern' and initializer\")\n",
        "  output = predict(\"XXX: No such file or directory\")\n",
        "  output = predict(\"`XXX' previously declared here\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93R3t2NAf_FU",
        "outputId": "2e19a834-3937-4fe6-c8a1-8e365206d8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GCC 컴파일 에러 메시지\n",
            "Input: `##' at end of macro definition)\n",
            "Output: 매크로 확장에서 예기치 않은 파일의 끝이 나타났습니다 .\n",
            "Input: `##' at start of macro definition\n",
            "Output: 매크로 확장에서 예기치 않은 파일의 끝이 나타났습니다 .\n",
            "Input: `#elif' after `#else'\n",
            "Output: 예기치 않은 #else입니다 .\n",
            "Input: #error XXX\n",
            "Output: #undef '%s'을(를) 할 수 없습니다\n",
            "Input: `#XXX' not within a conditional\n",
            "Output: }' 토큰 앞에 ')'이(가) 있어야 합니다 .\n",
            "Input: '#include' expects FILENAME or <FILENAME>\n",
            "Output: #include \"FILENAME\" 또는 <FILENAME>이 필요합니다 .\n",
            "Input: `#' operator is not followed by a macro argument name\n",
            "Output: 열거형 'enumeration'의 switch에 있는 'identifier' 열거자가 case 레이블에 의해 명시적으로 처리되지 않습니다 .\n",
            "Input: ANSI C requires a named argument before `...'\n",
            "Output: 차원은 음수일 수 없습니다 .\n",
            "Input: arithmetic on pointer to an incomplete type\n",
            "Output: 상수 또는 휘발성 개체에 대한 포인터 유형이 있어야 합니다 .\n",
            "Input: attempt to take address of bit-field structure member `XXX'\n",
            "Output: 문자열 리터럴 문자열 ')로 무시됩니다 .\n",
            "Input: badly punctuated parameter list in `#define'\n",
            "Output: 'file' 프로그램 데이터베이스를 열 수 없습니다 .\n",
            "Input: break statement not within loop or switch\n",
            "Output: 표현식은 정수여야 합니다 .\n",
            "Input: called object is not a function\n",
            "Output: 함수 수정자가 이전 선언 '%S'와 충돌합니다 .\n",
            "Input: case label not within a switch statement\n",
            "Output: switch 식이 정수가 아님\n",
            "Input: character constant too long\n",
            "Output: 자동 할당이 size를 초과합니다 .\n",
            "Input: char-array initialized from wide string\n",
            "Output: 선언문이 if 문 다음에 나옵니다 .\n",
            "Input: conflicting types for `XXX'\n",
            "Output: 'for' 앞에 ')'가 있어야 합니다 .\n",
            "Input: continue statement not within a loop\n",
            "Output: 함수가 아닙니다 .\n",
            "Input: declaration of `XXX' as array of voids\n",
            "Output: 'offsetof'의 배열 형식을 참조할 수 없습니다 .\n",
            "Input: default label not within a switch statement\n",
            "Output: switch 식이 정수가 아님\n",
            "Input: dereferencing pointer to incomplete type\n",
            "Output: 불완전한 형식 'type'에 대한 포인터를 삭제 했지만 소멸자가 호출되지 않음\n",
            "Input: duplicate case value\n",
            "Output: 중복된 case의 값 '%s'을(를) 찾았습니다 .\n",
            "Input: empty character constant\n",
            "Output: 잘못된 초기화 상수\n",
            "Input: empty file name in `#include'\n",
            "Output: main'을 참조할 수 없습니다 .\n",
            "Input: empty #if expression\n",
            "Output: 표현식은 정수여야 합니다 .\n",
            "Input: enumerator value for `xxx' not integer constant\n",
            "Output: '에 대한 표현식은 클래스 정의는 enumeration대한 포인터 유형이 아닙니다 .\n",
            "Input: function `XXX' is initialized like a variable\n",
            "Output: 'identifier': 함수 초기화\n",
            "Input: incompatible type for argument N of `XXX'\n",
            "Output: 'file' DLL을 찾을 수 없습니다 .\n",
            "Input: incompatible types in assignment\n",
            "Output: 잘못 배치된 #include 지시문\n",
            "Input: invalid format `#line' directive\n",
            "Output: #using이 'file'에서 실패했습니다 .\n",
            "Input: invalid #-line\n",
            "Output: 잘못된 #include 지시문\n",
            "Input: invalid initializer\n",
            "Output: 부동 소수점 상수가 너무 작아 표현할 수 없습니다 .\n",
            "Input: invalid macro name `defined'\n",
            "Output: 거부된 기능: %F가 %L을 정의하였음\n",
            "Input: invalid macro name `XXX'\n",
            "Output: 예기치 않은 'token' 토큰입니다 .\n",
            "Input: invalid operands to binary X\n",
            "Output: 잘못된 전처리 지시어 #intain\n",
            "Input: invalid preprocessing directive name\n",
            "Output: 예기치 않은 #전처리 지시문\n",
            "Input: invalid use of undefined type `XXX'\n",
            "Output: 정의되지 않은 형식 'type'의 사용\n",
            "Input: invalid type argument of `unary *'\n",
            "Output: 소멸자에 인수 목록이 있습니다 .\n",
            "Input: macro or `#include' recursion too deep\n",
            "Output: #include 중첩 수준은 'nest\\&undsccount'만큼 깊습니다 .  무한 재귀일 가능성이 있습니다 .\n",
            "Input: multiple default labels in one switch\n",
            "Output: 종료 \" 문자가 누락되었습니다 .\n",
            "Input: negative width in bit-field `XXX'\n",
            "Output: 비트 필드를 참조할 수 없습니다 .\n",
            "Input: No such file or directory\n",
            "Output: windows . h\n",
            "Input: numeric constant contains digits beyond the radix\n",
            "Output: 숫자 상수 앞에 ';'가 필요합니다 .\n",
            "Input: parameter `XXX' is initialized\n",
            "Output: continue가 잘못되었습니다 .\n",
            "Input: parameter name omitted\n",
            "Output: 함수는 배열을 반환합니다 .\n",
            "Input: parse error\n",
            "Output: 내부 메모리 관리 오류입니다 .\n",
            "Input: parse error before `XXX'\n",
            "Output: returns' 앞에 ';'가 필요합니다 .\n",
            "Input: possible real start of unterminated constant\n",
            "Output: 예기치 않은 유형 한정자를 찾았습니다 .\n",
            "Input: redeclaration of `XXX'\n",
            "Output: char m'이 재선언 되었습니다 .\n",
            "Input: redefinition of `XXX'\n",
            "Output: 불완전한 배열을  'enumeration' when\n",
            "Input: register name not specified for `XXX'\n",
            "Output: 왼쪽 표현식은 상수 또는 참조 형식에 정수 유형이 무시데 유효한 포인터가 다른 구현되지 않았습니다 .\n",
            "Input: request for member `XXX' in something not a structure or union\n",
            "Output: 첫 번째 피연산자가 클래스 ,  구조체 또는 공용체가 아닙니다 .\n",
            "Input: `sizeof' applied to a bit-field\n",
            "Output: 'sizeof'는 비트 필드에 사용할 수 없습니다 .\n",
            "Input: storage size of `XXX' isn't known\n",
            "Output: 'assembly' 어셈블리를 반환합니다 .\n",
            "Input: structure has no member named `XXX'\n",
            "Output: '&' 토큰 앞에 unqualified-id가 필요합니다 .\n",
            "Input: top-level declaration of `XXX' specifies `auto'\n",
            "Output: <' 토큰 앞에 단항식이 필요합니다 .\n",
            "Input: too few arguments to function `XXX'\n",
            "Output: 암시적 'void' 인수가 없기 때문에 인수 개수는 %d입니다 .\n",
            "Input: too many arguments to function `XXX'\n",
            "Output: 함수 a에 이미 본문이 있습니다 .\n",
            "Input: typedef `XXX' is initialized\n",
            "Output: '%S'에 대한 테스트 표현식은 항상 true입니다 .\n",
            "Input: unbalanced `#endif'\n",
            "Output: #endif가 필요합니다 .\n",
            "Input: undefined or invalid # directive'\n",
            "Output: #pragma 매개 변수 'parameter\\&undscnumber'은 정의되지 않았습니다 .\n",
            "Input: union has no member named `XXX'\n",
            "Output: 공용체의 모든 비트 앞에 ';'이 필요합니다 .\n",
            "Input: unterminated character constant\n",
            "Output: 잘못된 상수여야 합니다 .\n",
            "Input: unterminated comment\n",
            "Output: 익명 구조체/소멸자에 대한 \n",
            "Input: unterminated `#if' conditional\n",
            "Output: 예기치 않은 #endif입니다 .\n",
            "Input: unterminated macro call\n",
            "Output: 중복 매크로 매개변수 '%s'\n",
            "Input: unterminated string or character constant\n",
            "Output: 정수 상수 식이 잘못되었습니다 .\n",
            "Input: variable or field `XXX' declared void\n",
            "Output: 'fn': 실제 매개 변수의 형식이 'void': 매개 변수 번호\n",
            "Input: void value not ignored as it ought to be\n",
            "Output: 'fn': 내장 함수가 선언되지 않음\n",
            "Input: 'XXX' declared as function returning an array\n",
            "Output: 'c'은 프로그램에서 위치를 벗어났습니다 .\n",
            "Input: 'XXX' defined as wrong kind of tag\n",
            "Output: 'file' dll을 로드하는 동안 오류가 발생했습니다 .  호환되지 않는 버전입니다 .\n",
            "Input: `XXX' has both `extern' and initializer\n",
            "Output: extern \"C\" 함수에 대한 인수에 컴파일러 생성 정보가 포함되어 있습니다 .\n",
            "Input: XXX: No such file or directory\n",
            "Output: windows . h: 해당 파일 또는 디렉터리가 없습니다 .\n",
            "Input: `XXX' previously declared here\n",
            "Output: 'type' 형식이 예기치 않음\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo0dnyyUlakH"
      },
      "source": [
        "- !코랩 런타임 유지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JZtcFPGlebv"
      },
      "outputs": [],
      "source": [
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button\").click() \n",
        "}setInterval(ClickConnect, 450000)\n",
        "\n",
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = keras.models.load_model(\"my_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdP4tAsupFT7",
        "outputId": "08ec35ef-91f1-4bd8-a51c-ea9ccf0820f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-18 03:08:13--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54, 2606:4700:3030::6815:5c2c, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6532197 (6.2M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   6.23M  25.3MB/s    in 0.2s    \n",
            "\n",
            "2022-04-18 03:08:13 (25.3 MB/s) - ‘fra-eng.zip’ saved [6532197/6532197]\n",
            "\n",
            "Archive:  fra-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n"
          ]
        }
      ],
      "source": [
        "!wget http://www.manythings.org/anki/fra-eng.zip -O fra-eng.zip\n",
        "!unzip fra-eng.zip"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sBguAJ7GPq-3",
        "jLStl1dRP43v"
      ],
      "name": "Transformer_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}